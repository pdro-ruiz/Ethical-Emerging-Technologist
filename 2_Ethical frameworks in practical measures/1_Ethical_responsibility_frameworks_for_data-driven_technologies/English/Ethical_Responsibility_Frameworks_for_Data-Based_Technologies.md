# Ethical Responsibility Frameworks for Data-Based Technologies

## Translating Ethical Principles into Action

### **1. Utilitarianism**
   - **Definition**: Correct actions promote the greatest happiness for the greatest number.
   - **Proponent**: John Stuart Mill.
   - **Subtypes**:
     - **Act**: Each action judged individually by its effect.
     - **Rule**: Follow rules that generally promote the greatest happiness.
   - **Example**: Trolley dilemma; choosing between the well-being of one versus many.

### **2. Deontology (Duty-Based Ethics)**
   - **Definition**: Correct actions based on universal moral rules, regardless of consequences.
   - **Proponent**: Immanuel Kant.
   - **Key Concepts**:
     - **Categorical Imperative**: Act in a way that the action could be a universal law.
     - **Principle of Humanity**: Not to use people as means, but treat them as an end.
   - **Example**: Universal moral laws, like not lying, considered right under all circumstances.

### **3. Virtue Ethics**
   - **Definition**: Focused on being a person of good moral character rather than on performing specific right actions.
   - **Proponent**: Aristotle.
   - **Key Concepts**:
     - **Excellence as Habit**: Virtue is developed through practice and modeling.
     - **Golden Mean**: Balance between two extremes (e.g., courage between cowardice and recklessness).
   - **Example**: Adapting action to the specific situation based on virtuous character.

### **Comparative and Reflection:**
- **Utilitarianism vs. Deontology**: Utilitarianism focuses on consequences and overall well-being, 
  while deontology focuses on adhering to universal moral principles, regardless of outcomes.
- **Virtue Ethics**: Provides a more flexible approach, focused on character development
   and moral adaptation to specific situations.

### **Importance in Data-Based Technologies**:
- **Utilitarianism**: Can justify data use for the greater good, but poses risks of overriding individual rights.
- **Deontology**: Prioritizes respect for rules and human dignity in the design and use of technologies.
- **Virtue Ethics**: Encourages designers and users of technology to develop and apply moral character, beyond norms and consequences.



## Ethical Principles and Frameworks

### What is an Ethical Framework?

#### **Definition of Ethical Framework:**
- A set of guiding principles that influence how individuals or companies behave and make decisions.

#### **Important Distinction:**
- **Philosophical Theory vs. Ethical Framework**:
  - Philosophical Theory: Timeless ideals, conceptual, not always directly actionable.
  - Ethical Framework: Operationalized ethical principles, focused on action and practical application.

#### **Comparison:**
- **Morality vs. Ethics**:
  - Morality: Set of personal or cultural beliefs and values.
  - Ethics: Principles and norms that direct actions in a broader or professional context.

#### **Evolution and Context:**
- Origins in human reflection and decision-making.
- Surge in data-based technologies in the 80s and 90s, especially in business ethics.
  
#### **Development of New Ethical Frameworks:**
- Examine previous ethical frameworks to identify common principles and theories.
- Initially based on philosophies and religious teachings, evolving towards modernized approaches.
  
#### **Identifying the Right Framework:**
- Search for minimal similarities and distinctions among existing frameworks.
- Select the framework that best aligns with one's own needs and those of stakeholders.

### **Reflection and Action:**
- Consider which ethical framework best suits personal or business needs.
- Evaluate how each framework serves those it aims to benefit.

#### **Notes:**
- Ethical frameworks are critical tools for guiding responsible behaviors and decisions.
- The selection of an appropriate ethical framework requires careful consideration of common principles and specific needs.



### Montreal Declaration for a Responsible Development of Artificial Intelligence

#### **Objective of the Declaration**: To guide individuals, organizations, companies, and governments in ethical and responsible decision-making in AI.

#### **Initiation and Participation**: 
- Initiative started in November 2017 at the University of Montreal.
- Published in December 2018 with the help of over 500 citizens, experts, and stakeholders.

#### **Ten Fundamental Principles**:

1. **Well-being**: Promote the growth of the well-being of all sentient beings.

2. **Respect for Autonomy**: Respect and increase individuals' control over their lives and their environment.

3. **Protection of Privacy and Intimacy**: Protect intimacy and privacy against AI and data acquisition systems.

4. **Solidarity**: Maintain human solidarity ties and foster human relations.

5. **Democratic Participation**: Ensure transparency, justifiability, and accessibility; subject to democratic control.

6. **Equity**: Contribute to a just and equitable society.

7. **Diversity and Inclusion**: Promote social and

 cultural diversity; minimize and eliminate biases.

8. **Prudence (Caution)**: Act with caution anticipating and avoiding possible adverse consequences.

9. **Responsibility**: Ensure that AI does not diminish human responsibility; humans are always responsible.

10. **Sustainable Development**: Promote environmental sustainability.

#### **Comparison with Other Frameworks**:
- Similarities with other frameworks in emphasizing transparency, justice, impartiality, responsibility, non-maleficence, and privacy.

### **Framework Design**:
- Designed for any stakeholder involved in responsible AI.
- Includes over 85 distinct ethical frameworks for AI, with common fundamental principles.




### Ethical Guidelines for Trustworthy AI

#### **Origin and Development**:
- An initiative by the European Commission in 2018.
- Public consultation and pilot to gather opinions and improve the framework.

#### **Main Objectives**:
1. **Legality**: Compliance with all applicable laws and regulations.
2. **Ethics**: Respect for ethical principles and human values.
3. **Robustness**: Technological solidity, consideration of the social environment, and ecological development.

#### **Importance**:
- Ensure sustainable and beneficial AI development for everyone.
- Foster international and national debate on equitable, inclusive, and ecologically sustainable AI development.

#### **Fundamental Principles**:
1. **Human Agency and Oversight**: Importance of human intervention and control.
2. **Technological Robustness and Safety**: Reliability and safety in the design and operation of AI.
3. **Privacy and Data Governance**: Protection of user data and privacy.
4. **Transparency**: Understandability and accessibility of AI technologies.
5. **Diversity, Non-Discrimination, and Fairness**: Promotion of inclusion and equity in the development and use of AI.
6. **Social and Environmental Well-being**: Positive contribution to social well-being and environmental sustainability.
7. **Accountability**: Ensuring accountability and accountability in the development and use of AI.

#### **Differentiation with Other Frameworks**:
- Based on human and fundamental rights, specific to the European Union.
- Focused on a human-centered approach informed by human and fundamental rights.

#### **Special Considerations**:
- Aligned with the EU Charter of Fundamental Rights.
- Useful for individuals and companies within the EU.

#### **Questions for Reflection**:
- Do the guidelines cover all necessary aspects for ethical and trustworthy AI?
- What elements might be missing or need expansion in these guidelines?




### Beijing AI Principles

#### **Origin and Purpose**:
- Developed in Beijing, China, by the Beijing Academy of Artificial Intelligence in May 2019.
- Goal: Ensure that AI respects and protects privacy, dignity, and human freedoms, and prevents harm to humans.

#### **Framework Structure**:
1. **AI Research and Development (R&D)**:
   - **Do Good**: Benefit humanity.
   - **For Humanity**: Respect human values.
   - **Responsibility**: Ethical and responsible creation.
   - **Risk Control**: Risk management and reliability.
   - **Ethics**: Foster trust.
   - **Diversity and Inclusion**: Consideration of minorities and underserved groups.
   - **Open and Shareable**: Democratization and accessibility of data and developments.

2. **Principles for the Use of AI**:
   - **Wise and Appropriate Use**: Mitigation of misuse.
   - **Informed Consent**: Transparency in data processing.
   - **Education and Training**: Broad understanding of AI's workings.

3. **Principles for the Governance of AI**:
   - **Employment Optimization**: Labor adaptation without human replacement.
   - **Harmony and Cooperation**: Interdisciplinary and collaborative approach.
   - **Adaptation and Moderation**: Continuous evolution of regulations.
   - **Subdivision and Implementation**: Specific norms for AI subfields.
   - **Long-term Planning**: Preparation for future advances in AI.

#### **Applicability of the Framework**:
- Aimed at guiding ethical R&D within artificial intelligence.
- Focuses on the importance of data sharing, inclusion, and a human-centered approach.

#### **Considerations for Reflection**:
- Reflect on potential omissions or areas requiring expansion.
- Consider how this framework compares and complements other ethical frameworks in AI.




### Universal Guidelines for Artificial Intelligence (UGIA)

#### **Origin and Purpose**:
- Developed by the Public Voice coalition in October 2019, announced in 2018.
- Goal: Encourage transparency and accountability in AI systems, ensuring that people maintain control over technology.

#### **Key Features**:
- **Emphasis on Human Rights**: Protection and affirmation of human rights to maximize benefits and minimize risks of AI.
- **Assignment of Responsibility**: Responsibility for AI systems lies with the institutions that finance, develop, and deploy them, a stance not common in other frameworks.

#### **Usage Context**:
- **Incorporation into Laws**: Encouraged to be part of ethical norms in laws and agreements at international and national levels.
- **

Ethical Design of AI**: Focuses on ensuring that AI is ethically designed from its conception.

#### **Comparison with Other Frameworks**:
- Draws principles from other recognized frameworks such as IEEE's ethically aligned design and the Asilomar principles.
- Distinguished by its focus on the assignment of responsibility and protection of human rights.

#### **Questions for Reflection**:
- Are the UGIA truly universal?
- How could these guidelines be improved to ensure their applicability and effectiveness universally?



### The 10 Principles for Ethical Artificial Intelligence by UNI Global Union

#### **Context**:
- Created by the UNI Global Union, intending to prioritize people and planet in AI.
- Seeks a global convention on ethical AI.

#### **Goals**:
- Safeguard workers' rights.
- Positively influence digitization.

#### **The 10 Principles**:
1. **Transparency**: Understanding how AI systems work.

2. **Ethical Black Box**: Record of AI decision-making processes for review in case of incidents.

3. **Service to People and Planet**: Prioritizing human and environmental well-being.

4. **Humans in Command**: Maintaining human control over AI, avoiding complete replacement by machines.

5. **Bias-Free and Genderless AI**: Preventing the spread of racial and gender biases.

6. **Sharing AI Benefits**: Democratizing the benefits of AI for all.

7. **Just Transition and Fundamental Freedoms**: Facilitating the adaptation of workers displaced by AI.

8. **Global Governance**: Establishing global and regional guidelines for AI governance.

9. **Responsibility Attribution**: Holding the designers, implementers, and users of AI accountable, not robots.

10. **Prohibition of AI Arms Race**: Avoiding escalation of AI in military applications.

#### **Applicability**:
- Relevant for workers represented by unions and companies undergoing digitization.
- Especially useful for anticipating and preparing for labor changes due to AI.

#### **Comparison with Other Frameworks**:
- Similar emphasis on transparency and human accountability.
- Unique in its trade union focus and the protection of labor rights against digitization.

#### **Questions for Reflection**:
- Are all aspects of ethical AI well-represented in these principles?
- What principles might be added or modified for a more complete representation?



## Shared Principles across Ethical Frameworks



### Privacy in Ethical Frameworks of AI

#### Importance of Privacy
- **Privacy as a Foundation**: Considered essential in most ethical frameworks for AI, viewed both as a value to defend and a right to protect.
- **Incorporation into Ethical Frameworks**: More than 50% of the approximately 85 ethical frameworks for AI prioritize privacy as a key principle.
- **Key Reasons for the Importance of Privacy**:
  - Autonomy and freedom of choice.
  - Protection against abuse of power.
  - Physical security.
  - Foundation for freedom and free will.

#### Implementation of Privacy in AI
- **Technical Solutions**: Implementation of differential privacy, privacy by design, and data minimization.
- **Research, Awareness, and Regulation**: Promotion of awareness and regulation by nonprofit organizations.
- **Certifications**: Development of specific certifications and regulations to protect privacy in the realm of AI.

#### Reflections
- Privacy is recognized as a crucial principle in the development and application of AI technologies due to its intrinsic link to individual freedom and protection against abuses.
- It raises the question of whether privacy is treated with the depth and seriousness necessary in all existing ethical frameworks, and if there is room for improvement in how this principle is addressed and protected.
- The inclusion of privacy as a central component in ethical frameworks for AI reflects its universal importance, not only in terms of data protection but as a fundamental pillar for a just and free society.




### Responsibility in AI

#### Definition and Challenges
- **"Responsible AI" Not Clearly Defined**: Responsibility and accountability in the context of AI are often mentioned but seldom precisely defined.
- **Importance in Ethical Frameworks**: More than 70% of AI ethical frameworks emphasize the importance of responsibility and accountability.

#### Key Principles
- **Causality**: Identifying who or what caused a harm or error.
- **Justice**: Determining who deserves to be punished or recompensed.
- **Reparation**: Deciding who should compensate for the damages caused.

#### Challenge of the Accountability Gap
- **Accountability Gap**: Difficulty in assigning responsibility when AI fails due to the complexity of the systems and human intervention.
- **Varied Perspectives**: Some frameworks suggest that humans behind AI should be responsible, while others propose that the AI itself could carry some form of legal responsibility.

#### Approaches for Ensuring Accountability
- **Open Debate**: Most ethical frameworks promote debate on who should be responsible without

 reaching a clear consensus.
- **Auditability**: Proposes that transparency and the auditability of AI systems can help ensure accountability.

#### Reflections
- Responsibility and accountability in AI are essential yet complicated principles due to the lack of consensus on how to effectively implement them.
- It's crucial to continue the dialogue and develop clear regulations that assign responsibility fairly and effectively, considering both AI developers and AI systems themselves.




### Transparency and Explainability in AI

#### Definition and Popularity
- **Prevalence**: Cited in more than 85% of all ethical frameworks, making it the most popular principle.
- **Transparency**: Involves using clear language to explain how AI systems work, including their capabilities and the origin of their data.

#### Subprinciples
- **Explainability**: The ability to describe the internal processes of AI in human terms.
- **Interpretability**: The ability to understand and predict how AI responds to different situations or changes.
- **Auditability**: Verifying that models are transparent and explainable.

#### Importance
- **Facilitates Understanding**: Allows everyone to understand what AI does.
- **Mitigates Issues**: Helps reduce problems related to fairness, discrimination, and distrust.

#### Implementation Strategies
- **Integration into Ethical Frameworks**: Include transparency and explainability as key principles.
- **Differentiation between Explainability and Interpretability**: Recognize and apply their differences in the design and evaluation of AI systems.

#### Challenges and Solutions
- **Black Box Problem**: AI often operates in an opaque manner, making it difficult to understand its internal workings.
- **Need for Transparency**: Transparency allows for verifying fairness, reducing fraud, and educating the public.

#### Reflections
- **Transparency vs. Predictive Ability**: The discrepancy between AI and human decisions highlights the importance of transparency.
- **Transparency as a Foundation**: Considered essential for the ethical and responsible development of AI.




### Equity and Non-Discrimination in AI

#### Prevalence
- **Importance**: The second most cited principle after transparency in AI ethical frameworks.
- **Inclusion**: Present in almost all significant ethical frameworks.

#### Definitions and Difficulties
- **Definition of Fairness**: Not universal, highly contextual. Varies according to context and application.
- **Fair Algorithm**: Produces results independent of protected characteristics (gender, ethnicity, sexual orientation).

#### Two Perspectives of Fairness
1. **Outcome Independence**: Fairness as independence from protected characteristics.
2. **Equal Access**: Equitable access to data, AI, and technological benefits.

#### Relation with Non-Discrimination
- **Connection**: Fairness is intrinsically linked to non-discrimination to prevent biases and ensure equal treatment.

#### Value to the Industry
- **Economic Benefit**: Improving fairness and preventing discrimination can represent up to $500 billion in value for the tech industry.

#### Building Ethical AI Systems
- **Preventing Bias**: Essential to not reinforce or create biases, especially in relation to protected characteristics.
- **Reference in Frameworks**: Ethical frameworks emphasize the prevention, monitoring, and mitigation of biases and discrimination.

#### Implications
- Fairness and non-discrimination are fundamental for the ethical development of AI, addressing both the prevention of existing biases and the creation of new ones.
- Attention to these principles is not only a moral imperative but also a significant economic opportunity for the industry.




### Safety and Protection in AI

#### Main Concept
- **Non-Maleficence**: Inspired by bioethics, means not to cause foreseeable or intentional harm to humans. Interpreted as preventing discrimination, privacy violations, and bodily injuries.

#### Relation with Other Principles
- **Dependence on Principles**: To achieve safety and protection, explainability and transparency are necessary, allowing for a full human understanding of what the technology does and how it works.

#### Prevalence in Ethical Frameworks
- **Inclusion in Frameworks**: More than 70% of ethical frameworks for AI include the principle of non-maleficence or safety and protection as fundamental.

#### Importance
- **Goal**: Ensure that AI systems operate safely and protectedly before their widespread use.
- **Reasoning**: AI should not cause foreseeable harm; if it occurs, measures should be taken to mitigate it.

#### Linkage with Other Concepts
- **Relation with Privacy and Security**: This principle is linked with privacy and security to ensure data protection of end-users.

#### Implementation in Frameworks
- **Approach**: There is no standardized way; compliance with new legislations and oversight processes, including audits and assessments, is encouraged.
- **Technical Solutions**: Like differential privacy, to ensure end-user data protection.

#### Discussion
- **Relevance of Non-Maleficence**: The importance of having technology guaranteed not to cause harm is closely linked to the reliability and trust in AI technology.




### Human Control of Technology in AI

#### Main Concept
- **Meaningful Human Control**: Emphasizes the importance of maintaining genuine and conscious human oversight and participation in

 the operation of autonomous technologies, especially autonomous weapons.

#### Basic Premises
1. **Autonomy of Machines**: Generally considered problematic to allow weapons or machines to operate without human supervision.
2. **Inadequacy of Superficial Control**: The action of simply pressing a button under the instruction of a computer, without truly understanding the action, is insufficient to constitute meaningful human control.

#### Relation with Other Ethical Principles
- **Transparency and Explainability**: Essential for meaningful human control, enabling complete human understanding of what the technology does and how it operates.

#### Discussion in Ethical Frameworks
- While meaningful human control is a crucial topic, many ethical frameworks focus more on related principles (like transparency) than on defining or explicitly discussing human control.

#### Importance
- **Basis of Ethical Debates**: The debate about transparency and reliability revolves around the idea of maintaining human control over technology, ensuring that humans understand and can intervene in AI operations.

#### Reflection
- **Lack of Explicit Definition**: Despite its importance, human control is not clearly defined in many ethical frameworks, raising questions about how and why it should be more formally integrated into future discussions and ethical frameworks.



### Professional Responsibility in AI

#### Main Concept
- **Professional Responsibility**: Assesses AI's impact on the autonomy and capacity of professionals. Questions whether AI should amplify or replace professional intelligence and skills.

#### Discussion in Ethical Frameworks
- Largely absent in popular ethical frameworks, except for a brief mention in IEEE's Ethically Aligned Design.
- **IEEE's Ethically Aligned Design**: Touches on the topic in relation to classical ethics.

#### Key Question
- Does AI **enhance** or **replace** professional intelligence?

#### Case Study: American Medical Association (AMA)
- Defines AI as **Augmented Intelligence**, promoting the concept that AI should empower and not replace physicians.
- Emphasizes using AI to enhance medical expertise rather than replace human decision-making.

#### Fundamental Dilemma
- Difficult to differentiate between **enhancing** professional capacity versus **replacing** professional intelligence and autonomy.
- Important for future ethical frameworks to consider how to define and guide AI use in professional contexts.

#### Reflection and Future Perspective
- Future ethical frameworks could draw inspiration from the AMA's definition of AI as a model for balancing enhancement against replacement in professional use of AI.
- **Importance of Definition**: The way AI is defined can significantly influence its acceptance and application within professional practices.

#### Reflections
1. **Why is professional responsibility not widely discussed in current ethical frameworks?**
2. **Should professional responsibility be a more prominent principle in AI ethical frameworks?**



### Schematic Overview on Promoting Human Values in AI

#### Main Concept
- **Promotion of Human Values**: Considered a "meta-principle" in the development and implementation of AI technologies, emphasizing that AI should incorporate and reflect fundamental human values.

#### General Context
- Traditionally, technology adapted to social norms. However, the rapid evolution of autonomous technologies has reversed this trend, requiring ethical design from the start.
- Advances in AI force placing human values at the center of technological development to ensure benefits to humanity and minimize potential harms.

#### Importance of the Meta-principle
- Underlines that all ethical frameworks for AI should be designed with a human-centered orientation, ensuring that technology serves human well-being and avoids causing harm.

#### Relation with Other Principles
- The promotion of human values acts as the foundation of other principles discussed in ethical frameworks, including transparency, privacy, responsibility, and fairness.

#### Critical Questions
- **Why is this approach fundamental?** Reflects a preference for ensuring that AI benefits and does not harm humans.
- **Is it speciesist?** Some might argue it focuses too much on the human, excluding considerations towards other forms of life or potential autonomous entities.

#### Future Perspectives
- As AI advances towards general artificial intelligence (AGI), questions arise about AI's autonomy and its potential moral consideration.

#### Reflection
- The discussion on promoting human values in AI invites reflection on how technology can and should incorporate ethical principles that reflect and respect human dignity and rights, anticipating the future impact on society and potential AI entities with autonomy.
