<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.16.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:H,mm:ae}=window,W=new H.Toolbar;W.attach(ae);const we=W.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((o,T,c,r)=>{const g=o();window.mm=g.Markmap.create("svg#mindmap",(T||g.deriveOptions)(r),c)})(()=>window.markmap,null,{"content":"Marcos de responsabilidades eticas para tecnologias basadas en datos","children":[{"content":"Convertir los principios eticos en accion","children":[{"content":"<strong>1. Utilitarismo</strong>","children":[{"content":"<strong>Definición</strong>: Acciones correctas promueven la mayor felicidad para el mayor número.","children":[],"payload":{"lines":"6,7"}},{"content":"<strong>Proponente</strong>: John Stuart Mill.","children":[],"payload":{"lines":"7,8"}},{"content":"<strong>Subtipos</strong>:","children":[{"content":"<strong>Acto</strong>: Cada acción juzgada individualmente por su efecto.","children":[],"payload":{"lines":"9,10"}},{"content":"<strong>Regla</strong>: Seguir reglas que generalmente promueven la mayor felicidad.","children":[],"payload":{"lines":"10,11"}}],"payload":{"lines":"8,11"}},{"content":"<strong>Ejemplo</strong>: Dilema del tranvía; elegir entre el bienestar de uno frente al de muchos.","children":[],"payload":{"lines":"11,13"}}],"payload":{"lines":"5,6"}},{"content":"<strong>2. Deontología (Ética Basada en el Deber)</strong>","children":[{"content":"<strong>Definición</strong>: Acciones correctas basadas en reglas morales universales, independientes de las consecuencias.","children":[],"payload":{"lines":"14,15"}},{"content":"<strong>Proponente</strong>: Immanuel Kant.","children":[],"payload":{"lines":"15,16"}},{"content":"<strong>Conceptos Clave</strong>:","children":[{"content":"<strong>Imperativo Categórico</strong>: Actuar de manera que la acción podría ser una ley universal.","children":[],"payload":{"lines":"17,18"}},{"content":"<strong>Principio de Humanidad</strong>: No usar a las personas como medio, sino tratarlas como un fin.","children":[],"payload":{"lines":"18,19"}}],"payload":{"lines":"16,19"}},{"content":"<strong>Ejemplo</strong>: Leyes morales universales, como no mentir, consideradas correctas en todas las circunstancias.","children":[],"payload":{"lines":"19,21"}}],"payload":{"lines":"13,14"}},{"content":"<strong>3. Ética de la Virtud</strong>","children":[{"content":"<strong>Definición</strong>: Enfocada en ser una persona de buen carácter moral más que en realizar acciones específicas correctas.","children":[],"payload":{"lines":"22,23"}},{"content":"<strong>Proponente</strong>: Aristóteles.","children":[],"payload":{"lines":"23,24"}},{"content":"<strong>Conceptos Clave</strong>:","children":[{"content":"<strong>Excelencia como Hábito</strong>: La virtud se desarrolla a través de la práctica y el modelado.","children":[],"payload":{"lines":"25,26"}},{"content":"<strong>Media Dorada</strong>: Equilibrio entre dos extremos (ej.: valentía entre cobardía y temeridad).","children":[],"payload":{"lines":"26,27"}}],"payload":{"lines":"24,27"}},{"content":"<strong>Ejemplo</strong>: Adaptar la acción a la situación específica basada en el carácter virtuoso.","children":[],"payload":{"lines":"27,29"}}],"payload":{"lines":"21,22"}},{"content":"<strong>Comparativa y Reflexión:</strong>","children":[{"content":"<strong>Utilitarismo vs. Deontología</strong>: El utilitarismo se centra en las consecuencias y el bienestar general,<br>\nmientras que la deontología se enfoca en seguir principios morales universales, independientemente de los resultados.","children":[],"payload":{"lines":"30,32"}},{"content":"<strong>Ética de la Virtud</strong>: Proporciona un enfoque más flexible, centrado en el desarrollo del carácter<br>\ny la adaptación moral a situaciones específicas.","children":[],"payload":{"lines":"32,35"}}],"payload":{"lines":"29,30"}},{"content":"<strong>Importancia en Tecnologías Basadas en Datos</strong>:","children":[{"content":"<strong>Utilitarismo</strong>: Puede justificar el uso de datos para el bien mayor, pero plantea riesgos de sobrepasar derechos individuales.","children":[],"payload":{"lines":"36,37"}},{"content":"<strong>Deontología</strong>: Prioriza el respeto por las normas y la dignidad humana en el diseño y uso de tecnologías.","children":[],"payload":{"lines":"37,38"}},{"content":"<strong>Ética de la Virtud</strong>: Incita a los diseñadores y usuarios de tecnología a desarrollar y aplicar un carácter moral, más allá de las normas y las consecuencias.","children":[],"payload":{"lines":"38,39"}}],"payload":{"lines":"35,36"}}],"payload":{"lines":"3,4"}},{"content":"Principios y marcos eticos","children":[{"content":"¿Qué es un Marco Ético?","children":[{"content":"<strong>Definición de Marco Ético:</strong>","children":[{"content":"Un conjunto de principios rectores que influyen en cómo individuos o empresas se comportan y toman decisiones.","children":[],"payload":{"lines":"47,49"}}],"payload":{"lines":"46,47"}},{"content":"<strong>Distinción Importante:</strong>","children":[{"content":"<strong>Teoría Filosófica vs. Marco Ético</strong>:","children":[{"content":"Teoría Filosófica: Ideales atemporales, conceptuales, no siempre procesables directamente.","children":[],"payload":{"lines":"51,52"}},{"content":"Marco Ético: Principios éticos operacionalizados, enfocados en la acción y la aplicación práctica.","children":[],"payload":{"lines":"52,54"}}],"payload":{"lines":"50,54"}}],"payload":{"lines":"49,50"}},{"content":"<strong>Comparación:</strong>","children":[{"content":"<strong>Moralidad vs. Ética</strong>:","children":[{"content":"Moralidad: Conjunto de creencias y valores personales o culturales.","children":[],"payload":{"lines":"56,57"}},{"content":"Ética: Principios y normas que dirigen las acciones en un contexto más amplio o profesional.","children":[],"payload":{"lines":"57,59"}}],"payload":{"lines":"55,59"}}],"payload":{"lines":"54,55"}},{"content":"<strong>Evolución y Contexto:</strong>","children":[{"content":"Orígenes en la reflexión humana y la toma de decisiones.","children":[],"payload":{"lines":"60,61"}},{"content":"Auge en las tecnologías basadas en datos en los años 80 y 90, especialmente en ética empresarial.","children":[],"payload":{"lines":"61,63"}}],"payload":{"lines":"59,60"}},{"content":"<strong>Desarrollo de Nuevos Marcos Éticos:</strong>","children":[{"content":"Examinar marcos éticos previos para identificar principios y teorías comunes.","children":[],"payload":{"lines":"64,65"}},{"content":"Inicialmente basados en filosofías y enseñanzas religiosas, evolucionando hacia enfoques modernizados.","children":[],"payload":{"lines":"65,67"}}],"payload":{"lines":"63,64"}},{"content":"<strong>Identificación del Marco Adecuado:</strong>","children":[{"content":"Buscar similitudes y distinciones mínimas entre marcos existentes.","children":[],"payload":{"lines":"68,69"}},{"content":"Seleccionar el marco que mejor se alinea con las necesidades propias y de las partes interesadas.","children":[],"payload":{"lines":"69,71"}}],"payload":{"lines":"67,68"}}],"payload":{"lines":"44,45"}},{"content":"<strong>Reflexión y Acción:</strong>","children":[{"content":"<strong>Notas:</strong>","children":[{"content":"Los marcos éticos son herramientas críticas para guiar comportamientos y decisiones responsables.","children":[],"payload":{"lines":"76,77"}},{"content":"La selección de un marco ético adecuado requiere una cuidadosa consideración de principios comunes y necesidades específicas.","children":[],"payload":{"lines":"77,78"}}],"payload":{"lines":"75,76"}}],"payload":{"lines":"71,72"}},{"content":"Declaración de Montreal para un Desarrollo Responsable de la Inteligencia Artificial","children":[{"content":"<strong>Objetivo de la Declaración</strong>: Guiar a individuos, organizaciones, empresas y gobiernos en decisiones éticas y responsables en IA.","children":[],"payload":{"lines":"83,84"}},{"content":"<strong>Inicio y Participación</strong>:","children":[{"content":"Iniciativa comenzada en noviembre de 2017 en la Universidad de Montreal.","children":[],"payload":{"lines":"86,87"}},{"content":"Publicada en diciembre de 2018 con la ayuda de más de 500 ciudadanos, expertos y partes interesadas.","children":[],"payload":{"lines":"87,89"}}],"payload":{"lines":"85,86"}},{"content":"<strong>Diez Principios Fundamentales</strong>:","children":[{"content":"<p data-lines=\"91,92\"><strong>Bienestar</strong>: Promover el crecimiento del bienestar de todos los seres sintientes.</p>","children":[],"payload":{"lines":"91,93"}},{"content":"<p data-lines=\"93,94\"><strong>Respeto de la Autonomía</strong>: Respetar y aumentar el control de las personas sobre sus vidas y su entorno.</p>","children":[],"payload":{"lines":"93,95"}},{"content":"<p data-lines=\"95,96\"><strong>Protección de la Intimidad y la Privacidad</strong>: Proteger la intimidad y la privacidad frente a IA y sistemas de adquisición de datos.</p>","children":[],"payload":{"lines":"95,97"}},{"content":"<p data-lines=\"97,98\"><strong>Solidaridad</strong>:  Mantener lazos de solidaridad humana y fomentar relaciones humanas.</p>","children":[],"payload":{"lines":"97,99"}},{"content":"<p data-lines=\"99,100\"><strong>Participación Democrática</strong>: Asegurar la transparencia, justificabilidad y accesibilidad; sujeto a control democrático.</p>","children":[],"payload":{"lines":"99,101"}},{"content":"<p data-lines=\"101,102\"><strong>Equidad</strong>: Contribuir a una sociedad justa y equitativa.</p>","children":[],"payload":{"lines":"101,103"}},{"content":"<p data-lines=\"103,104\"><strong>Diversidad e Inclusión</strong>: Promover la diversidad social y cultural; minimizar y eliminar sesgos.</p>","children":[],"payload":{"lines":"103,105"}},{"content":"<p data-lines=\"105,106\"><strong>Prudencia (Precaución)</strong>: Actuar con precaución anticipando y evitando posibles consecuencias adversas.</p>","children":[],"payload":{"lines":"105,107"}},{"content":"<p data-lines=\"107,108\"><strong>Responsabilidad</strong>: Asegurar que la IA no disminuya la responsabilidad humana; los humanos siempre son responsables.</p>","children":[],"payload":{"lines":"107,109"}},{"content":"<p data-lines=\"109,110\"><strong>Desarrollo Sostenible</strong>: Fomentar la sostenibilidad medioambiental.</p>","children":[],"payload":{"lines":"109,111"}}],"payload":{"lines":"89,90"}},{"content":"<strong>Comparación con Otros Marcos</strong>:","children":[{"content":"Similitudes con otros marcos en enfatizar transparencia, justicia, imparcialidad, responsabilidad, no maleficencia y privacidad.","children":[],"payload":{"lines":"112,114"}}],"payload":{"lines":"111,112"}}],"payload":{"lines":"81,82"}},{"content":"<strong>Diseño del Marco</strong>:","children":[{"content":"Diseñado para cualquier parte interesada en IA responsable.","children":[],"payload":{"lines":"115,116"}},{"content":"Incluye más de 85 marcos éticos distintos para IA, con principios fundamentales comunes.","children":[],"payload":{"lines":"116,117"}}],"payload":{"lines":"114,115"}},{"content":"Directrices Éticas para una IA Digna de Confianza","children":[{"content":"<strong>Origen y Desarrollo</strong>:","children":[{"content":"Iniciativa de la Comisión Europea en 2018.","children":[],"payload":{"lines":"124,125"}},{"content":"Consulta pública y piloto para recoger opiniones y mejorar el marco.","children":[],"payload":{"lines":"125,127"}}],"payload":{"lines":"123,124"}},{"content":"<strong>Objetivos Principales</strong>:","children":[{"content":"<strong>Legalidad</strong>: Cumplimiento con todas las leyes y reglamentos aplicables.","children":[],"payload":{"lines":"128,129"}},{"content":"<strong>Ética</strong>: Respeto a los principios éticos y valores humanos.","children":[],"payload":{"lines":"129,130"}},{"content":"<strong>Robustez</strong>: Solidez tecnológica, consideración del entorno social y desarrollo ecológico.","children":[],"payload":{"lines":"130,132"}}],"payload":{"lines":"127,128"}},{"content":"<strong>Importancia</strong>:","children":[{"content":"Garantizar un desarrollo de IA sostenible y beneficioso para todos.","children":[],"payload":{"lines":"133,134"}},{"content":"Fomentar un debate internacional y nacional sobre el desarrollo equitativo, inclusivo y ecológicamente sostenible de la IA.","children":[],"payload":{"lines":"134,136"}}],"payload":{"lines":"132,133"}},{"content":"<strong>Principios Fundamentales</strong>:","children":[{"content":"<strong>Agencia y Supervisión Humana</strong>: Importancia de la intervención y control humano.","children":[],"payload":{"lines":"137,138"}},{"content":"<strong>Solidez y Seguridad Tecnológica</strong>: Fiabilidad y seguridad en el diseño y operación de IA.","children":[],"payload":{"lines":"138,139"}},{"content":"<strong>Privacidad y Gobernanza de Datos</strong>: Protección de datos y privacidad de los usuarios.","children":[],"payload":{"lines":"139,140"}},{"content":"<strong>Transparencia</strong>: Comprensibilidad y accesibilidad de las tecnologías de IA.","children":[],"payload":{"lines":"140,141"}},{"content":"<strong>Diversidad, No Discriminación y Equidad</strong>: Promoción de la inclusión y equidad en el desarrollo y uso de IA.","children":[],"payload":{"lines":"141,142"}},{"content":"<strong>Bienestar Social y Medioambiental</strong>: Contribución positiva al bienestar social y sostenibilidad ambiental.","children":[],"payload":{"lines":"142,143"}},{"content":"<strong>Responsabilidad</strong>: Asegurar la responsabilidad y rendición de cuentas en el desarrollo y uso de IA.","children":[],"payload":{"lines":"143,145"}}],"payload":{"lines":"136,137"}},{"content":"<strong>Diferenciación con Otros Marcos</strong>:","children":[{"content":"Basado en derechos humanos y fundamentales, específico para la Unión Europea.","children":[],"payload":{"lines":"146,147"}},{"content":"Enfocado en un enfoque centrado en el ser humano informado por derechos humanos y fundamentales.","children":[],"payload":{"lines":"147,149"}}],"payload":{"lines":"145,146"}},{"content":"<strong>Consideraciones Especiales</strong>:","children":[{"content":"Alineado con la Carta de Derechos Fundamentales de la UE.","children":[],"payload":{"lines":"150,151"}},{"content":"Útil para individuos y empresas dentro de la UE.","children":[],"payload":{"lines":"151,153"}}],"payload":{"lines":"149,150"}},{"content":"<strong>Preguntas Clave para la Reflexión</strong>:","children":[{"content":"¿Las directrices cubren todos los aspectos necesarios para una IA ética y digna de confianza?","children":[],"payload":{"lines":"154,155"}},{"content":"¿Qué elementos podrían faltar o necesitar ampliación en estas directrices?","children":[],"payload":{"lines":"155,156"}}],"payload":{"lines":"153,154"}}],"payload":{"lines":"121,122"}},{"content":"Principios de la IA de Beijing","children":[{"content":"<strong>Origen y Propósito</strong>:","children":[{"content":"Desarrollado en Pekín, China, por la Academia de Inteligencia Artificial de Pekín en mayo de 2019.","children":[],"payload":{"lines":"163,164"}},{"content":"Objetivo: Asegurar que la IA respete y proteja la privacidad, dignidad y libertades humanas, y evitar daños a los seres humanos.","children":[],"payload":{"lines":"164,166"}}],"payload":{"lines":"162,163"}},{"content":"<strong>Estructura del Marco</strong>:","children":[{"content":"<p data-lines=\"167,168\"><strong>Investigación y Desarrollo (I+D) de IA</strong>:</p>","children":[{"content":"<strong>Hacer el bien</strong>: Beneficiar a la humanidad.","children":[],"payload":{"lines":"168,169"}},{"content":"<strong>Para la humanidad</strong>: Respetar valores humanos.","children":[],"payload":{"lines":"169,170"}},{"content":"<strong>Responsabilidad</strong>: Creación ética y responsable.","children":[],"payload":{"lines":"170,171"}},{"content":"<strong>Control de riesgo</strong>: Gestión de riesgos y fiabilidad.","children":[],"payload":{"lines":"171,172"}},{"content":"<strong>Ética</strong>: Fomento de la confianza.","children":[],"payload":{"lines":"172,173"}},{"content":"<strong>Diversidad e inclusión</strong>: Consideración de minorías y grupos desatendidos.","children":[],"payload":{"lines":"173,174"}},{"content":"<strong>Abierto y compartible</strong>: Democratización y accesibilidad de datos y desarrollos.","children":[],"payload":{"lines":"174,176"}}],"payload":{"lines":"167,176"}},{"content":"<p data-lines=\"176,177\"><strong>Principios para el Uso de la IA</strong>:</p>","children":[{"content":"<strong>Uso sabio y apropiado</strong>: Mitigación de mal uso.","children":[],"payload":{"lines":"177,178"}},{"content":"<strong>Consentimiento informado</strong>: Transparencia en el procesamiento de datos.","children":[],"payload":{"lines":"178,179"}},{"content":"<strong>Educación y formación</strong>: Comprensión amplia del funcionamiento de la IA.","children":[],"payload":{"lines":"179,181"}}],"payload":{"lines":"176,181"}},{"content":"<p data-lines=\"181,182\"><strong>Principios para la Gobernanza de la IA</strong>:</p>","children":[{"content":"<strong>Optimización del empleo</strong>: Adaptación laboral sin reemplazo humano.","children":[],"payload":{"lines":"182,183"}},{"content":"<strong>Armonía y cooperación</strong>: Interdisciplinariedad y colaboración.","children":[],"payload":{"lines":"183,184"}},{"content":"<strong>Adaptación y moderación</strong>: Evolución continua de normativas.","children":[],"payload":{"lines":"184,185"}},{"content":"<strong>Subdivisión e implementación</strong>: Normas específicas para subcampos de IA.","children":[],"payload":{"lines":"185,186"}},{"content":"<strong>Planificación a largo plazo</strong>: Preparación para avances futuros en IA.","children":[],"payload":{"lines":"186,188"}}],"payload":{"lines":"181,188"}}],"payload":{"lines":"166,167"}},{"content":"<strong>Aplicabilidad del Marco</strong>:","children":[{"content":"Dirigido a guiar la ética en I+D dentro de la inteligencia artificial.","children":[],"payload":{"lines":"189,190"}},{"content":"Enfoca en la importancia de compartir datos, inclusión, y un enfoque centrado en el ser humano.","children":[],"payload":{"lines":"190,192"}}],"payload":{"lines":"188,189"}},{"content":"<strong>Consideraciones para Reflexión</strong>:","children":[{"content":"Reflexionar sobre posibles omisiones o áreas que requieren expansión.","children":[],"payload":{"lines":"193,194"}},{"content":"Considerar cómo este marco se compara y complementa con otros marcos éticos en IA.","children":[],"payload":{"lines":"194,195"}}],"payload":{"lines":"192,193"}}],"payload":{"lines":"160,161"}},{"content":"Directrices Universales para la Inteligencia Artificial (UGIA)","children":[{"content":"<strong>Origen y Propósito</strong>:","children":[{"content":"Desarrollado por la coalición Public Voice en octubre de 2019, anunciado en 2018.","children":[],"payload":{"lines":"202,203"}},{"content":"Objetivo: Fomentar la transparencia y rendición de cuentas en sistemas de IA, asegurando que las personas mantengan control sobre la tecnología.","children":[],"payload":{"lines":"203,205"}}],"payload":{"lines":"201,202"}},{"content":"<strong>Características Clave</strong>:","children":[{"content":"<strong>Énfasis en Derechos Humanos</strong>: Protección y afirmación de derechos humanos para maximizar beneficios y minimizar riesgos de la IA.","children":[],"payload":{"lines":"206,207"}},{"content":"<strong>Asignación de Responsabilidad</strong>: La responsabilidad de los sistemas de IA recae en las instituciones que los financian, desarrollan y despliegan, una postura firme no común en otros marcos.","children":[],"payload":{"lines":"207,209"}}],"payload":{"lines":"205,206"}},{"content":"<strong>Contexto de Uso</strong>:","children":[{"content":"<strong>Incorporación en Leyes</strong>: Alentada para ser parte de normas éticas en leyes y acuerdos a nivel internacional y nacional.","children":[],"payload":{"lines":"210,211"}},{"content":"<strong>Diseño Ético de IA</strong>: Se enfoca en asegurar que la IA sea diseñada éticamente desde su concepción.","children":[],"payload":{"lines":"211,213"}}],"payload":{"lines":"209,210"}},{"content":"<strong>Comparación con Otros Marcos</strong>:","children":[{"content":"Toma principios de otros marcos reconocidos como el diseño éticamente alineado del IEEE y los principios de Asilomar.","children":[],"payload":{"lines":"214,215"}},{"content":"Se distingue por su enfoque en la asignación de responsabilidad y protección de derechos humanos.","children":[],"payload":{"lines":"215,217"}}],"payload":{"lines":"213,214"}},{"content":"<strong>Preguntas</strong>:","children":[{"content":"¿Son las UGIA verdaderamente universales?","children":[],"payload":{"lines":"218,219"}},{"content":"¿Cómo se podrían mejorar estas directrices para asegurar su aplicabilidad y efectividad universal?","children":[],"payload":{"lines":"219,220"}}],"payload":{"lines":"217,218"}}],"payload":{"lines":"199,200"}},{"content":"Los 10 Principios para una Inteligencia Artificial Ética por UNI Global Union","children":[{"content":"<strong>Contexto</strong>:","children":[{"content":"Creado por la UNI Global Union, con la intención de priorizar personas y planeta en la IA.","children":[],"payload":{"lines":"226,227"}},{"content":"Busca una convención global sobre IA ética.","children":[],"payload":{"lines":"227,229"}}],"payload":{"lines":"225,226"}},{"content":"<strong>Objetivos</strong>:","children":[{"content":"Salvaguardar los derechos de los trabajadores.","children":[],"payload":{"lines":"230,231"}},{"content":"Influenciar positivamente en la digitalización.","children":[],"payload":{"lines":"231,233"}}],"payload":{"lines":"229,230"}},{"content":"<strong>Los 10 Principios</strong>:","children":[{"content":"<p data-lines=\"234,235\"><strong>Transparencia</strong>: Entender cómo funcionan los sistemas de IA.</p>","children":[],"payload":{"lines":"234,236"}},{"content":"<p data-lines=\"236,237\"><strong>Caja Negra Ética</strong>: Registro de procesos de toma de decisiones de IA para revisión en caso de incidentes.</p>","children":[],"payload":{"lines":"236,238"}},{"content":"<p data-lines=\"238,239\"><strong>Servicio a Personas y Planeta</strong>: Priorizar el bienestar humano y ambiental.</p>","children":[],"payload":{"lines":"238,240"}},{"content":"<p data-lines=\"240,241\"><strong>Humanos al Mando</strong>: Mantener control humano sobre la IA, evitando la sustitución completa por máquinas.</p>","children":[],"payload":{"lines":"240,242"}},{"content":"<p data-lines=\"242,243\"><strong>IA sin Prejuicios ni Género</strong>: Prevenir la propagación de prejuicios raciales y de género.</p>","children":[],"payload":{"lines":"242,244"}},{"content":"<p data-lines=\"244,245\"><strong>Compartir Beneficios de la IA</strong>: Democratizar los beneficios de la IA para todos.</p>","children":[],"payload":{"lines":"244,246"}},{"content":"<p data-lines=\"246,247\"><strong>Transición Justa y Libertades Fundamentales</strong>: Facilitar la adaptación de los trabajadores desplazados por la IA.</p>","children":[],"payload":{"lines":"246,248"}},{"content":"<p data-lines=\"248,249\"><strong>Gobernanza Global</strong>: Establecer directrices globales y regionales para la gobernanza de la IA.</p>","children":[],"payload":{"lines":"248,250"}},{"content":"<p data-lines=\"250,251\"><strong>Atribución de Responsabilidad</strong>: Responsabilizar a los diseñadores, implementadores y usuarios de IA, no a los robots.</p>","children":[],"payload":{"lines":"250,252"}},{"content":"<p data-lines=\"252,253\"><strong>Prohibición de Carrera Armamentística de IA</strong>: Evitar la escalada de IA en aplicaciones militares.</p>","children":[],"payload":{"lines":"252,254"}}],"payload":{"lines":"233,234"}},{"content":"<strong>Aplicabilidad</strong>:","children":[{"content":"Relevante para trabajadores representados por sindicatos y empresas en proceso de digitalización.","children":[],"payload":{"lines":"255,256"}},{"content":"Especialmente útil para anticipar y prepararse para los cambios laborales por IA.","children":[],"payload":{"lines":"256,258"}}],"payload":{"lines":"254,255"}},{"content":"<strong>Comparación con Otros Marcos</strong>:","children":[{"content":"Similar énfasis en la transparencia y la responsabilidad humana.","children":[],"payload":{"lines":"259,260"}},{"content":"Único en su enfoque sindical y la protección de los derechos laborales frente a la digitalización.","children":[],"payload":{"lines":"260,262"}}],"payload":{"lines":"258,259"}},{"content":"<strong>Preguntas para Reflexión</strong>:","children":[{"content":"¿Están bien representados todos los aspectos de la IA ética en estos principios?","children":[],"payload":{"lines":"263,264"}},{"content":"¿Qué principios podrían añadirse o modificarse para una representación más completa?","children":[],"payload":{"lines":"264,265"}}],"payload":{"lines":"262,263"}}],"payload":{"lines":"223,224"}}],"payload":{"lines":"42,43"}},{"content":"Principios compartidos por los marcos eticos","children":[{"content":"Privacidad en Marcos Éticos de la IA","children":[{"content":"Importancia de la Privacidad","children":[{"content":"<strong>Privacidad como Fundamento:</strong> Considerada esencial en la mayoría de marcos éticos de IA, vista tanto como valor a defender como derecho a proteger.","children":[],"payload":{"lines":"273,274"}},{"content":"<strong>Incorporación en Marcos Éticos:</strong> Más del 50% de los aproximadamente 85 marcos éticos para IA priorizan la privacidad como principio clave.","children":[],"payload":{"lines":"274,275"}},{"content":"<strong>Razones Clave para la Importancia de la Privacidad:</strong>","children":[{"content":"Autonomía y libertad de elección.","children":[],"payload":{"lines":"276,277"}},{"content":"Protección contra el abuso de poder.","children":[],"payload":{"lines":"277,278"}},{"content":"Seguridad física.","children":[],"payload":{"lines":"278,279"}},{"content":"Base para la libertad y el libre albedrío.","children":[],"payload":{"lines":"279,281"}}],"payload":{"lines":"275,281"}}],"payload":{"lines":"272,273"}},{"content":"Implementación de la Privacidad en IA","children":[{"content":"<strong>Soluciones Técnicas:</strong> Implementación de privacidad diferencial, privacidad por diseño, y minimización de datos.","children":[],"payload":{"lines":"282,283"}},{"content":"<strong>Investigación, Conciencia, y Regulación:</strong> Fomento de la conciencia y la regulación por parte de organizaciones sin fines de lucro.","children":[],"payload":{"lines":"283,284"}},{"content":"<strong>Certificaciones:</strong> Desarrollo de certificaciones y regulaciones específicas para proteger la privacidad en el ámbito de la IA.","children":[],"payload":{"lines":"284,286"}}],"payload":{"lines":"281,282"}},{"content":"Reflexiones Finales","children":[{"content":"La privacidad es reconocida como un principio crucial en el desarrollo y aplicación de tecnologías basadas en IA debido a su vínculo intrínseco con la libertad individual y la protección contra abusos.","children":[],"payload":{"lines":"287,288"}},{"content":"Se plantea la cuestión de si la privacidad es tratada con la profundidad y seriedad necesarias en todos los marcos éticos existentes, y si hay margen de mejora en cómo se aborda y protege este principio.","children":[],"payload":{"lines":"288,289"}},{"content":"La inclusión de la privacidad como un componente central en los marcos éticos para la IA refleja su importancia universal, no solo en términos de protección de datos, sino como un pilar fundamental para una sociedad justa y libre.","children":[],"payload":{"lines":"289,290"}}],"payload":{"lines":"286,287"}}],"payload":{"lines":"270,271"}},{"content":"Responsabilidad en IA","children":[{"content":"Definición y Desafíos","children":[{"content":"<strong>\"IA Responsable\" No Definida Claramente:</strong> La responsabilidad y la rendición de cuentas en el contexto de la IA suelen mencionarse pero rara vez se definen con precisión.","children":[],"payload":{"lines":"297,298"}},{"content":"<strong>Importancia en Marcos Éticos:</strong> Más del 70% de los marcos éticos de IA enfatizan la importancia de la responsabilidad y la rendición de cuentas.","children":[],"payload":{"lines":"298,300"}}],"payload":{"lines":"296,297"}},{"content":"Principios Clave","children":[{"content":"<strong>Causalidad:</strong> Identificación de quién o qué causó un daño o error.","children":[],"payload":{"lines":"301,302"}},{"content":"<strong>Justicia:</strong> Determinación de quién merece ser castigado o retribuido.","children":[],"payload":{"lines":"302,303"}},{"content":"<strong>Reparación:</strong> Decisión sobre quién debe compensar los daños causados.","children":[],"payload":{"lines":"303,305"}}],"payload":{"lines":"300,301"}},{"content":"Desafío de la Brecha de Responsabilidad","children":[{"content":"<strong>Brecha de Responsabilidad:</strong> Dificultad para asignar responsabilidad cuando la IA falla debido a la complejidad de los sistemas y la intervención humana.","children":[],"payload":{"lines":"306,307"}},{"content":"<strong>Perspectivas Variadas:</strong> Algunos marcos sugieren que los humanos detrás de la IA deben ser responsables, mientras que otros proponen que la propia IA podría llevar alguna forma de responsabilidad legal.","children":[],"payload":{"lines":"307,309"}}],"payload":{"lines":"305,306"}},{"content":"Enfoques para la Protección de la Responsabilidad","children":[{"content":"<strong>Debate Abierto:</strong> La mayoría de los marcos éticos promueven el debate sobre quién debería ser responsable sin llegar a un consenso claro.","children":[],"payload":{"lines":"310,311"}},{"content":"<strong>Auditabilidad:</strong> Propone que la transparencia y la capacidad de auditoría de los sistemas de IA pueden ayudar a garantizar la responsabilidad.","children":[],"payload":{"lines":"311,313"}}],"payload":{"lines":"309,310"}},{"content":"Reflexiones","children":[{"content":"La responsabilidad y la rendición de cuentas en la IA son principios esenciales pero complicados por la falta de consenso sobre cómo implementarlos efectivamente.","children":[],"payload":{"lines":"314,315"}},{"content":"Es crucial continuar el diálogo y desarrollar normativas claras que asignen responsabilidad de manera justa y efectiva, teniendo en cuenta tanto a los desarrolladores de IA como a los sistemas de IA en sí.","children":[],"payload":{"lines":"315,316"}}],"payload":{"lines":"313,314"}}],"payload":{"lines":"294,295"}},{"content":"Transparencia y Explicabilidad en IA","children":[{"content":"Definición y Popularidad","children":[{"content":"<strong>Prevalencia:</strong> Citado en más del 85% de todos los marcos éticos, lo que lo convierte en el principio más popular.","children":[],"payload":{"lines":"323,324"}},{"content":"<strong>Transparencia:</strong> Implica usar un lenguaje claro para explicar cómo funcionan los sistemas de IA, incluyendo sus capacidades y el origen de los datos.","children":[],"payload":{"lines":"324,326"}}],"payload":{"lines":"322,323"}},{"content":"Subprincipios","children":[{"content":"<strong>Explicabilidad:</strong> La capacidad de describir los procesos internos de la IA en términos humanos.","children":[],"payload":{"lines":"327,328"}},{"content":"<strong>Interpretabilidad:</strong> La habilidad de entender y prever cómo la IA responde a diferentes situaciones o cambios.","children":[],"payload":{"lines":"328,329"}},{"content":"<strong>Auditabilidad:</strong> Verificar que los modelos son transparentes y explicables.","children":[],"payload":{"lines":"329,331"}}],"payload":{"lines":"326,327"}},{"content":"Importancia","children":[{"content":"<strong>Facilita la Comprensión:</strong> Permite a todos entender qué hace la IA.","children":[],"payload":{"lines":"332,333"}},{"content":"<strong>Mitiga Problemas:</strong> Ayuda a reducir problemas relacionados con la equidad, la discriminación, y la desconfianza.","children":[],"payload":{"lines":"333,335"}}],"payload":{"lines":"331,332"}},{"content":"Estrategias de Implementación","children":[{"content":"<strong>Integración en Marcos Éticos:</strong> Incluir la transparencia y la explicabilidad como principios clave.","children":[],"payload":{"lines":"336,337"}},{"content":"<strong>Diferenciación de Explicabilidad e Interpretabilidad:</strong> Reconocer y aplicar sus diferencias en el diseño y la evaluación de sistemas de IA.","children":[],"payload":{"lines":"337,339"}}],"payload":{"lines":"335,336"}},{"content":"Desafíos y Soluciones","children":[{"content":"<strong>Problema de la Caja Negra:</strong> La IA a menudo opera de manera opaca, dificultando la comprensión de su funcionamiento interno.","children":[],"payload":{"lines":"340,341"}},{"content":"<strong>Necesidad de Transparencia:</strong> La transparencia permite verificar la justicia, reducir el fraude, y educar al público.","children":[],"payload":{"lines":"341,343"}}],"payload":{"lines":"339,340"}},{"content":"Reflexiones","children":[{"content":"<strong>Transparencia vs. Capacidad Predictiva:</strong> La discrepancia entre decisiones de IA y humanas resalta la importancia de la transparencia.","children":[],"payload":{"lines":"344,345"}},{"content":"<strong>Transparencia como Fundamento:</strong> Considerada esencial para el desarrollo ético y responsable de la IA.","children":[],"payload":{"lines":"345,346"}}],"payload":{"lines":"343,344"}}],"payload":{"lines":"320,321"}},{"content":"Equidad y No Discriminación en IA","children":[{"content":"Prevalencia","children":[{"content":"<strong>Importancia:</strong> Segundo principio más citado después de la transparencia en marcos éticos de IA.","children":[],"payload":{"lines":"353,354"}},{"content":"<strong>Inclusión:</strong> Presente en casi todos los marcos éticos significativos.","children":[],"payload":{"lines":"354,356"}}],"payload":{"lines":"352,353"}},{"content":"Definiciones y Dificultades","children":[{"content":"<strong>Definición de Equidad:</strong> No universal, altamente contextual. Varía según el contexto y la aplicación.","children":[],"payload":{"lines":"357,358"}},{"content":"<strong>Algoritmo Justo:</strong> Produce resultados independientes de características protegidas (género, etnia, orientación sexual).","children":[],"payload":{"lines":"358,360"}}],"payload":{"lines":"356,357"}},{"content":"Dos Perspectivas de Equidad","children":[{"content":"<strong>Resultados Independientes:</strong> Fairness como independencia de características protegidas.","children":[],"payload":{"lines":"361,362"}},{"content":"<strong>Igualdad de Acceso:</strong> Acceso equitativo a datos, IA y beneficios tecnológicos.","children":[],"payload":{"lines":"362,364"}}],"payload":{"lines":"360,361"}},{"content":"Relación con No Discriminación","children":[{"content":"<strong>Conexión:</strong> La equidad está intrínsecamente ligada a la no discriminación para prevenir sesgos y asegurar un trato igualitario.","children":[],"payload":{"lines":"365,367"}}],"payload":{"lines":"364,365"}},{"content":"Valor para la Industria","children":[{"content":"<strong>Beneficio Económico:</strong> Mejorar la equidad y prevenir la discriminación puede representar un valor de hasta 500 mil millones de dólares para la industria tecnológica.","children":[],"payload":{"lines":"368,370"}}],"payload":{"lines":"367,368"}},{"content":"Construcción de Sistemas de IA Éticos","children":[{"content":"<strong>Prevención de Prejuicios:</strong> Esencial para no reforzar ni crear prejuicios, especialmente en relación con características protegidas.","children":[],"payload":{"lines":"371,372"}},{"content":"<strong>Referencia en Marcos:</strong> Los marcos éticos enfatizan la prevención, el seguimiento y la mitigación de sesgos y discriminación.","children":[],"payload":{"lines":"372,374"}}],"payload":{"lines":"370,371"}},{"content":"Implicaciones","children":[{"content":"La equidad y la no discriminación son fundamentales para el desarrollo ético de la IA, abordando tanto la prevención de sesgos existentes como la creación de nuevos.","children":[],"payload":{"lines":"375,376"}},{"content":"La atención a estos principios no solo es un imperativo moral sino también una oportunidad económica significativa para la industria.","children":[],"payload":{"lines":"376,377"}}],"payload":{"lines":"374,375"}}],"payload":{"lines":"350,351"}},{"content":"Seguridad y Protección en IA","children":[{"content":"Concepto Principal","children":[{"content":"<strong>No Maleficencia:</strong> Inspirado en la bioética, significa no hacer daño previsible o intencionado contra los seres humanos. Interpretado como prevención de discriminación, violaciones de privacidad, y lesiones corporales.","children":[],"payload":{"lines":"384,386"}}],"payload":{"lines":"383,384"}},{"content":"Relación con Otros Principios","children":[{"content":"<strong>Dependencia de Principios:</strong> Para lograr seguridad y protección, es necesaria la explicabilidad y la transparencia, lo que permite comprender el funcionamiento de la IA y abordar fallas potenciales.","children":[],"payload":{"lines":"387,389"}}],"payload":{"lines":"386,387"}},{"content":"Prevalencia en Marcos Éticos","children":[{"content":"<strong>Inclusión en Marcos:</strong> Más del 70% de los marcos éticos para IA incluyen el principio de no maleficencia o seguridad y protección como fundamental.","children":[],"payload":{"lines":"390,392"}}],"payload":{"lines":"389,390"}},{"content":"Importancia","children":[{"content":"<strong>Objetivo:</strong> Asegurar que los sistemas de IA operen de manera segura y protegida antes de su uso generalizado.","children":[],"payload":{"lines":"393,394"}},{"content":"<strong>Razonamiento:</strong> La IA no debería causar daño previsible; si ocurre, deben tomarse medidas para mitigarlo.","children":[],"payload":{"lines":"394,396"}}],"payload":{"lines":"392,393"}},{"content":"Vinculación con Otros Conceptos","children":[{"content":"<strong>Relación con Privacidad y Seguridad:</strong> Este principio se vincula con la privacidad y la seguridad para garantizar la protección de datos de los usuarios.","children":[],"payload":{"lines":"397,399"}}],"payload":{"lines":"396,397"}},{"content":"Implementación en Marcos","children":[{"content":"<strong>Enfoque:</strong> No existe una manera estandarizada; se fomenta el cumplimiento de nuevas legislaciones y procesos de supervisión, incluidas auditorías y evaluaciones.","children":[],"payload":{"lines":"400,401"}},{"content":"<strong>Soluciones Técnicas:</strong> Como la privacidad diferencial, para asegurar la protección de datos del usuario final.","children":[],"payload":{"lines":"401,403"}}],"payload":{"lines":"399,400"}},{"content":"Discusión","children":[{"content":"<strong>Relevancia de la No Maleficencia:</strong> Se discute la importancia de tener tecnología que esté garantizada para no causar daños, vinculada estrechamente a la confiabilidad y confianza en la tecnología de IA.","children":[],"payload":{"lines":"404,405"}}],"payload":{"lines":"403,404"}}],"payload":{"lines":"381,382"}},{"content":"Control Humano de la Tecnología en IA","children":[{"content":"Concepto Principal","children":[{"content":"<strong>Control Humano Significativo:</strong> Enfatiza la importancia de mantener una supervisión y participación humanas auténticas y conscientes en el funcionamiento de las tecnologías autónomas, especialmente armas autónomas.","children":[],"payload":{"lines":"412,414"}}],"payload":{"lines":"411,412"}},{"content":"Premisas Básicas","children":[{"content":"<strong>Autonomía de Máquinas:</strong> Generalmente se considera problemático permitir que armas o máquinas operen sin supervisión humana.","children":[],"payload":{"lines":"415,416"}},{"content":"<strong>Inadecuación del Control Superficial:</strong> La acción de simplemente pulsar un botón bajo la instrucción de un ordenador, sin entender realmente la acción, es insuficiente para constituir un control humano significativo.","children":[],"payload":{"lines":"416,418"}}],"payload":{"lines":"414,415"}},{"content":"Relación con Otros Principios Éticos","children":[{"content":"<strong>Transparencia y Explicabilidad:</strong> Son esenciales para el control humano significativo, permitiendo la comprensión humana completa de lo que hace la tecnología y cómo funciona.","children":[],"payload":{"lines":"419,421"}}],"payload":{"lines":"418,419"}},{"content":"Discusión en Marcos Éticos","children":[{"content":"Aunque el control humano significativo es un tema crucial, muchos marcos éticos se enfocan más en principios relacionados (como la transparencia) que en definir o discutir explícitamente el control humano.","children":[],"payload":{"lines":"422,424"}}],"payload":{"lines":"421,422"}},{"content":"Importancia","children":[{"content":"<strong>Base de Debates Éticos:</strong> El debate sobre la transparencia y la fiabilidad gira en torno a la idea de mantener el control humano sobre la tecnología, asegurando que los humanos entiendan y puedan intervenir en las operaciones de IA.","children":[],"payload":{"lines":"425,427"}}],"payload":{"lines":"424,425"}},{"content":"Reflexión","children":[{"content":"<strong>Falta de Definición Explícita:</strong> A pesar de su importancia, el control humano no está claramente definido en muchos marcos éticos, lo que plantea preguntas sobre cómo y por qué debería integrarse más formalmente en futuras discusiones y marcos éticos.","children":[],"payload":{"lines":"428,429"}}],"payload":{"lines":"427,428"}}],"payload":{"lines":"409,410"}},{"content":"Responsabilidad Profesional en IA","children":[{"content":"Concepto Principal","children":[{"content":"<strong>Responsabilidad Profesional:</strong> Evalúa el impacto de la IA en la autonomía y capacidad de los profesionales. Cuestiona si la IA debe amplificar o reemplazar la inteligencia y habilidades profesionales.","children":[],"payload":{"lines":"435,437"}}],"payload":{"lines":"434,435"}},{"content":"Discusión en Marcos Éticos","children":[{"content":"Mayormente ausente en los marcos éticos populares, excepto una mención breve en el Diseño Éticamente Alineado del IEEE.","children":[],"payload":{"lines":"438,439"}},{"content":"<strong>Diseño Éticamente Alineado del IEEE:</strong> Toca brevemente el tema en relación con la ética clásica.","children":[],"payload":{"lines":"439,441"}}],"payload":{"lines":"437,438"}},{"content":"Cuestionamiento Clave","children":[{"content":"¿La IA <strong>aumenta</strong> o <strong>reemplaza</strong> la inteligencia de los profesionales?","children":[],"payload":{"lines":"442,444"}}],"payload":{"lines":"441,442"}},{"content":"Caso de Estudio: Asociación Médica Americana (AMA)","children":[{"content":"Define la IA como <strong>Inteligencia Aumentada</strong>, promoviendo el concepto de que la IA debe potenciar y no sustituir a los médicos.","children":[],"payload":{"lines":"445,446"}},{"content":"Enfatiza el uso de la IA para mejorar la pericia médica en lugar de reemplazar la toma de decisiones humana.","children":[],"payload":{"lines":"446,448"}}],"payload":{"lines":"444,445"}},{"content":"Dilema Fundamental","children":[{"content":"Difícil diferenciar entre <strong>potenciar</strong> la capacidad profesional versus <strong>reemplazar</strong> la inteligencia y autonomía profesional.","children":[],"payload":{"lines":"449,450"}},{"content":"Importante para futuros marcos éticos considerar cómo definir y orientar el uso de la IA en contextos profesionales.","children":[],"payload":{"lines":"450,452"}}],"payload":{"lines":"448,449"}},{"content":"Reflexión y Perspectiva Futura","children":[{"content":"Los futuros marcos éticos pueden inspirarse en la definición de IA de la AMA como un modelo para equilibrar la mejora contra el reemplazo en el uso profesional de la IA.","children":[],"payload":{"lines":"453,454"}},{"content":"<strong>Importancia de Definir:</strong> La manera en que se define la IA puede influir significativamente en su aceptación y aplicación dentro de las prácticas profesionales.","children":[],"payload":{"lines":"454,456"}}],"payload":{"lines":"452,453"}},{"content":"Preguntas","children":[{"content":"<strong>¿Por qué la responsabilidad profesional no se discute ampliamente en los marcos éticos actuales?</strong>","children":[],"payload":{"lines":"457,458"}},{"content":"<strong>¿Debería la responsabilidad profesional ser un principio más destacado en los marcos éticos de IA?</strong>","children":[],"payload":{"lines":"458,459"}}],"payload":{"lines":"456,457"}}],"payload":{"lines":"432,433"}},{"content":"Resumen Esquemático sobre la Promoción de los Valores Humanos en la IA","children":[{"content":"Concepto Principal","children":[{"content":"<strong>Promoción de los Valores Humanos:</strong> Considerado un \"metaprincipio\" en el desarrollo y la implementación de tecnologías de IA, enfatiza que la IA debe incorporar y reflejar valores humanos fundamentales.","children":[],"payload":{"lines":"465,467"}}],"payload":{"lines":"464,465"}},{"content":"Contexto General","children":[{"content":"Tradicionalmente, la tecnología se adaptaba a las normas sociales. Sin embargo, la evolución rápida de las tecnologías autónomas ha invertido esta tendencia, requiriendo un diseño ético desde el inicio.","children":[],"payload":{"lines":"468,469"}},{"content":"Los avances en IA obligan a poner los valores humanos al centro del desarrollo tecnológico para asegurar beneficios a la humanidad y minimizar posibles daños.","children":[],"payload":{"lines":"469,471"}}],"payload":{"lines":"467,468"}},{"content":"Importancia del Metaprincipio","children":[{"content":"Subraya que todos los marcos éticos para la IA deben ser diseñados con una orientación centrada en el ser humano, asegurando que la tecnología sirva al bienestar humano y evite causar daño.","children":[],"payload":{"lines":"472,474"}}],"payload":{"lines":"471,472"}},{"content":"Relación con Otros Principios","children":[{"content":"La promoción de valores humanos actúa como la base de otros principios discutidos en marcos éticos, incluyendo transparencia, privacidad, responsabilidad, y equidad.","children":[],"payload":{"lines":"475,477"}}],"payload":{"lines":"474,475"}},{"content":"Cuestionamientos Críticos","children":[{"content":"<strong>¿Por qué es fundamental este enfoque?</strong> Refleja una preferencia por garantizar que la IA beneficie y no perjudique a los seres humanos.","children":[],"payload":{"lines":"478,479"}},{"content":"<strong>¿Es especista?</strong> Algunos podrían argumentar que se centra excesivamente en el ser humano, excluyendo consideraciones hacia otras formas de vida o entidades autónomas potenciales.","children":[],"payload":{"lines":"479,481"}}],"payload":{"lines":"477,478"}},{"content":"Perspectivas Futuras","children":[{"content":"A medida que la IA avanza hacia la inteligencia general artificial (AGI), surgen preguntas sobre la autonomía de la IA y su posible consideración moral.","children":[],"payload":{"lines":"482,484"}}],"payload":{"lines":"481,482"}},{"content":"Reflexiones","children":[{"content":"La discusión sobre la promoción de valores humanos en la IA invita a reflexionar sobre cómo la tecnología puede y debe incorporar principios éticos que reflejen y respeten la dignidad y los derechos humanos,<br>\nanticipando el impacto futuro en la sociedad y las posibles entidades de IA con autonomía.","children":[],"payload":{"lines":"485,487"}}],"payload":{"lines":"484,485"}}],"payload":{"lines":"462,463"}}],"payload":{"lines":"268,269"}}],"payload":{"lines":"1,2"}},{"colorFreezeLevel":3})</script>
</body>
</html>
