<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.16.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:H,mm:ae}=window,W=new H.Toolbar;W.attach(ae);const we=W.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((o,T,c,r)=>{const g=o();window.mm=g.Markmap.create("svg#mindmap",(T||g.deriveOptions)(r),c)})(()=>window.markmap,null,{"content":"Aplicar marcos eticos a dilemas eticamente desafiantes","children":[{"content":"General","children":[{"content":"Convertir Principios Éticos en Acción","children":[{"content":"Escenarios a Cubrir","children":[{"content":"<strong>Problema del Trolebús y Coches Autónomos:</strong> Decisiones sobre quién salvar en situaciones de vida o muerte.","children":[],"payload":{"lines":"7,8"}},{"content":"<strong>Emergencias y Desastres:</strong> Priorización y toma de decisiones críticas basadas en marcos éticos.","children":[],"payload":{"lines":"8,9"}},{"content":"<strong>Confidencialidad del Paciente en Salud:</strong> Navegación por las leyes de privacidad como HIPAA y su relación con la ética.","children":[],"payload":{"lines":"9,10"}},{"content":"<strong>Cuestiones Sociales y Acoso por IA:</strong> Abordaje del potencial de daño social y acoso por sistemas de IA.","children":[],"payload":{"lines":"10,12"}}],"payload":{"lines":"6,7"}},{"content":"Importancia de la Selección de Marcos","children":[{"content":"Existen más de 85 marcos éticos, cada uno con un enfoque y audiencia específicos (por ejemplo, algunos están dirigidos a gobiernos, otros a individuos).","children":[],"payload":{"lines":"13,14"}}],"payload":{"lines":"12,13"}}],"payload":{"lines":"4,5"}}],"payload":{"lines":"2,3"}},{"content":"Aplicacion del marco a dilemas eticos","children":[{"content":"Aplicación de Marcos Éticos al Problema del Trolebús","children":[{"content":"Introducción al Dilema del Trolebús","children":[{"content":"<strong>Situación:</strong> Trolebús desbocado se dirige hacia un grupo de personas atadas a las vías.","children":[],"payload":{"lines":"21,22"}},{"content":"<strong>Opciones:</strong>","children":[{"content":"No hacer nada: el trolebús mata al grupo.","children":[],"payload":{"lines":"23,24"}},{"content":"Tirar de una palanca: desviar el trolebús, matar a una persona en vías adyacentes.","children":[],"payload":{"lines":"24,25"}}],"payload":{"lines":"22,25"}},{"content":"<strong>Dilema Ético:</strong> ¿Cuál es la acción más ética?","children":[],"payload":{"lines":"25,27"}}],"payload":{"lines":"20,21"}},{"content":"Enfoque Utilitarista","children":[{"content":"<strong>Acción Preferida:</strong> Tirar de la palanca para salvar al mayor número de personas.","children":[],"payload":{"lines":"28,29"}},{"content":"<strong>Consideraciones:</strong>","children":[{"content":"Participación directa en la muerte de una persona.","children":[],"payload":{"lines":"30,31"}},{"content":"Debate sobre la responsabilidad moral por acción vs. inacción.","children":[],"payload":{"lines":"31,33"}}],"payload":{"lines":"29,33"}}],"payload":{"lines":"27,28"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"34,35\"><strong>Declaración de Montreal para una IA Responsable (MDRAI):</strong></p>","children":[{"content":"<strong>Énfasis en:</strong> Autonomía humana, consideración de todos los seres sintientes, responsabilidad en la acción e inacción.","children":[],"payload":{"lines":"35,36"}},{"content":"<strong>Ventajas:</strong> Inclusión holística y énfasis en la responsabilidad.","children":[],"payload":{"lines":"36,37"}},{"content":"<strong>Desafíos:</strong> Aplicabilidad limitada a escenarios específicos de IA.","children":[],"payload":{"lines":"37,39"}}],"payload":{"lines":"34,39"}},{"content":"<p data-lines=\"39,40\"><strong>Principios de IA de Asilomar:</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Seguridad, alineación de valores, transparencia de fallos.","children":[],"payload":{"lines":"40,41"}},{"content":"<strong>Ventajas:</strong> Fomenta la preparación y conciencia sobre fallos de IA y decisiones seguras.","children":[],"payload":{"lines":"41,42"}},{"content":"<strong>Desafíos:</strong> Aplicación genérica que podría adaptarse a conveniencia del decisor.","children":[],"payload":{"lines":"42,44"}}],"payload":{"lines":"39,44"}}],"payload":{"lines":"33,34"}},{"content":"Conclusión","children":[{"content":"<strong>Importancia de Principios Rectores:</strong> Ayudan a definir y guiar prácticas éticas en situaciones complejas.","children":[],"payload":{"lines":"45,46"}},{"content":"<strong>Relevancia de Marcos Éticos:</strong> Ambos marcos proporcionan perspectivas útiles pero difieren en aplicación y énfasis en la responsabilidad y transparencia.","children":[],"payload":{"lines":"46,47"}}],"payload":{"lines":"44,45"}}],"payload":{"lines":"18,19"}},{"content":"Resumen Esquemático: Uso de IA en Emergencias y Catástrofes","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Despliegue de tecnología de rastreo de contactos durante una pandemia para afinar la respuesta de salud pública.","children":[],"payload":{"lines":"53,54"}},{"content":"<strong>Dilema:</strong> Equilibrio entre seguridad pública y privacidad individual.","children":[],"payload":{"lines":"54,56"}}],"payload":{"lines":"52,53"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"58,59\"><strong>Directrices Universales para la IA (UGAI)</strong></p>","children":[{"content":"<strong>Enfoque en:</strong> Seguridad pública y responsabilidad.","children":[],"payload":{"lines":"59,60"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Énfasis en mejorar la seguridad pública.","children":[],"payload":{"lines":"61,62"}},{"content":"Cláusula de terminación para uso limitado y específico.","children":[],"payload":{"lines":"62,63"}}],"payload":{"lines":"60,63"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de concreción en la aplicación de principios.","children":[],"payload":{"lines":"64,65"}},{"content":"Amplio margen para interpretación.","children":[],"payload":{"lines":"65,67"}}],"payload":{"lines":"63,67"}}],"payload":{"lines":"58,67"}},{"content":"<p data-lines=\"67,68\"><strong>Declaración de Toronto (DT)</strong></p>","children":[{"content":"<strong>Enfoque en:</strong> No discriminación y derechos humanos internacionales.","children":[],"payload":{"lines":"68,69"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aplicabilidad universal y aceptación transfronteriza.","children":[],"payload":{"lines":"70,71"}},{"content":"Basado en principios de derechos humanos.","children":[],"payload":{"lines":"71,72"}}],"payload":{"lines":"69,72"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de orientación sólida sobre privacidad.","children":[],"payload":{"lines":"73,74"}},{"content":"Posible insuficiencia en abordar todas las preocupaciones éticas.","children":[],"payload":{"lines":"74,76"}}],"payload":{"lines":"72,76"}}],"payload":{"lines":"67,76"}}],"payload":{"lines":"56,57"}},{"content":"Discusión","children":[{"content":"<strong>UGAI:</strong> Proporciona una orientación ética clara para el rastreo de contactos con énfasis en la responsabilidad<br>\ny seguridad pública, destacando una cláusula de terminación para evitar el abuso o uso prolongado indebido del sistema.","children":[],"payload":{"lines":"77,79"}},{"content":"<strong>DT:</strong> Centra en los derechos humanos y la no discriminación, ofreciendo un marco ético para equilibrar las necesidades de salud pública<br>\ncon la protección de la privacidad y los derechos individuales.","children":[],"payload":{"lines":"79,82"}}],"payload":{"lines":"76,77"}},{"content":"Conclusión","children":[{"content":"Ambos marcos ofrecen perspectivas valiosas para abordar el uso de la IA en situaciones de emergencia,<br>\nresaltando la importancia de mantener un equilibrio entre la seguridad pública y la protección de la privacidad y los derechos humanos.<br>\nLa elección del marco adecuado depende de las prioridades específicas y el contexto de la situación.","children":[],"payload":{"lines":"83,86"}}],"payload":{"lines":"82,83"}}],"payload":{"lines":"50,51"}},{"content":"IA en Medicina - Sesgo vs. Humanos","children":[{"content":"Contexto","children":[{"content":"<strong>Área de Aplicación:</strong> Radiología y lectura de escáneres de imágenes médicas.","children":[],"payload":{"lines":"92,93"}},{"content":"<strong>Dilema:</strong> Sistemas de IA muestran mayor precisión que paneles médicos humanos pero carecen de capacidad explicativa.","children":[],"payload":{"lines":"93,95"}}],"payload":{"lines":"91,92"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"97,98\"><strong>Declaración de Montreal para una IA Responsable (MDR)</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Prudencia, Autonomía Humana, Responsabilidad.","children":[],"payload":{"lines":"98,99"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Anticipa consecuencias negativas y asegura coherencia con decisiones humanas.","children":[],"payload":{"lines":"100,101"}},{"content":"Fomenta el control humano significativo e impulsa la confianza.","children":[],"payload":{"lines":"101,102"}}],"payload":{"lines":"99,102"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Margen de interpretación puede llevar a aplicaciones inconsistentes.","children":[],"payload":{"lines":"103,104"}},{"content":"Necesita respaldo de instrumentos regulatorios.","children":[],"payload":{"lines":"104,106"}}],"payload":{"lines":"102,106"}}],"payload":{"lines":"97,106"}},{"content":"<p data-lines=\"106,107\"><strong>Principios de la IA de Pekín</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Consentimiento Informado, Formación Educativa.","children":[],"payload":{"lines":"107,108"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Promueve comprensión de riesgos por parte del paciente.","children":[],"payload":{"lines":"109,110"}},{"content":"Prepara a médicos para manejar fallos del sistema y comunicar riesgos.","children":[],"payload":{"lines":"110,111"}}],"payload":{"lines":"108,111"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de detalles sobre la implementación práctica de principios.","children":[],"payload":{"lines":"112,113"}},{"content":"Cuestiones sobre la suficiencia de la formación educativa y el consentimiento informado.","children":[],"payload":{"lines":"113,115"}}],"payload":{"lines":"111,115"}}],"payload":{"lines":"106,115"}}],"payload":{"lines":"95,96"}},{"content":"Comparación y Conclusión","children":[{"content":"<strong>MDR vs. Principios de Pekín:</strong> Ambos marcos ofrecen perspectivas útiles para abordar el dilema ético, centrando la atención en la prudencia, la autonomía, la responsabilidad, y el consentimiento informado como fundamentos para el uso ético de IA en la medicina.","children":[],"payload":{"lines":"117,118"}},{"content":"<strong>Eficacia:</strong> MDR proporciona un enfoque holístico que abarca la confianza y los valores de la organización, mientras que los Principios de Pekín se centran en el consentimiento y la preparación del paciente y el profesional médico.","children":[],"payload":{"lines":"118,119"}},{"content":"<strong>Implementación:</strong> Ambos marcos enfrentan desafíos en la aplicación práctica, necesitando claridad y apoyo regulatorio para garantizar su efectividad.","children":[],"payload":{"lines":"119,120"}}],"payload":{"lines":"115,116"}}],"payload":{"lines":"89,90"}},{"content":"IA y Comportamientos Autodestructivos","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de IA en redes sociales que promueve comportamientos adictivos a través del desplazamiento interminable y contenidos hiper personalizados.","children":[],"payload":{"lines":"126,127"}},{"content":"<strong>Dilema:</strong> Balance entre maximizar beneficios empresariales y preservar el bienestar de los usuarios.","children":[],"payload":{"lines":"127,129"}}],"payload":{"lines":"125,126"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"131,132\"><strong>Directrices Universales para la IA (UGAI)</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Calidad de Datos, Prohibición de Perfiles Secretos, Seguridad Pública.","children":[],"payload":{"lines":"132,133"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Cobertura amplia de preocupaciones éticas.","children":[],"payload":{"lines":"134,135"}},{"content":"Orienta hacia el beneficio de los usuarios.","children":[],"payload":{"lines":"135,136"}}],"payload":{"lines":"133,136"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de directrices concretas para la implementación.","children":[],"payload":{"lines":"137,139"}}],"payload":{"lines":"136,139"}}],"payload":{"lines":"131,139"}},{"content":"<p data-lines=\"139,140\"><strong>Principios de la IA de Pekín</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Consentimiento Informado, Ética por Diseño.","children":[],"payload":{"lines":"140,141"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Promueve consideraciones éticas desde el desarrollo inicial.","children":[],"payload":{"lines":"142,143"}},{"content":"Prevención de interfaces adictivas y sistemas de recompensa perjudiciales.","children":[],"payload":{"lines":"143,144"}}],"payload":{"lines":"141,144"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Margen de interpretación amplio.","children":[],"payload":{"lines":"145,146"}},{"content":"Falta de especificidad en la implementación.","children":[],"payload":{"lines":"146,148"}}],"payload":{"lines":"144,148"}}],"payload":{"lines":"139,148"}}],"payload":{"lines":"129,130"}},{"content":"Comparación y Conclusión","children":[{"content":"<strong>UGAI</strong> enfatiza en el uso adecuado de datos y el impacto social, proporcionando un marco para equilibrar la ganancia empresarial<br>\ncon el bienestar de los usuarios. Sin embargo, carece de pautas detalladas para la práctica.","children":[],"payload":{"lines":"150,152"}},{"content":"<strong>Principios de Pekín</strong> se centran en el consentimiento informado y la inclusión de consideraciones éticas en el diseño,<br>\napoyando el desarrollo de sistemas menos perjudiciales desde el inicio. No obstante, la vaguedad en la aplicación práctica podría limitar su efectividad.","children":[],"payload":{"lines":"152,154"}},{"content":"<strong>Enfoque Recomendado:</strong> La combinación de ambos marcos puede ofrecer un enfoque equilibrado, asegurando tanto la responsabilidad<br>\nen el uso de datos como la incorporación de ética en el diseño y desarrollo de IA, para mitigar comportamientos autodestructivos entre los usuarios.","children":[],"payload":{"lines":"154,156"}}],"payload":{"lines":"148,149"}}],"payload":{"lines":"123,124"}},{"content":"Límites de la Tecnología Persuasiva en Juguetes Inteligentes","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de IA en juguetes inteligentes para influir en comportamientos de menores, como persuadirlos para que deseen ciertas marcas.","children":[],"payload":{"lines":"162,163"}},{"content":"<strong>Preocupación:</strong> Tecnología altamente persuasiva dirigida a un público vulnerable (niños).","children":[],"payload":{"lines":"163,165"}}],"payload":{"lines":"161,162"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"167,168\"><strong>Principios de la IA de la OCDE</strong></p>","children":[{"content":"<strong>Enfoque:</strong> Divulgación responsable, transparencia, privacidad, bienestar.","children":[],"payload":{"lines":"168,169"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Equilibrio entre divulgación responsable y bienestar.","children":[],"payload":{"lines":"170,171"}},{"content":"Alineación con entornos legales y regulatorios.","children":[],"payload":{"lines":"171,172"}}],"payload":{"lines":"169,172"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Carácter normativo sin casos de uso demostrados.","children":[],"payload":{"lines":"173,175"}}],"payload":{"lines":"172,175"}}],"payload":{"lines":"167,175"}},{"content":"<p data-lines=\"175,176\"><strong>Directrices Éticas sobre IA no Confiable</strong></p>","children":[{"content":"<strong>Enfoque:</strong> Respeto a la autonomía humana, privacidad, gobernanza de datos, bienestar.","children":[],"payload":{"lines":"176,177"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Orientación granular con casos de uso efectivos.","children":[],"payload":{"lines":"178,179"}},{"content":"Proximidad a requisitos legales y regulatorios.","children":[],"payload":{"lines":"179,180"}}],"payload":{"lines":"177,180"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Perspectiva enfocada en la legislación de la UE, puede requerir adaptación fuera de Europa.","children":[],"payload":{"lines":"181,183"}}],"payload":{"lines":"180,183"}}],"payload":{"lines":"175,183"}}],"payload":{"lines":"165,166"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>OCDE vs. Directrices Éticas no Confiables:</strong> Los principios de la OCDE proporcionan un marco general para el desarrollo ético,<br>\nmientras que las Directrices Éticas ofrecen una orientación más detallada y pragmática, especialmente en lo que respecta a la autonomía y seguridad de los menores.","children":[],"payload":{"lines":"185,187"}},{"content":"<strong>Impacto en el Desarrollo de Productos:</strong> Ambos marcos buscan guiar la creación de productos que respeten la autonomía de los usuarios<br>\ny promuevan su bienestar, aunque desde diferentes niveles de detalle y aplicabilidad geográfica.","children":[],"payload":{"lines":"187,190"}}],"payload":{"lines":"183,184"}},{"content":"Conclusión","children":[{"content":"<strong>Equilibrio Ético:</strong> Es crucial equilibrar la innovación tecnológica con la protección de los usuarios vulnerables,<br>\nasegurando que la tecnología persuasiva no comprometa el bienestar ni la autonomía de los niños.","children":[],"payload":{"lines":"192,194"}},{"content":"<strong>Elección de Marco:</strong> Dependerá de las necesidades específicas de la organización y el contexto jurisdiccional en el que opere,<br>\naunque la tendencia es hacia una aplicación ética granular y basada en casos de uso demostrados.","children":[],"payload":{"lines":"194,196"}}],"payload":{"lines":"190,191"}}],"payload":{"lines":"159,160"}},{"content":"Violación de la Confidencialidad del Paciente por Incumplimiento","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de chatbots con PNL para asistencia no médica en salud mental.","children":[],"payload":{"lines":"203,204"}},{"content":"<strong>Dilema:</strong> Equilibrar la privacidad del usuario con la necesidad de intervención en caso de riesgo de autolesión o suicidio.","children":[],"payload":{"lines":"204,206"}}],"payload":{"lines":"202,203"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"208,209\"><strong>Diseño Éticamente Alineado (EAD) del IEEE</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Ética por diseño, privacidad informática afectiva, bienestar.","children":[],"payload":{"lines":"209,210"}},{"content":"<strong>Enfoque:</strong>","children":[{"content":"Equilibrio entre el apoyo al usuario y la prevención de dependencias perjudiciales.","children":[],"payload":{"lines":"211,212"}},{"content":"Privacidad con límites claros, pero permitiendo intervenciones en caso de riesgo vital.","children":[],"payload":{"lines":"212,213"}}],"payload":{"lines":"210,213"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Consideración explícita de la computación afectiva y el bienestar junto a la privacidad.","children":[],"payload":{"lines":"214,215"}}],"payload":{"lines":"213,215"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Recomendaciones de alto nivel sujetas a interpretación, posibilidad de esquivar responsabilidades.","children":[],"payload":{"lines":"216,218"}}],"payload":{"lines":"215,218"}}],"payload":{"lines":"208,218"}},{"content":"<p data-lines=\"218,219\"><strong>Principios de la IA de Asilomar</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Seguridad y transparencia de fallos.","children":[],"payload":{"lines":"219,220"}},{"content":"<strong>Enfoque:</strong>","children":[{"content":"Divulgación equilibrada y seguridad de la vida humana.","children":[],"payload":{"lines":"221,222"}},{"content":"Conciencia de las limitaciones del sistema para gestionar expectativas.","children":[],"payload":{"lines":"222,223"}}],"payload":{"lines":"220,223"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Mención explícita de la transparencia de fallos, crucial en salud mental.","children":[],"payload":{"lines":"224,225"}}],"payload":{"lines":"223,225"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Principios de muy alto nivel y genéricos, dificultad en la implementación práctica.","children":[],"payload":{"lines":"226,228"}}],"payload":{"lines":"225,228"}}],"payload":{"lines":"218,228"}}],"payload":{"lines":"206,207"}},{"content":"Análisis Comparativo","children":[{"content":"<strong>EAD vs. Asilomar:</strong>","children":[{"content":"EAD proporciona un enfoque más completo al incluir la computación afectiva, pero puede ser vago en su aplicación.","children":[],"payload":{"lines":"231,232"}},{"content":"Asilomar enfatiza la seguridad y la transparencia, esencial en el contexto de la salud mental, pero carece de especificidad operativa.","children":[],"payload":{"lines":"232,234"}}],"payload":{"lines":"230,234"}}],"payload":{"lines":"228,229"}},{"content":"Conclusión","children":[{"content":"<strong>Implicación Ética:</strong> Ambos marcos sugieren la importancia de mantener un equilibrio ético entre la confidencialidad del paciente<br>\ny la intervención necesaria en casos de emergencia.","children":[],"payload":{"lines":"236,238"}},{"content":"<strong>Desafío en la Implementación:</strong> La falta de concreción en las directrices plantea retos en la aplicación efectiva<br>\ny la toma de decisiones éticas responsables.","children":[],"payload":{"lines":"238,240"}},{"content":"<strong>Consideración de los Principios:</strong> A pesar de sus diferencias, ambos marcos subrayan la prioridad de la seguridad del usuario<br>\ny la necesidad de una intervención ética informada.","children":[],"payload":{"lines":"240,242"}}],"payload":{"lines":"234,235"}}],"payload":{"lines":"200,201"}},{"content":"Beneficios Individuales vs. Daño al Tejido Social","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Libertad de expresión en redes sociales vs. impacto negativo en la sociedad.","children":[],"payload":{"lines":"248,249"}},{"content":"<strong>Conflicto:</strong> Entre autonomía individual y bienestar colectivo.","children":[],"payload":{"lines":"249,251"}}],"payload":{"lines":"247,248"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"253,254\"><strong>Diseño Éticamente Alineado (EAD) del IEEE</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Autonomía individual, garantizar bienestar social.","children":[],"payload":{"lines":"254,255"}},{"content":"<strong>Enfoque:</strong> Balance entre potenciar la autonomía individual y restricciones para proteger la comunidad.","children":[],"payload":{"lines":"255,256"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Llamada explícita a la autonomía de los individuos.","children":[],"payload":{"lines":"257,258"}},{"content":"Flexibilidad para incluir necesidades comunitarias.","children":[],"payload":{"lines":"258,259"}}],"payload":{"lines":"256,259"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de especificidad para moderación de contenidos.","children":[],"payload":{"lines":"260,262"}}],"payload":{"lines":"259,262"}}],"payload":{"lines":"253,262"}},{"content":"<p data-lines=\"262,263\"><strong>Principios de Santa Clara sobre Transparencia y Responsabilidad en Moderación de Contenidos</strong></p>","children":[{"content":"<strong>Especialización:</strong> Orientado a medios de comunicación, subsana lagunas de la EAD en moderación de contenidos.","children":[],"payload":{"lines":"263,265"}}],"payload":{"lines":"262,265"}},{"content":"<p data-lines=\"265,266\"><strong>Directriz Ética para una IA Digna de Confianza</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Responsabilidad, supervisión humana, bienestar de la sociedad.","children":[],"payload":{"lines":"266,267"}},{"content":"<strong>Enfoque:</strong> Marco basado en riesgos para balancear responsabilidad y supervisión con bienestar colectivo.","children":[],"payload":{"lines":"267,268"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Supervisión humana y responsabilidad definidas explícitamente.","children":[],"payload":{"lines":"269,270"}},{"content":"Fortalecimiento de cultura, valores y normas sociales.","children":[],"payload":{"lines":"270,271"}}],"payload":{"lines":"268,271"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de especificidad para moderación de contenidos.","children":[],"payload":{"lines":"272,273"}},{"content":"Enfoque regional puede limitar aplicabilidad global.","children":[],"payload":{"lines":"273,275"}}],"payload":{"lines":"271,275"}}],"payload":{"lines":"265,275"}}],"payload":{"lines":"251,252"}},{"content":"Análisis Comparativo","children":[{"content":"<strong>EAD vs. Directrices Éticas:</strong> EAD proporciona un marco amplio para potenciar la autonomía, pero carece de enfoque específico en moderación.<br>\nLas Directrices Éticas ofrecen un marco basado en riesgos con énfasis en el bienestar colectivo, pero su aplicación puede ser regionalmente limitada.","children":[],"payload":{"lines":"277,280"}}],"payload":{"lines":"275,276"}},{"content":"Conclusión","children":[{"content":"<strong>Combinación de Marcos:</strong> Integrar múltiples marcos puede ofrecer un equilibrio más efectivo entre beneficios individuales y responsabilidad social.","children":[],"payload":{"lines":"282,283"}},{"content":"<strong>Desafío de Implementación:</strong> La falta de especificidad en la moderación de contenidos y la variabilidad regional requiere<br>\nun enfoque adaptativo y posiblemente combinado para abordar eficazmente el dilema.","children":[],"payload":{"lines":"283,285"}}],"payload":{"lines":"280,281"}}],"payload":{"lines":"245,246"}},{"content":"Emancipación de Sistemas de IA de Supervisión Humana","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Sistemas de IA operan sin supervisión humana significativa.","children":[],"payload":{"lines":"292,293"}},{"content":"<strong>Problema:</strong> Dificultad para garantizar el bienestar y otros resultados prosociales.","children":[],"payload":{"lines":"293,295"}}],"payload":{"lines":"291,292"}},{"content":"Principios de Beijing sobre la IA (BAIP)","children":[{"content":"<strong>Enfoque:</strong> Riesgos de control y apertura/intercambio.","children":[],"payload":{"lines":"296,297"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Identifica explícitamente los riesgos de control.","children":[],"payload":{"lines":"298,299"}},{"content":"Propone apertura e intercambio para supervisión pública y rendición de cuentas.","children":[],"payload":{"lines":"299,300"}}],"payload":{"lines":"297,300"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de consejos específicos y procesables.","children":[],"payload":{"lines":"301,302"}},{"content":"Señala áreas para investigación sin recomendaciones detalladas.","children":[],"payload":{"lines":"302,304"}}],"payload":{"lines":"300,304"}}],"payload":{"lines":"295,296"}},{"content":"Principios de la IA de la OCDE","children":[{"content":"<strong>Enfoque:</strong> Intervención humana adecuada, oposición a la emancipación completa de supervisión humana.","children":[],"payload":{"lines":"305,306"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Orientación arraigada en legislación de derechos humanos.","children":[],"payload":{"lines":"307,308"}},{"content":"Directrices claras para mantener controles humanos.","children":[],"payload":{"lines":"308,309"}}],"payload":{"lines":"306,309"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"De muy alto nivel, abstractos, y abiertos a interpretación.","children":[],"payload":{"lines":"310,311"}},{"content":"Riesgo de afirmar adhesión sin cumplimiento efectivo.","children":[],"payload":{"lines":"311,313"}}],"payload":{"lines":"309,313"}}],"payload":{"lines":"304,305"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>BAIP vs. OCDE:</strong>","children":[{"content":"<strong>BAIP:</strong> Centrados en identificar riesgos y promover la apertura para la supervisión. Carecen de especificidad.","children":[],"payload":{"lines":"315,316"}},{"content":"<strong>OCDE:</strong> Enfatizan la necesidad de control humano y están bien alineados con requisitos legales, pero son abstractos.","children":[],"payload":{"lines":"316,318"}}],"payload":{"lines":"314,318"}}],"payload":{"lines":"313,314"}},{"content":"Conclusiones","children":[{"content":"La <strong>emancipación de la IA</strong> de la supervisión humana presenta desafíos únicos en términos de riesgos de control y la garantía del bienestar humano.","children":[],"payload":{"lines":"319,320"}},{"content":"<strong>BAIP</strong> proporciona un marco para la supervisión pública, mientras que <strong>OCDE</strong> aboga por mantener los controles humanos.","children":[],"payload":{"lines":"320,321"}},{"content":"Ambos enfoques presentan ventajas en términos de concienciación sobre riesgos y promoción de la apertura,<br>\npero carecen de directrices detalladas para la implementación práctica.","children":[],"payload":{"lines":"321,323"}},{"content":"<strong>Necesidad de Equilibrio:</strong> Entre la autonomía operativa de los sistemas de IA y la supervisión humana efectiva<br>\npara asegurar resultados éticos y prosociales.","children":[],"payload":{"lines":"323,325"}}],"payload":{"lines":"318,319"}}],"payload":{"lines":"289,290"}},{"content":"Protección Contra el Acoso por IA","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Uso de técnicas de IA, como deep fakes, para el acoso.","children":[],"payload":{"lines":"332,333"}},{"content":"<strong>Problema:</strong> Facilidad de implementación y potencial de daño significativo.","children":[],"payload":{"lines":"333,335"}}],"payload":{"lines":"331,332"}},{"content":"Declaración de Toronto (TD)","children":[{"content":"<strong>Base:</strong> Derechos humanos internacionales.","children":[],"payload":{"lines":"336,337"}},{"content":"<strong>Enfoque:</strong> Considerar efectos de segundo orden de la publicación abierta.","children":[],"payload":{"lines":"337,338"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aplicabilidad amplia y coherencia internacional.","children":[],"payload":{"lines":"339,340"}},{"content":"Raíces en las leyes internacionales de derechos humanos.","children":[],"payload":{"lines":"340,341"}}],"payload":{"lines":"338,341"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de orientación prescriptiva sobre modelos de publicación alternativos.","children":[],"payload":{"lines":"342,343"}},{"content":"Necesidad de equilibrar investigación abierta con protección de derechos.","children":[],"payload":{"lines":"343,345"}}],"payload":{"lines":"341,345"}}],"payload":{"lines":"335,336"}},{"content":"Principios de IA de Asilomar (AAIP)","children":[{"content":"<strong>Elementos clave:</strong> Objetivos de investigación, financiación, cultura de investigación, prosperidad compartida.","children":[],"payload":{"lines":"346,347"}},{"content":"<strong>Enfoque:</strong> Establecer expectativas sobre problemas de investigación dignos de perseguir.","children":[],"payload":{"lines":"347,348"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aborda qué problemas de investigación perseguir.","children":[],"payload":{"lines":"349,350"}},{"content":"Equilibra costes y beneficios de la investigación para maximizar el beneficio.","children":[],"payload":{"lines":"350,351"}}],"payload":{"lines":"348,351"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Orientaciones normativas sin casos de uso demostrados.","children":[],"payload":{"lines":"352,353"}},{"content":"Dificultad para evaluar la eficacia en la práctica.","children":[],"payload":{"lines":"353,355"}}],"payload":{"lines":"351,355"}}],"payload":{"lines":"345,346"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>TD vs. AAIP:</strong>","children":[{"content":"<strong>TD:</strong> Foco en protección de derechos humanos y coherencia jurídica.","children":[],"payload":{"lines":"357,358"}},{"content":"<strong>AAIP:</strong> Enfoque en definir y equilibrar objetivos de investigación éticamente.","children":[],"payload":{"lines":"358,360"}}],"payload":{"lines":"356,360"}}],"payload":{"lines":"355,356"}},{"content":"Conclusiones","children":[{"content":"Tanto <strong>TD</strong> como <strong>AAIP</strong> ofrecen marcos para proteger contra el acoso por IA.","children":[],"payload":{"lines":"361,362"}},{"content":"<strong>TD</strong> proporciona un fundamento en derechos humanos para una aplicación amplia.","children":[],"payload":{"lines":"362,363"}},{"content":"<strong>AAIP</strong> destaca la importancia de la elección y el equilibrio en la investigación.","children":[],"payload":{"lines":"363,364"}},{"content":"Ambos marcos enfrentan desafíos en proporcionar orientación específica y aplicable.","children":[],"payload":{"lines":"364,365"}},{"content":"<strong>Necesidad de Más Orientación:</strong> Hay una necesidad de directrices más específicas que puedan guiar prácticamente la implementación<br>\ny la toma de decisiones éticas en el uso de la IA para evitar el acoso.","children":[],"payload":{"lines":"365,367"}}],"payload":{"lines":"360,361"}}],"payload":{"lines":"329,330"}}],"payload":{"lines":"16,17"}}],"payload":{"lines":"0,1"}},{"colorFreezeLevel":3})</script>
</body>
</html>
