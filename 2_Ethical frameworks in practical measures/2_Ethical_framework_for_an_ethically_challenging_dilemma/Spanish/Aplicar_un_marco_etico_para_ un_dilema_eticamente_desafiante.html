<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.16.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:H,mm:ae}=window,W=new H.Toolbar;W.attach(ae);const we=W.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((o,T,c,r)=>{const g=o();window.mm=g.Markmap.create("svg#mindmap",(T||g.deriveOptions)(r),c)})(()=>window.markmap,null,{"content":"Aplicar marcos eticos a dilemas eticamente desafiantes","children":[{"content":"General","children":[{"content":"Convertir Principios Éticos en Acción","children":[{"content":"Escenarios a Cubrir","children":[{"content":"<strong>Problema del Trolebús y Coches Autónomos:</strong> Decisiones sobre quién salvar en situaciones de vida o muerte.","children":[],"payload":{"lines":"8,9"}},{"content":"<strong>Emergencias y Desastres:</strong> Priorización y toma de decisiones críticas basadas en marcos éticos.","children":[],"payload":{"lines":"9,10"}},{"content":"<strong>Confidencialidad del Paciente en Salud:</strong> Navegación por las leyes de privacidad como HIPAA y su relación con la ética.","children":[],"payload":{"lines":"10,11"}},{"content":"<strong>Cuestiones Sociales y Acoso por IA:</strong> Abordaje del potencial de daño social y acoso por sistemas de IA.","children":[],"payload":{"lines":"11,13"}}],"payload":{"lines":"7,8"}},{"content":"Importancia de la Selección de Marcos","children":[{"content":"Existen más de 85 marcos éticos, cada uno con un enfoque y audiencia específicos (por ejemplo, algunos están dirigidos a gobiernos, otros a individuos).","children":[],"payload":{"lines":"14,15"}}],"payload":{"lines":"13,14"}}],"payload":{"lines":"5,6"}}],"payload":{"lines":"3,4"}},{"content":"Aplicacion del marco a dilemas eticos","children":[{"content":"Aplicación de Marcos Éticos al Problema del Trolebús","children":[{"content":"Introducción al Dilema del Trolebús","children":[{"content":"<strong>Situación:</strong> Trolebús desbocado se dirige hacia un grupo de personas atadas a las vías.","children":[],"payload":{"lines":"22,23"}},{"content":"<strong>Opciones:</strong>","children":[{"content":"No hacer nada: el trolebús mata al grupo.","children":[],"payload":{"lines":"24,25"}},{"content":"Tirar de una palanca: desviar el trolebús, matar a una persona en vías adyacentes.","children":[],"payload":{"lines":"25,26"}}],"payload":{"lines":"23,26"}},{"content":"<strong>Dilema Ético:</strong> ¿Cuál es la acción más ética?","children":[],"payload":{"lines":"26,28"}}],"payload":{"lines":"21,22"}},{"content":"Enfoque Utilitarista","children":[{"content":"<strong>Acción Preferida:</strong> Tirar de la palanca para salvar al mayor número de personas.","children":[],"payload":{"lines":"29,30"}},{"content":"<strong>Consideraciones:</strong>","children":[{"content":"Participación directa en la muerte de una persona.","children":[],"payload":{"lines":"31,32"}},{"content":"Debate sobre la responsabilidad moral por acción vs. inacción.","children":[],"payload":{"lines":"32,34"}}],"payload":{"lines":"30,34"}}],"payload":{"lines":"28,29"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"35,36\"><strong>Declaración de Montreal para una IA Responsable (MDRAI):</strong></p>","children":[{"content":"<strong>Énfasis en:</strong> Autonomía humana, consideración de todos los seres sintientes, responsabilidad en la acción e inacción.","children":[],"payload":{"lines":"36,37"}},{"content":"<strong>Ventajas:</strong> Inclusión holística y énfasis en la responsabilidad.","children":[],"payload":{"lines":"37,38"}},{"content":"<strong>Desafíos:</strong> Aplicabilidad limitada a escenarios específicos de IA.","children":[],"payload":{"lines":"38,40"}}],"payload":{"lines":"35,40"}},{"content":"<p data-lines=\"40,41\"><strong>Principios de IA de Asilomar:</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Seguridad, alineación de valores, transparencia de fallos.","children":[],"payload":{"lines":"41,42"}},{"content":"<strong>Ventajas:</strong> Fomenta la preparación y conciencia sobre fallos de IA y decisiones seguras.","children":[],"payload":{"lines":"42,43"}},{"content":"<strong>Desafíos:</strong> Aplicación genérica que podría adaptarse a conveniencia del decisor.","children":[],"payload":{"lines":"43,45"}}],"payload":{"lines":"40,45"}}],"payload":{"lines":"34,35"}},{"content":"Notas","children":[{"content":"<strong>Importancia de Principios Rectores:</strong> Ayudan a definir y guiar prácticas éticas en situaciones complejas.","children":[],"payload":{"lines":"46,47"}},{"content":"<strong>Relevancia de Marcos Éticos:</strong> Ambos marcos proporcionan perspectivas útiles pero difieren en aplicación y énfasis en la responsabilidad y transparencia.","children":[],"payload":{"lines":"47,48"}}],"payload":{"lines":"45,46"}}],"payload":{"lines":"19,20"}},{"content":"Resumen Esquemático: Uso de IA en Emergencias y Catástrofes","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Despliegue de tecnología de rastreo de contactos durante una pandemia para afinar la respuesta de salud pública.","children":[],"payload":{"lines":"54,55"}},{"content":"<strong>Dilema:</strong> Equilibrio entre seguridad pública y privacidad individual.","children":[],"payload":{"lines":"55,57"}}],"payload":{"lines":"53,54"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"59,60\"><strong>Directrices Universales para la IA (UGAI)</strong></p>","children":[{"content":"<strong>Enfoque en:</strong> Seguridad pública y responsabilidad.","children":[],"payload":{"lines":"60,61"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Énfasis en mejorar la seguridad pública.","children":[],"payload":{"lines":"62,63"}},{"content":"Cláusula de terminación para uso limitado y específico.","children":[],"payload":{"lines":"63,64"}}],"payload":{"lines":"61,64"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de concreción en la aplicación de principios.","children":[],"payload":{"lines":"65,66"}},{"content":"Amplio margen para interpretación.","children":[],"payload":{"lines":"66,68"}}],"payload":{"lines":"64,68"}}],"payload":{"lines":"59,68"}},{"content":"<p data-lines=\"68,69\"><strong>Declaración de Toronto (DT)</strong></p>","children":[{"content":"<strong>Enfoque en:</strong> No discriminación y derechos humanos internacionales.","children":[],"payload":{"lines":"69,70"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aplicabilidad universal y aceptación transfronteriza.","children":[],"payload":{"lines":"71,72"}},{"content":"Basado en principios de derechos humanos.","children":[],"payload":{"lines":"72,73"}}],"payload":{"lines":"70,73"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de orientación sólida sobre privacidad.","children":[],"payload":{"lines":"74,75"}},{"content":"Posible insuficiencia en abordar todas las preocupaciones éticas.","children":[],"payload":{"lines":"75,77"}}],"payload":{"lines":"73,77"}}],"payload":{"lines":"68,77"}}],"payload":{"lines":"57,58"}},{"content":"Discusión","children":[{"content":"<strong>UGAI:</strong> Proporciona una orientación ética clara para el rastreo de contactos con énfasis en la responsabilidad<br>\ny seguridad pública, destacando una cláusula de terminación para evitar el abuso o uso prolongado indebido del sistema.","children":[],"payload":{"lines":"78,80"}},{"content":"<strong>DT:</strong> Centra en los derechos humanos y la no discriminación, ofreciendo un marco ético para equilibrar las necesidades de salud pública<br>\ncon la protección de la privacidad y los derechos individuales.","children":[],"payload":{"lines":"80,82"}}],"payload":{"lines":"77,78"}}],"payload":{"lines":"51,52"}},{"content":"IA en Medicina - Sesgo vs. Humanos","children":[{"content":"Contexto","children":[{"content":"<strong>Área de Aplicación:</strong> Radiología y lectura de escáneres de imágenes médicas.","children":[],"payload":{"lines":"89,90"}},{"content":"<strong>Dilema:</strong> Sistemas de IA muestran mayor precisión que paneles médicos humanos pero carecen de capacidad explicativa.","children":[],"payload":{"lines":"90,92"}}],"payload":{"lines":"88,89"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"94,95\"><strong>Declaración de Montreal para una IA Responsable (MDR)</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Prudencia, Autonomía Humana, Responsabilidad.","children":[],"payload":{"lines":"95,96"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Anticipa consecuencias negativas y asegura coherencia con decisiones humanas.","children":[],"payload":{"lines":"97,98"}},{"content":"Fomenta el control humano significativo e impulsa la confianza.","children":[],"payload":{"lines":"98,99"}}],"payload":{"lines":"96,99"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Margen de interpretación puede llevar a aplicaciones inconsistentes.","children":[],"payload":{"lines":"100,101"}},{"content":"Necesita respaldo de instrumentos regulatorios.","children":[],"payload":{"lines":"101,103"}}],"payload":{"lines":"99,103"}}],"payload":{"lines":"94,103"}},{"content":"<p data-lines=\"103,104\"><strong>Principios de la IA de Pekín</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Consentimiento Informado, Formación Educativa.","children":[],"payload":{"lines":"104,105"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Promueve comprensión de riesgos por parte del paciente.","children":[],"payload":{"lines":"106,107"}},{"content":"Prepara a médicos para manejar fallos del sistema y comunicar riesgos.","children":[],"payload":{"lines":"107,108"}}],"payload":{"lines":"105,108"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de detalles sobre la implementación práctica de principios.","children":[],"payload":{"lines":"109,110"}},{"content":"Cuestiones sobre la suficiencia de la formación educativa y el consentimiento informado.","children":[],"payload":{"lines":"110,112"}}],"payload":{"lines":"108,112"}}],"payload":{"lines":"103,112"}}],"payload":{"lines":"92,93"}},{"content":"Comparación y Conclusión","children":[{"content":"<strong>MDR vs. Principios de Pekín:</strong> Ambos marcos ofrecen perspectivas útiles para abordar el dilema ético, centrando la atención en la prudencia, la autonomía, la responsabilidad, y el consentimiento informado como fundamentos para el uso ético de IA en la medicina.","children":[],"payload":{"lines":"114,115"}},{"content":"<strong>Eficacia:</strong> MDR proporciona un enfoque holístico que abarca la confianza y los valores de la organización, mientras que los Principios de Pekín se centran en el consentimiento y la preparación del paciente y el profesional médico.","children":[],"payload":{"lines":"115,116"}},{"content":"<strong>Implementación:</strong> Ambos marcos enfrentan desafíos en la aplicación práctica, necesitando claridad y apoyo regulatorio para garantizar su efectividad.","children":[],"payload":{"lines":"116,117"}}],"payload":{"lines":"112,113"}}],"payload":{"lines":"86,87"}},{"content":"IA y Comportamientos Autodestructivos","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de IA en redes sociales que promueve comportamientos adictivos a través del desplazamiento interminable y contenidos hiper personalizados.","children":[],"payload":{"lines":"123,124"}},{"content":"<strong>Dilema:</strong> Balance entre maximizar beneficios empresariales y preservar el bienestar de los usuarios.","children":[],"payload":{"lines":"124,126"}}],"payload":{"lines":"122,123"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"128,129\"><strong>Directrices Universales para la IA (UGAI)</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Calidad de Datos, Prohibición de Perfiles Secretos, Seguridad Pública.","children":[],"payload":{"lines":"129,130"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Cobertura amplia de preocupaciones éticas.","children":[],"payload":{"lines":"131,132"}},{"content":"Orienta hacia el beneficio de los usuarios.","children":[],"payload":{"lines":"132,133"}}],"payload":{"lines":"130,133"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de directrices concretas para la implementación.","children":[],"payload":{"lines":"134,136"}}],"payload":{"lines":"133,136"}}],"payload":{"lines":"128,136"}},{"content":"<p data-lines=\"136,137\"><strong>Principios de la IA de Pekín</strong></p>","children":[{"content":"<strong>Principios Aplicables:</strong> Consentimiento Informado, Ética por Diseño.","children":[],"payload":{"lines":"137,138"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Promueve consideraciones éticas desde el desarrollo inicial.","children":[],"payload":{"lines":"139,140"}},{"content":"Prevención de interfaces adictivas y sistemas de recompensa perjudiciales.","children":[],"payload":{"lines":"140,141"}}],"payload":{"lines":"138,141"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Margen de interpretación amplio.","children":[],"payload":{"lines":"142,143"}},{"content":"Falta de especificidad en la implementación.","children":[],"payload":{"lines":"143,145"}}],"payload":{"lines":"141,145"}}],"payload":{"lines":"136,145"}}],"payload":{"lines":"126,127"}},{"content":"Comparación y Conclusión","children":[{"content":"<strong>UGAI</strong> enfatiza en el uso adecuado de datos y el impacto social, proporcionando un marco para equilibrar la ganancia empresarial<br>\ncon el bienestar de los usuarios. Sin embargo, carece de pautas detalladas para la práctica.","children":[],"payload":{"lines":"147,149"}},{"content":"<strong>Principios de Pekín</strong> se centran en el consentimiento informado y la inclusión de consideraciones éticas en el diseño,<br>\napoyando el desarrollo de sistemas menos perjudiciales desde el inicio. No obstante, la vaguedad en la aplicación práctica podría limitar su efectividad.","children":[],"payload":{"lines":"149,151"}},{"content":"<strong>Enfoque Recomendado:</strong> La combinación de ambos marcos puede ofrecer un enfoque equilibrado, asegurando tanto la responsabilidad<br>\nen el uso de datos como la incorporación de ética en el diseño y desarrollo de IA, para mitigar comportamientos autodestructivos entre los usuarios.","children":[],"payload":{"lines":"151,153"}}],"payload":{"lines":"145,146"}}],"payload":{"lines":"120,121"}},{"content":"Límites de la Tecnología Persuasiva en Juguetes Inteligentes","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de IA en juguetes inteligentes para influir en comportamientos de menores, como persuadirlos para que deseen ciertas marcas.","children":[],"payload":{"lines":"159,160"}},{"content":"<strong>Preocupación:</strong> Tecnología altamente persuasiva dirigida a un público vulnerable (niños).","children":[],"payload":{"lines":"160,162"}}],"payload":{"lines":"158,159"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"164,165\"><strong>Principios de la IA de la OCDE</strong></p>","children":[{"content":"<strong>Enfoque:</strong> Divulgación responsable, transparencia, privacidad, bienestar.","children":[],"payload":{"lines":"165,166"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Equilibrio entre divulgación responsable y bienestar.","children":[],"payload":{"lines":"167,168"}},{"content":"Alineación con entornos legales y regulatorios.","children":[],"payload":{"lines":"168,169"}}],"payload":{"lines":"166,169"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Carácter normativo sin casos de uso demostrados.","children":[],"payload":{"lines":"170,172"}}],"payload":{"lines":"169,172"}}],"payload":{"lines":"164,172"}},{"content":"<p data-lines=\"172,173\"><strong>Directrices Éticas sobre IA no Confiable</strong></p>","children":[{"content":"<strong>Enfoque:</strong> Respeto a la autonomía humana, privacidad, gobernanza de datos, bienestar.","children":[],"payload":{"lines":"173,174"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Orientación granular con casos de uso efectivos.","children":[],"payload":{"lines":"175,176"}},{"content":"Proximidad a requisitos legales y regulatorios.","children":[],"payload":{"lines":"176,177"}}],"payload":{"lines":"174,177"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Perspectiva enfocada en la legislación de la UE, puede requerir adaptación fuera de Europa.","children":[],"payload":{"lines":"178,180"}}],"payload":{"lines":"177,180"}}],"payload":{"lines":"172,180"}}],"payload":{"lines":"162,163"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>OCDE vs. Directrices Éticas no Confiables:</strong> Los principios de la OCDE proporcionan un marco general para el desarrollo ético,<br>\nmientras que las Directrices Éticas ofrecen una orientación más detallada y pragmática, especialmente en lo que respecta a la autonomía y seguridad de los menores.","children":[],"payload":{"lines":"182,184"}},{"content":"<strong>Impacto en el Desarrollo de Productos:</strong> Ambos marcos buscan guiar la creación de productos que respeten la autonomía de los usuarios<br>\ny promuevan su bienestar, aunque desde diferentes niveles de detalle y aplicabilidad geográfica.","children":[],"payload":{"lines":"184,187"}}],"payload":{"lines":"180,181"}},{"content":"Notas","children":[{"content":"<strong>Equilibrio Ético:</strong> Es crucial equilibrar la innovación tecnológica con la protección de los usuarios vulnerables,<br>\nasegurando que la tecnología persuasiva no comprometa el bienestar ni la autonomía de los niños.","children":[],"payload":{"lines":"189,191"}},{"content":"<strong>Elección de Marco:</strong> Dependerá de las necesidades específicas de la organización y el contexto jurisdiccional en el que opere,<br>\naunque la tendencia es hacia una aplicación ética granular y basada en casos de uso demostrados.","children":[],"payload":{"lines":"191,193"}}],"payload":{"lines":"187,188"}}],"payload":{"lines":"156,157"}},{"content":"Violación de la Confidencialidad del Paciente por Incumplimiento","children":[{"content":"Contexto","children":[{"content":"<strong>Escenario:</strong> Uso de chatbots con PNL para asistencia no médica en salud mental.","children":[],"payload":{"lines":"200,201"}},{"content":"<strong>Dilema:</strong> Equilibrar la privacidad del usuario con la necesidad de intervención en caso de riesgo de autolesión o suicidio.","children":[],"payload":{"lines":"201,203"}}],"payload":{"lines":"199,200"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"205,206\"><strong>Diseño Éticamente Alineado (EAD) del IEEE</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Ética por diseño, privacidad informática afectiva, bienestar.","children":[],"payload":{"lines":"206,207"}},{"content":"<strong>Enfoque:</strong>","children":[{"content":"Equilibrio entre el apoyo al usuario y la prevención de dependencias perjudiciales.","children":[],"payload":{"lines":"208,209"}},{"content":"Privacidad con límites claros, pero permitiendo intervenciones en caso de riesgo vital.","children":[],"payload":{"lines":"209,210"}}],"payload":{"lines":"207,210"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Consideración explícita de la computación afectiva y el bienestar junto a la privacidad.","children":[],"payload":{"lines":"211,212"}}],"payload":{"lines":"210,212"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Recomendaciones de alto nivel sujetas a interpretación, posibilidad de esquivar responsabilidades.","children":[],"payload":{"lines":"213,215"}}],"payload":{"lines":"212,215"}}],"payload":{"lines":"205,215"}},{"content":"<p data-lines=\"215,216\"><strong>Principios de la IA de Asilomar</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Seguridad y transparencia de fallos.","children":[],"payload":{"lines":"216,217"}},{"content":"<strong>Enfoque:</strong>","children":[{"content":"Divulgación equilibrada y seguridad de la vida humana.","children":[],"payload":{"lines":"218,219"}},{"content":"Conciencia de las limitaciones del sistema para gestionar expectativas.","children":[],"payload":{"lines":"219,220"}}],"payload":{"lines":"217,220"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Mención explícita de la transparencia de fallos, crucial en salud mental.","children":[],"payload":{"lines":"221,222"}}],"payload":{"lines":"220,222"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Principios de muy alto nivel y genéricos, dificultad en la implementación práctica.","children":[],"payload":{"lines":"223,225"}}],"payload":{"lines":"222,225"}}],"payload":{"lines":"215,225"}}],"payload":{"lines":"203,204"}},{"content":"Análisis Comparativo","children":[{"content":"<strong>EAD vs. Asilomar:</strong>","children":[{"content":"EAD proporciona un enfoque más completo al incluir la computación afectiva, pero puede ser vago en su aplicación.","children":[],"payload":{"lines":"228,229"}},{"content":"Asilomar enfatiza la seguridad y la transparencia, esencial en el contexto de la salud mental, pero carece de especificidad operativa.","children":[],"payload":{"lines":"229,231"}}],"payload":{"lines":"227,231"}}],"payload":{"lines":"225,226"}},{"content":"Conclusión","children":[{"content":"<strong>Implicación Ética:</strong> Ambos marcos sugieren la importancia de mantener un equilibrio ético entre la confidencialidad del paciente<br>\ny la intervención necesaria en casos de emergencia.","children":[],"payload":{"lines":"233,235"}},{"content":"<strong>Desafío en la Implementación:</strong> La falta de concreción en las directrices plantea retos en la aplicación efectiva<br>\ny la toma de decisiones éticas responsables.","children":[],"payload":{"lines":"235,237"}},{"content":"<strong>Consideración de los Principios:</strong> A pesar de sus diferencias, ambos marcos subrayan la prioridad de la seguridad del usuario<br>\ny la necesidad de una intervención ética informada.","children":[],"payload":{"lines":"237,239"}}],"payload":{"lines":"231,232"}}],"payload":{"lines":"197,198"}},{"content":"Beneficios Individuales vs. Daño al Tejido Social","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Libertad de expresión en redes sociales vs. impacto negativo en la sociedad.","children":[],"payload":{"lines":"245,246"}},{"content":"<strong>Conflicto:</strong> Entre autonomía individual y bienestar colectivo.","children":[],"payload":{"lines":"246,248"}}],"payload":{"lines":"244,245"}},{"content":"Aplicación de Marcos Éticos","children":[{"content":"<p data-lines=\"250,251\"><strong>Diseño Éticamente Alineado (EAD) del IEEE</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Autonomía individual, garantizar bienestar social.","children":[],"payload":{"lines":"251,252"}},{"content":"<strong>Enfoque:</strong> Balance entre potenciar la autonomía individual y restricciones para proteger la comunidad.","children":[],"payload":{"lines":"252,253"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Llamada explícita a la autonomía de los individuos.","children":[],"payload":{"lines":"254,255"}},{"content":"Flexibilidad para incluir necesidades comunitarias.","children":[],"payload":{"lines":"255,256"}}],"payload":{"lines":"253,256"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de especificidad para moderación de contenidos.","children":[],"payload":{"lines":"257,259"}}],"payload":{"lines":"256,259"}}],"payload":{"lines":"250,259"}},{"content":"<p data-lines=\"259,260\"><strong>Principios de Santa Clara sobre Transparencia y Responsabilidad en Moderación de Contenidos</strong></p>","children":[{"content":"<strong>Especialización:</strong> Orientado a medios de comunicación, subsana lagunas de la EAD en moderación de contenidos.","children":[],"payload":{"lines":"260,262"}}],"payload":{"lines":"259,262"}},{"content":"<p data-lines=\"262,263\"><strong>Directriz Ética para una IA Digna de Confianza</strong></p>","children":[{"content":"<strong>Principios Clave:</strong> Responsabilidad, supervisión humana, bienestar de la sociedad.","children":[],"payload":{"lines":"263,264"}},{"content":"<strong>Enfoque:</strong> Marco basado en riesgos para balancear responsabilidad y supervisión con bienestar colectivo.","children":[],"payload":{"lines":"264,265"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Supervisión humana y responsabilidad definidas explícitamente.","children":[],"payload":{"lines":"266,267"}},{"content":"Fortalecimiento de cultura, valores y normas sociales.","children":[],"payload":{"lines":"267,268"}}],"payload":{"lines":"265,268"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de especificidad para moderación de contenidos.","children":[],"payload":{"lines":"269,270"}},{"content":"Enfoque regional puede limitar aplicabilidad global.","children":[],"payload":{"lines":"270,272"}}],"payload":{"lines":"268,272"}}],"payload":{"lines":"262,272"}}],"payload":{"lines":"248,249"}},{"content":"Análisis Comparativo","children":[{"content":"<strong>EAD vs. Directrices Éticas:</strong> EAD proporciona un marco amplio para potenciar la autonomía, pero carece de enfoque específico en moderación.<br>\nLas Directrices Éticas ofrecen un marco basado en riesgos con énfasis en el bienestar colectivo, pero su aplicación puede ser regionalmente limitada.","children":[],"payload":{"lines":"274,277"}}],"payload":{"lines":"272,273"}},{"content":"Notas","children":[{"content":"<strong>Combinación de Marcos:</strong> Integrar múltiples marcos puede ofrecer un equilibrio más efectivo entre beneficios individuales y responsabilidad social.","children":[],"payload":{"lines":"279,280"}},{"content":"<strong>Desafío de Implementación:</strong> La falta de especificidad en la moderación de contenidos y la variabilidad regional requiere<br>\nun enfoque adaptativo y posiblemente combinado para abordar eficazmente el dilema.","children":[],"payload":{"lines":"280,282"}}],"payload":{"lines":"277,278"}}],"payload":{"lines":"242,243"}},{"content":"Emancipación de Sistemas de IA de Supervisión Humana","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Sistemas de IA operan sin supervisión humana significativa.","children":[],"payload":{"lines":"289,290"}},{"content":"<strong>Problema:</strong> Dificultad para garantizar el bienestar y otros resultados prosociales.","children":[],"payload":{"lines":"290,292"}}],"payload":{"lines":"288,289"}},{"content":"Principios de Beijing sobre la IA (BAIP)","children":[{"content":"<strong>Enfoque:</strong> Riesgos de control y apertura/intercambio.","children":[],"payload":{"lines":"293,294"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Identifica explícitamente los riesgos de control.","children":[],"payload":{"lines":"295,296"}},{"content":"Propone apertura e intercambio para supervisión pública y rendición de cuentas.","children":[],"payload":{"lines":"296,297"}}],"payload":{"lines":"294,297"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de consejos específicos y procesables.","children":[],"payload":{"lines":"298,299"}},{"content":"Señala áreas para investigación sin recomendaciones detalladas.","children":[],"payload":{"lines":"299,301"}}],"payload":{"lines":"297,301"}}],"payload":{"lines":"292,293"}},{"content":"Principios de la IA de la OCDE","children":[{"content":"<strong>Enfoque:</strong> Intervención humana adecuada, oposición a la emancipación completa de supervisión humana.","children":[],"payload":{"lines":"302,303"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Orientación arraigada en legislación de derechos humanos.","children":[],"payload":{"lines":"304,305"}},{"content":"Directrices claras para mantener controles humanos.","children":[],"payload":{"lines":"305,306"}}],"payload":{"lines":"303,306"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"De muy alto nivel, abstractos, y abiertos a interpretación.","children":[],"payload":{"lines":"307,308"}},{"content":"Riesgo de afirmar adhesión sin cumplimiento efectivo.","children":[],"payload":{"lines":"308,310"}}],"payload":{"lines":"306,310"}}],"payload":{"lines":"301,302"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>BAIP vs. OCDE:</strong>","children":[{"content":"<strong>BAIP:</strong> Centrados en identificar riesgos y promover la apertura para la supervisión. Carecen de especificidad.","children":[],"payload":{"lines":"312,313"}},{"content":"<strong>OCDE:</strong> Enfatizan la necesidad de control humano y están bien alineados con requisitos legales, pero son abstractos.","children":[],"payload":{"lines":"313,315"}}],"payload":{"lines":"311,315"}}],"payload":{"lines":"310,311"}},{"content":"Notas","children":[{"content":"La <strong>emancipación de la IA</strong> de la supervisión humana presenta desafíos únicos en términos de riesgos de control y la garantía del bienestar humano.","children":[],"payload":{"lines":"316,317"}},{"content":"<strong>BAIP</strong> proporciona un marco para la supervisión pública, mientras que <strong>OCDE</strong> aboga por mantener los controles humanos.","children":[],"payload":{"lines":"317,318"}},{"content":"Ambos enfoques presentan ventajas en términos de concienciación sobre riesgos y promoción de la apertura,<br>\npero carecen de directrices detalladas para la implementación práctica.","children":[],"payload":{"lines":"318,320"}},{"content":"<strong>Necesidad de Equilibrio:</strong> Entre la autonomía operativa de los sistemas de IA y la supervisión humana efectiva<br>\npara asegurar resultados éticos y prosociales.","children":[],"payload":{"lines":"320,322"}}],"payload":{"lines":"315,316"}}],"payload":{"lines":"286,287"}},{"content":"Protección Contra el Acoso por IA","children":[{"content":"Contexto","children":[{"content":"<strong>Desafío:</strong> Uso de técnicas de IA, como deep fakes, para el acoso.","children":[],"payload":{"lines":"329,330"}},{"content":"<strong>Problema:</strong> Facilidad de implementación y potencial de daño significativo.","children":[],"payload":{"lines":"330,332"}}],"payload":{"lines":"328,329"}},{"content":"Declaración de Toronto (TD)","children":[{"content":"<strong>Base:</strong> Derechos humanos internacionales.","children":[],"payload":{"lines":"333,334"}},{"content":"<strong>Enfoque:</strong> Considerar efectos de segundo orden de la publicación abierta.","children":[],"payload":{"lines":"334,335"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aplicabilidad amplia y coherencia internacional.","children":[],"payload":{"lines":"336,337"}},{"content":"Raíces en las leyes internacionales de derechos humanos.","children":[],"payload":{"lines":"337,338"}}],"payload":{"lines":"335,338"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Falta de orientación prescriptiva sobre modelos de publicación alternativos.","children":[],"payload":{"lines":"339,340"}},{"content":"Necesidad de equilibrar investigación abierta con protección de derechos.","children":[],"payload":{"lines":"340,342"}}],"payload":{"lines":"338,342"}}],"payload":{"lines":"332,333"}},{"content":"Principios de IA de Asilomar (AAIP)","children":[{"content":"<strong>Elementos clave:</strong> Objetivos de investigación, financiación, cultura de investigación, prosperidad compartida.","children":[],"payload":{"lines":"343,344"}},{"content":"<strong>Enfoque:</strong> Establecer expectativas sobre problemas de investigación dignos de perseguir.","children":[],"payload":{"lines":"344,345"}},{"content":"<strong>Ventajas:</strong>","children":[{"content":"Aborda qué problemas de investigación perseguir.","children":[],"payload":{"lines":"346,347"}},{"content":"Equilibra costes y beneficios de la investigación para maximizar el beneficio.","children":[],"payload":{"lines":"347,348"}}],"payload":{"lines":"345,348"}},{"content":"<strong>Desafíos:</strong>","children":[{"content":"Orientaciones normativas sin casos de uso demostrados.","children":[],"payload":{"lines":"349,350"}},{"content":"Dificultad para evaluar la eficacia en la práctica.","children":[],"payload":{"lines":"350,352"}}],"payload":{"lines":"348,352"}}],"payload":{"lines":"342,343"}},{"content":"Comparación y Análisis","children":[{"content":"<strong>TD vs. AAIP:</strong>","children":[{"content":"<strong>TD:</strong> Foco en protección de derechos humanos y coherencia jurídica.","children":[],"payload":{"lines":"354,355"}},{"content":"<strong>AAIP:</strong> Enfoque en definir y equilibrar objetivos de investigación éticamente.","children":[],"payload":{"lines":"355,357"}}],"payload":{"lines":"353,357"}}],"payload":{"lines":"352,353"}},{"content":"Notas","children":[{"content":"Tanto <strong>TD</strong> como <strong>AAIP</strong> ofrecen marcos para proteger contra el acoso por IA.","children":[],"payload":{"lines":"358,359"}},{"content":"<strong>TD</strong> proporciona un fundamento en derechos humanos para una aplicación amplia.","children":[],"payload":{"lines":"359,360"}},{"content":"<strong>AAIP</strong> destaca la importancia de la elección y el equilibrio en la investigación.","children":[],"payload":{"lines":"360,361"}},{"content":"Ambos marcos enfrentan desafíos en proporcionar orientación específica y aplicable.","children":[],"payload":{"lines":"361,362"}},{"content":"<strong>Necesidad de Más Orientación:</strong> Hay una necesidad de directrices más específicas que puedan guiar prácticamente la implementación<br>\ny la toma de decisiones éticas en el uso de la IA para evitar el acoso.","children":[],"payload":{"lines":"362,364"}}],"payload":{"lines":"357,358"}}],"payload":{"lines":"326,327"}}],"payload":{"lines":"17,18"}}],"payload":{"lines":"1,2"}},{"colorFreezeLevel":3})</script>
</body>
</html>
