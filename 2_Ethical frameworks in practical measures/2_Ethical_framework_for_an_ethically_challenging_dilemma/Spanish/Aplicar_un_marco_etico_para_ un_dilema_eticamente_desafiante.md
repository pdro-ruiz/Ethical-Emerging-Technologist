# Aplicar marcos eticos a dilemas eticamente desafiantes

## General

### Convertir Principios Éticos en Acción

#### Escenarios a Cubrir
1. **Problema del Trolebús y Coches Autónomos:** Decisiones sobre quién salvar en situaciones de vida o muerte.
2. **Emergencias y Desastres:** Priorización y toma de decisiones críticas basadas en marcos éticos.
3. **Confidencialidad del Paciente en Salud:** Navegación por las leyes de privacidad como HIPAA y su relación con la ética.
4. **Cuestiones Sociales y Acoso por IA:** Abordaje del potencial de daño social y acoso por sistemas de IA.

#### Importancia de la Selección de Marcos
- Existen más de 85 marcos éticos, cada uno con un enfoque y audiencia específicos (por ejemplo, algunos están dirigidos a gobiernos, otros a individuos).


## Aplicacion del marco a dilemas eticos

### Aplicación de Marcos Éticos al Problema del Trolebús

#### Introducción al Dilema del Trolebús
- **Situación:** Trolebús desbocado se dirige hacia un grupo de personas atadas a las vías.
- **Opciones:**
  - No hacer nada: el trolebús mata al grupo.
  - Tirar de una palanca: desviar el trolebús, matar a una persona en vías adyacentes.
- **Dilema Ético:** ¿Cuál es la acción más ética?

#### Enfoque Utilitarista
- **Acción Preferida:** Tirar de la palanca para salvar al mayor número de personas.
- **Consideraciones:**
  - Participación directa en la muerte de una persona.
  - Debate sobre la responsabilidad moral por acción vs. inacción.

#### Aplicación de Marcos Éticos
1. **Declaración de Montreal para una IA Responsable (MDRAI):**
   - **Énfasis en:** Autonomía humana, consideración de todos los seres sintientes, responsabilidad en la acción e inacción.
   - **Ventajas:** Inclusión holística y énfasis en la responsabilidad.
   - **Desafíos:** Aplicabilidad limitada a escenarios específicos de IA.
   
2. **Principios de IA de Asilomar:**
   - **Principios Clave:** Seguridad, alineación de valores, transparencia de fallos.
   - **Ventajas:** Fomenta la preparación y conciencia sobre fallos de IA y decisiones seguras.
   - **Desafíos:** Aplicación genérica que podría adaptarse a conveniencia del decisor.

#### Notas
- **Importancia de Principios Rectores:** Ayudan a definir y guiar prácticas éticas en situaciones complejas.
- **Relevancia de Marcos Éticos:** Ambos marcos proporcionan perspectivas útiles pero difieren en aplicación y énfasis en la responsabilidad y transparencia.



### Resumen Esquemático: Uso de IA en Emergencias y Catástrofes

#### Contexto
- **Escenario:** Despliegue de tecnología de rastreo de contactos durante una pandemia para afinar la respuesta de salud pública.
- **Dilema:** Equilibrio entre seguridad pública y privacidad individual.

#### Aplicación de Marcos Éticos

1. **Directrices Universales para la IA (UGAI)**
   - **Enfoque en:** Seguridad pública y responsabilidad.
   - **Ventajas:**
     - Énfasis en mejorar la seguridad pública.
     - Cláusula de terminación para uso limitado y específico.
   - **Desafíos:**
     - Falta de concreción en la aplicación de principios.
     - Amplio margen para interpretación.
   
2. **Declaración de Toronto (DT)**
   - **Enfoque en:** No discriminación y derechos humanos internacionales.
   - **Ventajas:**
     - Aplicabilidad universal y aceptación transfronteriza.
     - Basado en principios de derechos humanos.
   - **Desafíos:**
     - Falta de orientación sólida sobre privacidad.
     - Posible insuficiencia en abordar todas las preocupaciones éticas.

#### Discusión
- **UGAI:** Proporciona una orientación ética clara para el rastreo de contactos con énfasis en la responsabilidad
   y seguridad pública, destacando una cláusula de terminación para evitar el abuso o uso prolongado indebido del sistema.
- **DT:** Centra en los derechos humanos y la no discriminación, ofreciendo un marco ético para equilibrar las necesidades de salud pública
   con la protección de la privacidad y los derechos individuales.




### IA en Medicina - Sesgo vs. Humanos

#### Contexto
- **Área de Aplicación:** Radiología y lectura de escáneres de imágenes médicas.
- **Dilema:** Sistemas de IA muestran mayor precisión que paneles médicos humanos pero carecen de capacidad explicativa.

#### Aplicación de Marcos Éticos

1. **Declaración de Montreal para una IA Responsable (MDR)**
   - **Principios Aplicables:** Prudencia, Autonomía Humana, Responsabilidad.
   - **Ventajas:**
     - Anticipa consecuencias negativas y asegura coherencia con decisiones humanas.
     - Fomenta el control humano significativo e impulsa la confianza.
   - **Desafíos:**
     - Margen de interpretación puede llevar a aplicaciones inconsistentes.
     - Necesita respaldo de instrumentos regulatorios.

2. **Principios de la IA de Pekín**
   - **Principios Aplicables:** Consentimiento Informado, Formación Educativa.
   - **Ventajas:**
     - Promueve comprensión de riesgos por parte del paciente.
     - Prepara a médicos para manejar fallos del sistema y comunicar riesgos.
   - **Desafíos:**
     - Falta de detalles sobre la implementación práctica de principios.
     - Cuestiones sobre la suficiencia de la formación educativa y el consentimiento informado.

#### Comparación y Conclusión

- **MDR vs. Principios de Pekín:** Ambos marcos ofrecen perspectivas útiles para abordar el dilema ético, centrando la atención en la prudencia, la autonomía, la responsabilidad, y el consentimiento informado como fundamentos para el uso ético de IA en la medicina.
- **Eficacia:** MDR proporciona un enfoque holístico que abarca la confianza y los valores de la organización, mientras que los Principios de Pekín se centran en el consentimiento y la preparación del paciente y el profesional médico.
- **Implementación:** Ambos marcos enfrentan desafíos en la aplicación práctica, necesitando claridad y apoyo regulatorio para garantizar su efectividad.



### IA y Comportamientos Autodestructivos

#### Contexto
- **Escenario:** Uso de IA en redes sociales que promueve comportamientos adictivos a través del desplazamiento interminable y contenidos hiper personalizados.
- **Dilema:** Balance entre maximizar beneficios empresariales y preservar el bienestar de los usuarios.

#### Aplicación de Marcos Éticos

1. **Directrices Universales para la IA (UGAI)**
   - **Principios Aplicables:** Calidad de Datos, Prohibición de Perfiles Secretos, Seguridad Pública.
   - **Ventajas:**
     - Cobertura amplia de preocupaciones éticas.
     - Orienta hacia el beneficio de los usuarios.
   - **Desafíos:**
     - Falta de directrices concretas para la implementación.

2. **Principios de la IA de Pekín**
   - **Principios Aplicables:** Consentimiento Informado, Ética por Diseño.
   - **Ventajas:**
     - Promueve consideraciones éticas desde el desarrollo inicial.
     - Prevención de interfaces adictivas y sistemas de recompensa perjudiciales.
   - **Desafíos:**
     - Margen de interpretación amplio.
     - Falta de especificidad en la implementación.

#### Comparación y Conclusión

- **UGAI** enfatiza en el uso adecuado de datos y el impacto social, proporcionando un marco para equilibrar la ganancia empresarial
  con el bienestar de los usuarios. Sin embargo, carece de pautas detalladas para la práctica.
- **Principios de Pekín** se centran en el consentimiento informado y la inclusión de consideraciones éticas en el diseño, 
  apoyando el desarrollo de sistemas menos perjudiciales desde el inicio. No obstante, la vaguedad en la aplicación práctica podría limitar su efectividad.
- **Enfoque Recomendado:** La combinación de ambos marcos puede ofrecer un enfoque equilibrado, asegurando tanto la responsabilidad
   en el uso de datos como la incorporación de ética en el diseño y desarrollo de IA, para mitigar comportamientos autodestructivos entre los usuarios.



### Límites de la Tecnología Persuasiva en Juguetes Inteligentes

#### Contexto
- **Escenario:** Uso de IA en juguetes inteligentes para influir en comportamientos de menores, como persuadirlos para que deseen ciertas marcas.
- **Preocupación:** Tecnología altamente persuasiva dirigida a un público vulnerable (niños).

#### Aplicación de Marcos Éticos

1. **Principios de la IA de la OCDE**
   - **Enfoque:** Divulgación responsable, transparencia, privacidad, bienestar.
   - **Ventajas:**
     - Equilibrio entre divulgación responsable y bienestar.
     - Alineación con entornos legales y regulatorios.
   - **Desafíos:**
     - Carácter normativo sin casos de uso demostrados.

2. **Directrices Éticas sobre IA no Confiable**
   - **Enfoque:** Respeto a la autonomía humana, privacidad, gobernanza de datos, bienestar.
   - **Ventajas:**
     - Orientación granular con casos de uso efectivos.
     - Proximidad a requisitos legales y regulatorios.
   - **Desafíos:**
     - Perspectiva enfocada en la legislación de la UE, puede requerir adaptación fuera de Europa.

#### Comparación y Análisis

- **OCDE vs. Directrices Éticas no Confiables:** Los principios de la OCDE proporcionan un marco general para el desarrollo ético,
  mientras que las Directrices Éticas ofrecen una orientación más detallada y pragmática, especialmente en lo que respecta a la autonomía y seguridad de los menores.
- **Impacto en el Desarrollo de Productos:** Ambos marcos buscan guiar la creación de productos que respeten la autonomía de los usuarios
   y promuevan su bienestar, aunque desde diferentes niveles de detalle y aplicabilidad geográfica.

#### Notas

- **Equilibrio Ético:** Es crucial equilibrar la innovación tecnológica con la protección de los usuarios vulnerables, 
  asegurando que la tecnología persuasiva no comprometa el bienestar ni la autonomía de los niños.
- **Elección de Marco:** Dependerá de las necesidades específicas de la organización y el contexto jurisdiccional en el que opere,
  aunque la tendencia es hacia una aplicación ética granular y basada en casos de uso demostrados.




### Violación de la Confidencialidad del Paciente por Incumplimiento

#### Contexto
- **Escenario:** Uso de chatbots con PNL para asistencia no médica en salud mental.
- **Dilema:** Equilibrar la privacidad del usuario con la necesidad de intervención en caso de riesgo de autolesión o suicidio.

#### Aplicación de Marcos Éticos

1. **Diseño Éticamente Alineado (EAD) del IEEE**
   - **Principios Clave:** Ética por diseño, privacidad informática afectiva, bienestar.
   - **Enfoque:**
     - Equilibrio entre el apoyo al usuario y la prevención de dependencias perjudiciales.
     - Privacidad con límites claros, pero permitiendo intervenciones en caso de riesgo vital.
   - **Ventajas:**
     - Consideración explícita de la computación afectiva y el bienestar junto a la privacidad.
   - **Desafíos:**
     - Recomendaciones de alto nivel sujetas a interpretación, posibilidad de esquivar responsabilidades.

2. **Principios de la IA de Asilomar**
   - **Principios Clave:** Seguridad y transparencia de fallos.
   - **Enfoque:**
     - Divulgación equilibrada y seguridad de la vida humana.
     - Conciencia de las limitaciones del sistema para gestionar expectativas.
   - **Ventajas:**
     - Mención explícita de la transparencia de fallos, crucial en salud mental.
   - **Desafíos:**
     - Principios de muy alto nivel y genéricos, dificultad en la implementación práctica.

#### Análisis Comparativo

- **EAD vs. Asilomar:** 
  - EAD proporciona un enfoque más completo al incluir la computación afectiva, pero puede ser vago en su aplicación.
  - Asilomar enfatiza la seguridad y la transparencia, esencial en el contexto de la salud mental, pero carece de especificidad operativa.

#### Conclusión

- **Implicación Ética:** Ambos marcos sugieren la importancia de mantener un equilibrio ético entre la confidencialidad del paciente
  y la intervención necesaria en casos de emergencia.
- **Desafío en la Implementación:** La falta de concreción en las directrices plantea retos en la aplicación efectiva 
  y la toma de decisiones éticas responsables.
- **Consideración de los Principios:** A pesar de sus diferencias, ambos marcos subrayan la prioridad de la seguridad del usuario 
  y la necesidad de una intervención ética informada.



### Beneficios Individuales vs. Daño al Tejido Social

#### Contexto
- **Desafío:** Libertad de expresión en redes sociales vs. impacto negativo en la sociedad.
- **Conflicto:** Entre autonomía individual y bienestar colectivo.

#### Aplicación de Marcos Éticos

1. **Diseño Éticamente Alineado (EAD) del IEEE**
   - **Principios Clave:** Autonomía individual, garantizar bienestar social.
   - **Enfoque:** Balance entre potenciar la autonomía individual y restricciones para proteger la comunidad.
   - **Ventajas:** 
     - Llamada explícita a la autonomía de los individuos.
     - Flexibilidad para incluir necesidades comunitarias.
   - **Desafíos:** 
     - Falta de especificidad para moderación de contenidos.

2. **Principios de Santa Clara sobre Transparencia y Responsabilidad en Moderación de Contenidos**
   - **Especialización:** Orientado a medios de comunicación, subsana lagunas de la EAD en moderación de contenidos.

3. **Directriz Ética para una IA Digna de Confianza**
   - **Principios Clave:** Responsabilidad, supervisión humana, bienestar de la sociedad.
   - **Enfoque:** Marco basado en riesgos para balancear responsabilidad y supervisión con bienestar colectivo.
   - **Ventajas:** 
     - Supervisión humana y responsabilidad definidas explícitamente.
     - Fortalecimiento de cultura, valores y normas sociales.
   - **Desafíos:** 
     - Falta de especificidad para moderación de contenidos.
     - Enfoque regional puede limitar aplicabilidad global.

#### Análisis Comparativo

- **EAD vs. Directrices Éticas:** EAD proporciona un marco amplio para potenciar la autonomía, pero carece de enfoque específico en moderación. 
  Las Directrices Éticas ofrecen un marco basado en riesgos con énfasis en el bienestar colectivo, pero su aplicación puede ser regionalmente limitada.

#### Notas

- **Combinación de Marcos:** Integrar múltiples marcos puede ofrecer un equilibrio más efectivo entre beneficios individuales y responsabilidad social.
- **Desafío de Implementación:** La falta de especificidad en la moderación de contenidos y la variabilidad regional requiere 
  un enfoque adaptativo y posiblemente combinado para abordar eficazmente el dilema.




### Emancipación de Sistemas de IA de Supervisión Humana

#### Contexto
- **Desafío:** Sistemas de IA operan sin supervisión humana significativa.
- **Problema:** Dificultad para garantizar el bienestar y otros resultados prosociales.

#### Principios de Beijing sobre la IA (BAIP)
- **Enfoque:** Riesgos de control y apertura/intercambio.
- **Ventajas:**
  - Identifica explícitamente los riesgos de control.
  - Propone apertura e intercambio para supervisión pública y rendición de cuentas.
- **Desafíos:**
  - Falta de consejos específicos y procesables.
  - Señala áreas para investigación sin recomendaciones detalladas.

#### Principios de la IA de la OCDE
- **Enfoque:** Intervención humana adecuada, oposición a la emancipación completa de supervisión humana.
- **Ventajas:**
  - Orientación arraigada en legislación de derechos humanos.
  - Directrices claras para mantener controles humanos.
- **Desafíos:**
  - De muy alto nivel, abstractos, y abiertos a interpretación.
  - Riesgo de afirmar adhesión sin cumplimiento efectivo.

#### Comparación y Análisis
- **BAIP vs. OCDE:**
  - **BAIP:** Centrados en identificar riesgos y promover la apertura para la supervisión. Carecen de especificidad.
  - **OCDE:** Enfatizan la necesidad de control humano y están bien alineados con requisitos legales, pero son abstractos.

#### Notas
- La **emancipación de la IA** de la supervisión humana presenta desafíos únicos en términos de riesgos de control y la garantía del bienestar humano.
- **BAIP** proporciona un marco para la supervisión pública, mientras que **OCDE** aboga por mantener los controles humanos.
- Ambos enfoques presentan ventajas en términos de concienciación sobre riesgos y promoción de la apertura, 
  pero carecen de directrices detalladas para la implementación práctica.
- **Necesidad de Equilibrio:** Entre la autonomía operativa de los sistemas de IA y la supervisión humana efectiva 
  para asegurar resultados éticos y prosociales.




### Protección Contra el Acoso por IA

#### Contexto
- **Desafío:** Uso de técnicas de IA, como deep fakes, para el acoso.
- **Problema:** Facilidad de implementación y potencial de daño significativo.

#### Declaración de Toronto (TD)
- **Base:** Derechos humanos internacionales.
- **Enfoque:** Considerar efectos de segundo orden de la publicación abierta.
- **Ventajas:**
  - Aplicabilidad amplia y coherencia internacional.
  - Raíces en las leyes internacionales de derechos humanos.
- **Desafíos:**
  - Falta de orientación prescriptiva sobre modelos de publicación alternativos.
  - Necesidad de equilibrar investigación abierta con protección de derechos.

#### Principios de IA de Asilomar (AAIP)
- **Elementos clave:** Objetivos de investigación, financiación, cultura de investigación, prosperidad compartida.
- **Enfoque:** Establecer expectativas sobre problemas de investigación dignos de perseguir.
- **Ventajas:**
  - Aborda qué problemas de investigación perseguir.
  - Equilibra costes y beneficios de la investigación para maximizar el beneficio.
- **Desafíos:**
  - Orientaciones normativas sin casos de uso demostrados.
  - Dificultad para evaluar la eficacia en la práctica.

#### Comparación y Análisis
- **TD vs. AAIP:**
  - **TD:** Foco en protección de derechos humanos y coherencia jurídica.
  - **AAIP:** Enfoque en definir y equilibrar objetivos de investigación éticamente.

#### Notas
- Tanto **TD** como **AAIP** ofrecen marcos para proteger contra el acoso por IA.
- **TD** proporciona un fundamento en derechos humanos para una aplicación amplia.
- **AAIP** destaca la importancia de la elección y el equilibrio en la investigación.
- Ambos marcos enfrentan desafíos en proporcionar orientación específica y aplicable.
- **Necesidad de Más Orientación:** Hay una necesidad de directrices más específicas que puedan guiar prácticamente la implementación
   y la toma de decisiones éticas en el uso de la IA para evitar el acoso.