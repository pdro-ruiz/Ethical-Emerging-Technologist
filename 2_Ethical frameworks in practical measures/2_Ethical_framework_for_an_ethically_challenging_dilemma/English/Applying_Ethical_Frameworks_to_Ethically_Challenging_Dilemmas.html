<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.16.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:H,mm:ae}=window,W=new H.Toolbar;W.attach(ae);const we=W.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((o,T,c,r)=>{const g=o();window.mm=g.Markmap.create("svg#mindmap",(T||g.deriveOptions)(r),c)})(()=>window.markmap,null,{"content":"Applying Ethical Frameworks to Ethically Challenging Dilemmas","children":[{"content":"General","children":[{"content":"Turning Ethical Principles into Action","children":[{"content":"Scenarios to Cover","children":[{"content":"<strong>Trolley Problem and Autonomous Cars:</strong> Decisions about who to save in life-or-death situations.","children":[],"payload":{"lines":"8,9"}},{"content":"<strong>Emergencies and Disasters:</strong> Prioritization and critical decision-making based on ethical frameworks.","children":[],"payload":{"lines":"9,10"}},{"content":"<strong>Patient Confidentiality in Health:</strong> Navigating privacy laws like HIPAA and their relation to ethics.","children":[],"payload":{"lines":"10,11"}},{"content":"<strong>Social Issues and Harassment by AI:</strong> Addressing the potential for social harm and harassment by AI systems.","children":[],"payload":{"lines":"11,13"}}],"payload":{"lines":"7,8"}},{"content":"Importance of Framework Selection","children":[{"content":"There are over 85 ethical frameworks, each with a specific focus and audience (e.g., some are aimed at governments, others at individuals).","children":[],"payload":{"lines":"14,15"}}],"payload":{"lines":"13,14"}}],"payload":{"lines":"5,6"}}],"payload":{"lines":"3,4"}},{"content":"Application of Frameworks to Ethical Dilemmas","children":[{"content":"Applying Ethical Frameworks to the Trolley Problem","children":[{"content":"Introduction to the Trolley Problem","children":[{"content":"<strong>Situation:</strong> A runaway trolley is headed towards a group of people tied to the tracks.","children":[],"payload":{"lines":"22,23"}},{"content":"<strong>Options:</strong>","children":[{"content":"Do nothing: the trolley kills the group.","children":[],"payload":{"lines":"24,25"}},{"content":"Pull a lever: divert the trolley, killing one person on adjacent tracks.","children":[],"payload":{"lines":"25,26"}}],"payload":{"lines":"23,26"}},{"content":"<strong>Ethical Dilemma:</strong> What is the most ethical action?","children":[],"payload":{"lines":"26,28"}}],"payload":{"lines":"21,22"}},{"content":"Utilitarian Approach","children":[{"content":"<strong>Preferred Action:</strong> Pull the lever to save the greater number of people.","children":[],"payload":{"lines":"29,30"}},{"content":"<strong>Considerations:</strong>","children":[{"content":"Direct involvement in the death of one person.","children":[],"payload":{"lines":"31,32"}},{"content":"Debate on moral responsibility for action vs. inaction.","children":[],"payload":{"lines":"32,34"}}],"payload":{"lines":"30,34"}}],"payload":{"lines":"28,29"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"35,36\"><strong>Montreal Declaration for a Responsible AI (MDRAI):</strong></p>","children":[{"content":"<strong>Emphasis on:</strong> Human autonomy, consideration of all sentient beings, responsibility in action and inaction.","children":[],"payload":{"lines":"36,37"}},{"content":"<strong>Advantages:</strong> Holistic inclusion and emphasis on responsibility.","children":[],"payload":{"lines":"37,38"}},{"content":"<strong>Challenges:</strong> Limited applicability to specific AI scenarios.","children":[],"payload":{"lines":"38,40"}}],"payload":{"lines":"35,40"}},{"content":"<p data-lines=\"40,41\"><strong>Asilomar AI Principles:</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Safety, value alignment, transparency of failures.","children":[],"payload":{"lines":"41,42"}},{"content":"<strong>Advantages:</strong> Promotes preparedness and awareness of AI failures and safe decisions.","children":[],"payload":{"lines":"42,43"}},{"content":"<strong>Challenges:</strong> Generic application that could be tailored at the decider's convenience.","children":[],"payload":{"lines":"43,45"}}],"payload":{"lines":"40,45"}}],"payload":{"lines":"34,35"}},{"content":"Conclusion","children":[{"content":"<strong>Importance of Guiding Principles:</strong> They help define and guide ethical practices in complex situations.","children":[],"payload":{"lines":"46,47"}},{"content":"<strong>Relevance of Ethical Frameworks:</strong> Both frameworks provide useful perspectives but differ in application and emphasis on responsibility and transparency.","children":[],"payload":{"lines":"47,48"}}],"payload":{"lines":"45,46"}}],"payload":{"lines":"19,20"}},{"content":"Schematic Summary: Use of AI in Emergencies and Disasters","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Deployment of contact tracing technology during a pandemic to fine-tune public health response.","children":[],"payload":{"lines":"54,55"}},{"content":"<strong>Dilemma:</strong> Balance between public safety and individual privacy.","children":[],"payload":{"lines":"55,57"}}],"payload":{"lines":"53,54"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"59,60\"><strong>Universal Guidelines for AI (UGAI)</strong></p>","children":[{"content":"<strong>Focus on:</strong> Public safety and accountability.","children":[],"payload":{"lines":"60,61"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Emphasis on enhancing public safety.","children":[],"payload":{"lines":"62,63"}},{"content":"Termination clause for limited and specific use.","children":[],"payload":{"lines":"63,64"}}],"payload":{"lines":"61,64"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of concreteness in principle application.","children":[],"payload":{"lines":"65,66"}},{"content":"Wide margin for interpretation.","children":[],"payload":{"lines":"66,68"}}],"payload":{"lines":"64,68"}}],"payload":{"lines":"59,68"}},{"content":"<p data-lines=\"68,69\"><strong>Toronto Declaration (TD)</strong></p>","children":[{"content":"<strong>Focus on:</strong> Non-discrimination and international human rights.","children":[],"payload":{"lines":"69,70"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Universal applicability and cross-border acceptance.","children":[],"payload":{"lines":"71,72"}},{"content":"Based on human rights principles.","children":[],"payload":{"lines":"72,73"}}],"payload":{"lines":"70,73"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of solid guidance on privacy.","children":[],"payload":{"lines":"74,75"}},{"content":"Potential insufficiency in addressing all ethical concerns.","children":[],"payload":{"lines":"75,77"}}],"payload":{"lines":"73,77"}}],"payload":{"lines":"68,77"}}],"payload":{"lines":"57,58"}},{"content":"Discussion","children":[{"content":"<strong>UGAI:</strong> Provides clear ethical guidance for contact tracing with an emphasis on accountability<br>\nand public safety, highlighting a termination clause to prevent misuse or undue prolonged use of the system.","children":[],"payload":{"lines":"78,80"}},{"content":"<strong>TD:</strong> Focuses on human rights and non-discrimination, offering an ethical framework to balance public health needs<br>\nwith the protection of privacy and individual rights.","children":[],"payload":{"lines":"80,83"}}],"payload":{"lines":"77,78"}},{"content":"Conclusion","children":[{"content":"Both frameworks offer valuable perspectives for addressing the use of AI in emergency situations,<br>\nhighlighting the importance of maintaining a balance between public safety and the protection of privacy and human rights.<br>\nThe choice of framework depends on the specific priorities and context of the situation.","children":[],"payload":{"lines":"84,87"}}],"payload":{"lines":"83,84"}}],"payload":{"lines":"51,52"}},{"content":"AI in Medicine - Bias vs. Humans","children":[{"content":"Context","children":[{"content":"<strong>Application Area:</strong> Radiology and reading of medical imaging scans.","children":[],"payload":{"lines":"93,94"}},{"content":"<strong>Dilemma:</strong> AI systems show greater accuracy than human medical panels but lack explanatory capability.","children":[],"payload":{"lines":"94,96"}}],"payload":{"lines":"92,93"}},{"content":"Application of Ethical Frameworks","children":[{"content":"","children":[{"content":"<p data-lines=\"98,99\"><strong>Montreal Declaration for a Responsible AI (MDR)</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Prudence, Human Autonomy, Responsibility.","children":[],"payload":{"lines":"99,100"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Anticipates negative consequences and ensures coherence with human decisions.","children":[],"payload":{"lines":"101,102"}},{"content":"Promotes significant human control and boosts trust.","children":[],"payload":{"lines":"102,103"}}],"payload":{"lines":"100,103"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Margin of interpretation can lead to inconsistent applications.","children":[],"payload":{"lines":"104,105"}},{"content":"Needs backing from regulatory instruments.","children":[],"payload":{"lines":"105,107"}}],"payload":{"lines":"103,107"}}],"payload":{"lines":"98,107"}},{"content":"<p data-lines=\"107,108\"><strong>Beijing AI Principles</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Informed Consent, Educational Formation.","children":[],"payload":{"lines":"108,109"}},{"content":"<strong>Advantages:</strong>","children":[],"payload":{"lines":"109,110"}}],"payload":{"lines":"107,110"}}],"payload":{"lines":"98,110"}},{"content":"Promotes patient understanding of risks.","children":[{"content":"Prepares doctors to handle system failures and communicate risks.","children":[],"payload":{"lines":"113,114"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of details on the practical implementation of principles.","children":[],"payload":{"lines":"115,116"}},{"content":"Questions on the sufficiency of educational formation and informed consent.","children":[],"payload":{"lines":"116,118"}}],"payload":{"lines":"114,118"}}],"payload":{"lines":"112,118"}}],"payload":{"lines":"96,97"}},{"content":"Comparison and Conclusion","children":[{"content":"<strong>MDR vs. Beijing Principles:</strong> Both frameworks offer useful perspectives for addressing the ethical dilemma, focusing attention on prudence, autonomy, responsibility, and informed consent as foundations for the ethical use of AI in medicine.","children":[],"payload":{"lines":"120,121"}},{"content":"<strong>Effectiveness:</strong> MDR provides a holistic approach encompassing trust and organizational values, while the Beijing Principles focus on consent and preparation of the patient and medical professional.","children":[],"payload":{"lines":"121,122"}},{"content":"<strong>Implementation:</strong> Both frameworks face challenges in practical application, needing clarity and regulatory support to ensure their effectiveness.","children":[],"payload":{"lines":"122,123"}}],"payload":{"lines":"118,119"}}],"payload":{"lines":"90,91"}},{"content":"AI and Self-Destructive Behaviors","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of AI in social media that promotes addictive behaviors through endless scrolling and hyper-personalized content.","children":[],"payload":{"lines":"129,130"}},{"content":"<strong>Dilemma:</strong> Balance between maximizing business profits and preserving user well-being.","children":[],"payload":{"lines":"130,132"}}],"payload":{"lines":"128,129"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"134,135\"><strong>Universal Guidelines for AI (UGAI)</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Data Quality, Prohibition of Secret Profiling, Public Safety.","children":[],"payload":{"lines":"135,136"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Wide coverage of ethical concerns.","children":[],"payload":{"lines":"137,138"}},{"content":"Guides towards user benefit.","children":[],"payload":{"lines":"138,139"}}],"payload":{"lines":"136,139"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of concrete guidelines for implementation.","children":[],"payload":{"lines":"140,142"}}],"payload":{"lines":"139,142"}}],"payload":{"lines":"134,142"}},{"content":"<p data-lines=\"142,143\"><strong>Beijing AI Principles</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Informed Consent, Ethics by Design.","children":[],"payload":{"lines":"143,144"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Promotes ethical considerations from initial development.","children":[],"payload":{"lines":"145,146"}},{"content":"Prevention of addictive interfaces and harmful reward systems.","children":[],"payload":{"lines":"146,147"}}],"payload":{"lines":"144,147"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Wide margin for interpretation.","children":[],"payload":{"lines":"148,149"}},{"content":"Lack of specificity in implementation.","children":[],"payload":{"lines":"149,151"}}],"payload":{"lines":"147,151"}}],"payload":{"lines":"142,151"}}],"payload":{"lines":"132,133"}},{"content":"Comparison and Conclusion","children":[{"content":"<strong>UGAI</strong> emphasizes the proper use of data and social impact, providing a framework for balancing business gain<br>\nwith user well-being. However, it lacks detailed guidelines for practice.","children":[],"payload":{"lines":"153,155"}},{"content":"<strong>Beijing Principles</strong> focus on informed consent and the inclusion of ethical considerations in design,<br>\nsupporting the development of less harmful systems from the start. However, vagueness in practical application could limit its effectiveness.","children":[],"payload":{"lines":"155,157"}},{"content":"<strong>Recommended Approach:</strong> Combining both frameworks may offer a balanced approach, ensuring both responsibility<br>\nin data use and the incorporation of ethics in AI design and development, to mitigate self-destructive behaviors among users.","children":[],"payload":{"lines":"157,159"}}],"payload":{"lines":"151,152"}}],"payload":{"lines":"126,127"}},{"content":"Limits of Persuasive Technology in Smart Toys","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of AI in smart toys to influence children's behaviors, such as persuading them to desire certain brands.","children":[],"payload":{"lines":"165,166"}},{"content":"<strong>Concern:</strong> Highly persuasive technology aimed at a vulnerable audience (children).","children":[],"payload":{"lines":"166,168"}}],"payload":{"lines":"164,165"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"170,171\"><strong>OECD AI Principles</strong></p>","children":[{"content":"<strong>Focus:</strong> Responsible disclosure, transparency, privacy, societal well-being.","children":[],"payload":{"lines":"171,172"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Balance between responsible disclosure and societal well-being.","children":[],"payload":{"lines":"173,174"}},{"content":"Alignment with legal and regulatory environments.","children":[],"payload":{"lines":"174,175"}}],"payload":{"lines":"172,175"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Normative character without demonstrated use cases.","children":[],"payload":{"lines":"176,178"}}],"payload":{"lines":"175,178"}}],"payload":{"lines":"170,178"}},{"content":"<p data-lines=\"178,179\"><strong>Ethical Guidelines on Untrustworthy AI</strong></p>","children":[{"content":"<strong>Focus:</strong> Respect for human autonomy, privacy, data governance, societal well-being.","children":[],"payload":{"lines":"179,180"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Granular guidance with effective use cases.","children":[],"payload":{"lines":"181,182"}},{"content":"Proximity to legal and regulatory requirements.","children":[],"payload":{"lines":"182,183"}}],"payload":{"lines":"180,183"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Focus on EU legislation, may require adaptation outside Europe.","children":[],"payload":{"lines":"184,186"}}],"payload":{"lines":"183,186"}}],"payload":{"lines":"178,186"}}],"payload":{"lines":"168,169"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>OECD vs. Ethical Guidelines:</strong> OECD principles provide a general framework for ethical development,<br>\nwhile Ethical Guidelines offer more detailed and pragmatic guidance, especially regarding the autonomy and safety of minors.","children":[],"payload":{"lines":"188,190"}},{"content":"<strong>Impact on Product Development:</strong> Both frameworks seek to guide the creation of products that respect user autonomy<br>\nand promote their well-being, though from different levels of detail and geographic applicability.","children":[],"payload":{"lines":"190,193"}}],"payload":{"lines":"186,187"}},{"content":"Conclusion","children":[{"content":"<strong>Ethical Balance:</strong> It's crucial to balance technological innovation with the protection of vulnerable users,<br>\nensuring that persuasive technology does not compromise the well-being or autonomy of children.","children":[],"payload":{"lines":"195,197"}},{"content":"<strong>Framework Choice:</strong> Will depend on the specific needs of the organization and the jurisdictional context in which it operates,<br>\nthough the trend is towards granular and use-case-based ethical application.","children":[],"payload":{"lines":"197,199"}}],"payload":{"lines":"193,194"}}],"payload":{"lines":"162,163"}},{"content":"Patient Confidentiality Breach by Compliance Failure","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of NLP chatbots for non-medical mental health assistance.","children":[],"payload":{"lines":"206,207"}},{"content":"<strong>Dilemma:</strong> Balancing user privacy with the need for intervention in cases of self-harm or suicide risk.","children":[],"payload":{"lines":"207,209"}}],"payload":{"lines":"205,206"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<strong>IEEE Ethically Aligned Design (EAD)</strong>","children":[{"content":"<strong>Key Principles:</strong> Ethics by design, affective computing privacy, well-being.","children":[],"payload":{"lines":"212,213"}},{"content":"<strong>Approach:</strong>","children":[{"content":"Balance between user support and prevention of harmful dependencies.","children":[],"payload":{"lines":"214,215"}},{"content":"Privacy with clear boundaries, yet allowing interventions in case of vital risk.","children":[],"payload":{"lines":"215,216"}}],"payload":{"lines":"213,216"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit consideration of affective computing and well-being alongside privacy.","children":[],"payload":{"lines":"217,218"}}],"payload":{"lines":"216,218"}},{"content":"**Ch","children":[],"payload":{"lines":"218,220"}}],"payload":{"lines":"211,220"}},{"content":"<strong>Asilomar AI Principles</strong>","children":[{"content":"<strong>Key Principles:</strong> Safety and transparency of failures.","children":[],"payload":{"lines":"224,225"}},{"content":"<strong>Approach:</strong>","children":[{"content":"Balanced disclosure and human life safety.","children":[],"payload":{"lines":"226,227"}},{"content":"Awareness of system limitations to manage expectations.","children":[],"payload":{"lines":"227,228"}}],"payload":{"lines":"225,228"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit mention of failure transparency, crucial in mental health.","children":[],"payload":{"lines":"229,230"}}],"payload":{"lines":"228,230"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Very high-level and generic principles, difficulty in practical implementation.","children":[],"payload":{"lines":"231,233"}}],"payload":{"lines":"230,233"}}],"payload":{"lines":"223,233"}}],"payload":{"lines":"209,210"}},{"content":"Comparative Analysis","children":[{"content":"<strong>EAD vs. Asilomar:</strong>","children":[{"content":"EAD provides a more comprehensive approach by including affective computing, but can be vague in its application.","children":[],"payload":{"lines":"236,237"}},{"content":"Asilomar emphasizes safety and transparency, essential in the context of mental health, but lacks operational specificity.","children":[],"payload":{"lines":"237,239"}}],"payload":{"lines":"235,239"}}],"payload":{"lines":"233,234"}},{"content":"Conclusion","children":[{"content":"<strong>Ethical Implication:</strong> Both frameworks suggest the importance of maintaining an ethical balance between patient confidentiality<br>\nand necessary intervention in emergency cases.","children":[],"payload":{"lines":"241,243"}},{"content":"<strong>Implementation Challenge:</strong> The lack of concreteness in guidelines poses challenges in effective application<br>\nand responsible ethical decision-making.","children":[],"payload":{"lines":"243,245"}},{"content":"<strong>Consideration of Principles:</strong> Despite their differences, both frameworks underline the priority of user safety<br>\nand the need for informed ethical intervention.","children":[],"payload":{"lines":"245,247"}}],"payload":{"lines":"239,240"}}],"payload":{"lines":"203,204"}},{"content":"Individual Benefits vs. Harm to Social Fabric","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> Free speech on social media vs. negative societal impact.","children":[],"payload":{"lines":"253,254"}},{"content":"<strong>Conflict:</strong> Between individual autonomy and collective well-being.","children":[],"payload":{"lines":"254,256"}}],"payload":{"lines":"252,253"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"258,259\"><strong>IEEE Ethically Aligned Design (EAD)</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Individual autonomy, ensuring social well-being.","children":[],"payload":{"lines":"259,260"}},{"content":"<strong>Approach:</strong> Balance between empowering individual autonomy and restrictions to protect the community.","children":[],"payload":{"lines":"260,261"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit call to individual autonomy.","children":[],"payload":{"lines":"262,263"}},{"content":"Flexibility to include community needs.","children":[],"payload":{"lines":"263,264"}}],"payload":{"lines":"261,264"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of specificity for content moderation.","children":[],"payload":{"lines":"265,267"}}],"payload":{"lines":"264,267"}}],"payload":{"lines":"258,267"}},{"content":"<p data-lines=\"267,268\"><strong>Santa Clara Principles on Transparency and Accountability in Content Moderation</strong></p>","children":[{"content":"<strong>Specialization:</strong> Aimed at media, addresses gaps of EAD in content moderation.","children":[],"payload":{"lines":"268,270"}}],"payload":{"lines":"267,270"}},{"content":"<p data-lines=\"270,271\"><strong>Ethical Guideline for Trustworthy AI</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Accountability, human oversight, societal well-being.","children":[],"payload":{"lines":"271,272"}},{"content":"<strong>Approach:</strong> Risk-based framework to balance accountability and oversight with collective well-being.","children":[],"payload":{"lines":"272,273"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Human oversight and accountability defined explicitly.","children":[],"payload":{"lines":"274,275"}},{"content":"Strengthening of culture, values, and social norms.","children":[],"payload":{"lines":"275,276"}}],"payload":{"lines":"273,276"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of specificity for content moderation.","children":[],"payload":{"lines":"277,278"}},{"content":"Regional focus may limit global applicability.","children":[],"payload":{"lines":"278,280"}}],"payload":{"lines":"276,280"}}],"payload":{"lines":"270,280"}}],"payload":{"lines":"256,257"}},{"content":"Comparative Analysis","children":[{"content":"<strong>EAD vs. Ethical Guidelines:</strong> EAD provides a broad framework for empowering autonomy, but lacks a specific focus on moderation.<br>\nEthical Guidelines offer a risk-based framework with an emphasis on collective well-being, but its application may be regionally limited.","children":[],"payload":{"lines":"282,285"}}],"payload":{"lines":"280,281"}},{"content":"Conclusion","children":[{"content":"<strong>Combination of Frameworks:</strong> Integrating multiple frameworks may offer a more effective balance between individual benefits and social responsibility.","children":[],"payload":{"lines":"287,288"}},{"content":"<strong>Implementation Challenge:</strong> The lack of specificity in content moderation and regional variability requires<br>\nan adaptive and possibly combined approach to effectively address the dilemma.","children":[],"payload":{"lines":"288,290"}}],"payload":{"lines":"285,286"}}],"payload":{"lines":"250,251"}},{"content":"Emancipation of AI Systems from Human Oversight","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> AI systems operate without significant human oversight.","children":[],"payload":{"lines":"297,298"}},{"content":"<strong>Problem:</strong> Difficulty in ensuring well-being and other pro-social outcomes.","children":[],"payload":{"lines":"298,300"}}],"payload":{"lines":"296,297"}},{"content":"Beijing AI Principles (BAIP)","children":[{"content":"<strong>Approach:</strong> Control risks and openness/exchange.","children":[],"payload":{"lines":"301,302"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicitly identifies control risks.","children":[],"payload":{"lines":"303,304"}},{"content":"Proposes openness and exchange for public oversight and accountability.","children":[],"payload":{"lines":"304,305"}}],"payload":{"lines":"302,305"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of actionable advice.","children":[],"payload":{"lines":"306,307"}},{"content":"Points to areas for research without detailed recommendations.","children":[],"payload":{"lines":"307,309"}}],"payload":{"lines":"305,309"}}],"payload":{"lines":"300,301"}},{"content":"OECD AI Principles","children":[{"content":"<strong>Approach:</strong> Adequate human intervention, opposition to complete emancipation from human oversight.","children":[],"payload":{"lines":"310,311"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Guidance grounded in human rights legislation.","children":[],"payload":{"lines":"312,313"}},{"content":"Clear guidelines for maintaining human controls.","children":[],"payload":{"lines":"313,314"}}],"payload":{"lines":"311,314"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Very high level, abstract, and open to interpretation.","children":[],"payload":{"lines":"315,316"}},{"content":"Risk of claiming adherence without effective compliance.","children":[],"payload":{"lines":"316,318"}}],"payload":{"lines":"314,318"}}],"payload":{"lines":"309,310"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>BAIP vs. OECD:</strong>","children":[{"content":"<strong>BAIP:</strong> Focused on identifying risks and promoting openness for oversight. Lacks specificity.","children":[],"payload":{"lines":"320,321"}},{"content":"<strong>OECD:</strong> Emphasizes the need for human control and is well-aligned with legal requirements, but is abstract.","children":[],"payload":{"lines":"321,323"}}],"payload":{"lines":"319,323"}}],"payload":{"lines":"318,319"}},{"content":"Conclusions","children":[{"content":"The <strong>emancipation of AI</strong> from human oversight presents unique challenges in terms of control risks and ensuring human well-being.","children":[],"payload":{"lines":"324,325"}},{"content":"<strong>BAIP</strong> provides a framework for public oversight, while <strong>OECD</strong> advocates for maintaining human controls.","children":[],"payload":{"lines":"325,326"}},{"content":"Both approaches offer advantages in terms of risk awareness and promotion of openness,<br>\nbut lack detailed guidelines for practical implementation.","children":[],"payload":{"lines":"326,328"}},{"content":"<strong>Need for Balance:</strong> Between operational autonomy of AI systems and effective human oversight<br>\nto ensure ethical and pro-social outcomes.","children":[],"payload":{"lines":"328,330"}}],"payload":{"lines":"323,324"}}],"payload":{"lines":"294,295"}},{"content":"Protection Against AI-Driven Harassment","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> Use of AI techniques, like deep f","children":[],"payload":{"lines":"337,339"}},{"content":"<strong>Problem:</strong> Ease of implementation and potential for significant harm.","children":[],"payload":{"lines":"340,342"}}],"payload":{"lines":"336,337"}},{"content":"Toronto Declaration (TD)","children":[{"content":"<strong>Basis:</strong> International human rights.","children":[],"payload":{"lines":"343,344"}},{"content":"<strong>Approach:</strong> Consider second-order effects of open publication.","children":[],"payload":{"lines":"344,345"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Broad applicability and international coherence.","children":[],"payload":{"lines":"346,347"}},{"content":"Roots in international human rights laws.","children":[],"payload":{"lines":"347,348"}}],"payload":{"lines":"345,348"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of prescriptive guidance on alternative publication models.","children":[],"payload":{"lines":"349,350"}},{"content":"Need to balance open research with rights protection.","children":[],"payload":{"lines":"350,352"}}],"payload":{"lines":"348,352"}}],"payload":{"lines":"342,343"}},{"content":"Asilomar AI Principles (AAIP)","children":[{"content":"<strong>Key Elements:</strong> Research objectives, funding, research culture, shared prosperity.","children":[],"payload":{"lines":"353,354"}},{"content":"<strong>Approach:</strong> Set expectations on worthy research problems to pursue.","children":[],"payload":{"lines":"354,355"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Addresses which research problems to pursue.","children":[],"payload":{"lines":"356,357"}},{"content":"Balances costs and benefits of research to maximize benefit.","children":[],"payload":{"lines":"357,358"}}],"payload":{"lines":"355,358"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Normative guidelines without demonstrated use cases.","children":[],"payload":{"lines":"359,360"}},{"content":"Difficulty in assessing effectiveness in practice.","children":[],"payload":{"lines":"360,362"}}],"payload":{"lines":"358,362"}}],"payload":{"lines":"352,353"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>TD vs. AAIP:</strong>","children":[{"content":"<strong>TD:</strong> Focus on human rights protection and legal coherence.","children":[],"payload":{"lines":"364,365"}},{"content":"<strong>AAIP:</strong> Approach on defining and balancing ethically research objectives.","children":[],"payload":{"lines":"365,367"}}],"payload":{"lines":"363,367"}}],"payload":{"lines":"362,363"}},{"content":"Conclusions","children":[{"content":"Both <strong>TD</strong> and <strong>AAIP</strong> offer frameworks for protecting against AI-driven harassment.","children":[],"payload":{"lines":"368,369"}},{"content":"<strong>TD</strong> provides a foundation in human rights for broad application.","children":[],"payload":{"lines":"369,370"}},{"content":"<strong>AAIP</strong> highlights the importance of choice and balance in research.","children":[],"payload":{"lines":"370,371"}},{"content":"Both frameworks face challenges in providing specific, applicable guidance.","children":[],"payload":{"lines":"371,372"}},{"content":"<strong>Need for More Guidance:</strong> There's a need for more specific guidelines that can practically guide implementation<br>\nand ethical decision-making in the use of AI to prevent harassment.","children":[],"payload":{"lines":"372,374"}}],"payload":{"lines":"367,368"}}],"payload":{"lines":"334,335"}}],"payload":{"lines":"17,18"}}],"payload":{"lines":"1,2"}},{"colorFreezeLevel":3})</script>
</body>
</html>
