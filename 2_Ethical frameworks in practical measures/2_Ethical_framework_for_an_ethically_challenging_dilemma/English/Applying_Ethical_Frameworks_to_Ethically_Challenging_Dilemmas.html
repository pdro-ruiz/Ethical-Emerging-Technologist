<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.16.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.16.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:H,mm:ae}=window,W=new H.Toolbar;W.attach(ae);const we=W.render();we.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(we)})})()</script><script>((o,T,c,r)=>{const g=o();window.mm=g.Markmap.create("svg#mindmap",(T||g.deriveOptions)(r),c)})(()=>window.markmap,null,{"content":"Applying Ethical Frameworks to Ethically Challenging Dilemmas","children":[{"content":"General","children":[{"content":"Turning Ethical Principles into Action","children":[{"content":"Scenarios to Cover","children":[{"content":"<strong>Trolley Problem and Autonomous Cars:</strong> Decisions about who to save in life-or-death situations.","children":[],"payload":{"lines":"8,9"}},{"content":"<strong>Emergencies and Disasters:</strong> Prioritization and critical decision-making based on ethical frameworks.","children":[],"payload":{"lines":"9,10"}},{"content":"<strong>Patient Confidentiality in Health:</strong> Navigating privacy laws like HIPAA and their relation to ethics.","children":[],"payload":{"lines":"10,11"}},{"content":"<strong>Social Issues and Harassment by AI:</strong> Addressing the potential for social harm and harassment by AI systems.","children":[],"payload":{"lines":"11,13"}}],"payload":{"lines":"7,8"}},{"content":"Importance of Framework Selection","children":[{"content":"There are over 85 ethical frameworks, each with a specific focus and audience (e.g., some are aimed at governments, others at individuals).","children":[],"payload":{"lines":"14,15"}}],"payload":{"lines":"13,14"}}],"payload":{"lines":"5,6"}}],"payload":{"lines":"3,4"}},{"content":"Application of Frameworks to Ethical Dilemmas","children":[{"content":"Applying Ethical Frameworks to the Trolley Problem","children":[{"content":"Introduction to the Trolley Problem","children":[{"content":"<strong>Situation:</strong> A runaway trolley is headed towards a group of people tied to the tracks.","children":[],"payload":{"lines":"22,23"}},{"content":"<strong>Options:</strong>","children":[{"content":"Do nothing: the trolley kills the group.","children":[],"payload":{"lines":"24,25"}},{"content":"Pull a lever: divert the trolley, killing one person on adjacent tracks.","children":[],"payload":{"lines":"25,26"}}],"payload":{"lines":"23,26"}},{"content":"<strong>Ethical Dilemma:</strong> What is the most ethical action?","children":[],"payload":{"lines":"26,28"}}],"payload":{"lines":"21,22"}},{"content":"Utilitarian Approach","children":[{"content":"<strong>Preferred Action:</strong> Pull the lever to save the greater number of people.","children":[],"payload":{"lines":"29,30"}},{"content":"<strong>Considerations:</strong>","children":[{"content":"Direct involvement in the death of one person.","children":[],"payload":{"lines":"31,32"}},{"content":"Debate on moral responsibility for action vs. inaction.","children":[],"payload":{"lines":"32,34"}}],"payload":{"lines":"30,34"}}],"payload":{"lines":"28,29"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"35,36\"><strong>Montreal Declaration for a Responsible AI (MDRAI):</strong></p>","children":[{"content":"<strong>Emphasis on:</strong> Human autonomy, consideration of all sentient beings, responsibility in action and inaction.","children":[],"payload":{"lines":"36,37"}},{"content":"<strong>Advantages:</strong> Holistic inclusion and emphasis on responsibility.","children":[],"payload":{"lines":"37,38"}},{"content":"<strong>Challenges:</strong> Limited applicability to specific AI scenarios.","children":[],"payload":{"lines":"38,40"}}],"payload":{"lines":"35,40"}},{"content":"<p data-lines=\"40,41\"><strong>Asilomar AI Principles:</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Safety, value alignment, transparency of failures.","children":[],"payload":{"lines":"41,42"}},{"content":"<strong>Advantages:</strong> Promotes preparedness and awareness of AI failures and safe decisions.","children":[],"payload":{"lines":"42,43"}},{"content":"<strong>Challenges:</strong> Generic application that could be tailored at the decider's convenience.","children":[],"payload":{"lines":"43,45"}}],"payload":{"lines":"40,45"}}],"payload":{"lines":"34,35"}},{"content":"Notes","children":[{"content":"<strong>Importance of Guiding Principles:</strong> They help define and guide ethical practices in complex situations.","children":[],"payload":{"lines":"46,47"}},{"content":"<strong>Relevance of Ethical Frameworks:</strong> Both frameworks provide useful perspectives but differ in application and emphasis on responsibility and transparency.","children":[],"payload":{"lines":"47,48"}}],"payload":{"lines":"45,46"}}],"payload":{"lines":"19,20"}},{"content":"Schematic Summary: Use of AI in Emergencies and Disasters","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Deployment of contact tracing technology during a pandemic to fine-tune public health response.","children":[],"payload":{"lines":"54,55"}},{"content":"<strong>Dilemma:</strong> Balance between public safety and individual privacy.","children":[],"payload":{"lines":"55,57"}}],"payload":{"lines":"53,54"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"59,60\"><strong>Universal Guidelines for AI (UGAI)</strong></p>","children":[{"content":"<strong>Focus on:</strong> Public safety and accountability.","children":[],"payload":{"lines":"60,61"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Emphasis on enhancing public safety.","children":[],"payload":{"lines":"62,63"}},{"content":"Termination clause for limited and specific use.","children":[],"payload":{"lines":"63,64"}}],"payload":{"lines":"61,64"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of concreteness in principle application.","children":[],"payload":{"lines":"65,66"}},{"content":"Wide margin for interpretation.","children":[],"payload":{"lines":"66,68"}}],"payload":{"lines":"64,68"}}],"payload":{"lines":"59,68"}},{"content":"<p data-lines=\"68,69\"><strong>Toronto Declaration (TD)</strong></p>","children":[{"content":"<strong>Focus on:</strong> Non-discrimination and international human rights.","children":[],"payload":{"lines":"69,70"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Universal applicability and cross-border acceptance.","children":[],"payload":{"lines":"71,72"}},{"content":"Based on human rights principles.","children":[],"payload":{"lines":"72,73"}}],"payload":{"lines":"70,73"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of solid guidance on privacy.","children":[],"payload":{"lines":"74,75"}},{"content":"Potential insufficiency in addressing all ethical concerns.","children":[],"payload":{"lines":"75,77"}}],"payload":{"lines":"73,77"}}],"payload":{"lines":"68,77"}}],"payload":{"lines":"57,58"}},{"content":"Discussion","children":[{"content":"<strong>UGAI:</strong> Provides clear ethical guidance for contact tracing with an emphasis on accountability<br>\nand public safety, highlighting a termination clause to prevent misuse or undue prolonged use of the system.","children":[],"payload":{"lines":"78,80"}},{"content":"<strong>TD:</strong> Focuses on human rights and non-discrimination, offering an ethical framework to balance public health needs<br>\nwith the protection of privacy and individual rights.","children":[],"payload":{"lines":"80,82"}}],"payload":{"lines":"77,78"}}],"payload":{"lines":"51,52"}},{"content":"AI in Medicine - Bias vs. Humans","children":[{"content":"Context","children":[{"content":"<strong>Application Area:</strong> Radiology and reading of medical imaging scans.","children":[],"payload":{"lines":"88,89"}},{"content":"<strong>Dilemma:</strong> AI systems show greater accuracy than human medical panels but lack explanatory capability.","children":[],"payload":{"lines":"89,91"}}],"payload":{"lines":"87,88"}},{"content":"Application of Ethical Frameworks","children":[{"content":"","children":[{"content":"<p data-lines=\"93,94\"><strong>Montreal Declaration for a Responsible AI (MDR)</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Prudence, Human Autonomy, Responsibility.","children":[],"payload":{"lines":"94,95"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Anticipates negative consequences and ensures coherence with human decisions.","children":[],"payload":{"lines":"96,97"}},{"content":"Promotes significant human control and boosts trust.","children":[],"payload":{"lines":"97,98"}}],"payload":{"lines":"95,98"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Margin of interpretation can lead to inconsistent applications.","children":[],"payload":{"lines":"99,100"}},{"content":"Needs backing from regulatory instruments.","children":[],"payload":{"lines":"100,102"}}],"payload":{"lines":"98,102"}}],"payload":{"lines":"93,102"}},{"content":"<p data-lines=\"102,103\"><strong>Beijing AI Principles</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Informed Consent, Educational Formation.","children":[],"payload":{"lines":"103,104"}},{"content":"<strong>Advantages:</strong>","children":[],"payload":{"lines":"104,105"}}],"payload":{"lines":"102,105"}}],"payload":{"lines":"93,105"}},{"content":"Promotes patient understanding of risks.","children":[{"content":"Prepares doctors to handle system failures and communicate risks.","children":[],"payload":{"lines":"108,109"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of details on the practical implementation of principles.","children":[],"payload":{"lines":"110,111"}},{"content":"Questions on the sufficiency of educational formation and informed consent.","children":[],"payload":{"lines":"111,113"}}],"payload":{"lines":"109,113"}}],"payload":{"lines":"107,113"}}],"payload":{"lines":"91,92"}},{"content":"Comparison and Conclusion","children":[{"content":"<strong>MDR vs. Beijing Principles:</strong> Both frameworks offer useful perspectives for addressing the ethical dilemma, focusing attention on prudence, autonomy, responsibility, and informed consent as foundations for the ethical use of AI in medicine.","children":[],"payload":{"lines":"114,115"}},{"content":"<strong>Effectiveness:</strong> MDR provides a holistic approach encompassing trust and organizational values, while the Beijing Principles focus on consent and preparation of the patient and medical professional.","children":[],"payload":{"lines":"115,116"}},{"content":"<strong>Implementation:</strong> Both frameworks face challenges in practical application, needing clarity and regulatory support to ensure their effectiveness.","children":[],"payload":{"lines":"116,117"}}],"payload":{"lines":"113,114"}}],"payload":{"lines":"85,86"}},{"content":"AI and Self-Destructive Behaviors","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of AI in social media that promotes addictive behaviors through endless scrolling and hyper-personalized content.","children":[],"payload":{"lines":"123,124"}},{"content":"<strong>Dilemma:</strong> Balance between maximizing business profits and preserving user well-being.","children":[],"payload":{"lines":"124,126"}}],"payload":{"lines":"122,123"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"128,129\"><strong>Universal Guidelines for AI (UGAI)</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Data Quality, Prohibition of Secret Profiling, Public Safety.","children":[],"payload":{"lines":"129,130"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Wide coverage of ethical concerns.","children":[],"payload":{"lines":"131,132"}},{"content":"Guides towards user benefit.","children":[],"payload":{"lines":"132,133"}}],"payload":{"lines":"130,133"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of concrete guidelines for implementation.","children":[],"payload":{"lines":"134,136"}}],"payload":{"lines":"133,136"}}],"payload":{"lines":"128,136"}},{"content":"<p data-lines=\"136,137\"><strong>Beijing AI Principles</strong></p>","children":[{"content":"<strong>Applicable Principles:</strong> Informed Consent, Ethics by Design.","children":[],"payload":{"lines":"137,138"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Promotes ethical considerations from initial development.","children":[],"payload":{"lines":"139,140"}},{"content":"Prevention of addictive interfaces and harmful reward systems.","children":[],"payload":{"lines":"140,141"}}],"payload":{"lines":"138,141"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Wide margin for interpretation.","children":[],"payload":{"lines":"142,143"}},{"content":"Lack of specificity in implementation.","children":[],"payload":{"lines":"143,145"}}],"payload":{"lines":"141,145"}}],"payload":{"lines":"136,145"}}],"payload":{"lines":"126,127"}},{"content":"Comparison and Conclusion","children":[{"content":"<strong>UGAI</strong> emphasizes the proper use of data and social impact, providing a framework for balancing business gain<br>\nwith user well-being. However, it lacks detailed guidelines for practice.","children":[],"payload":{"lines":"147,149"}},{"content":"<strong>Beijing Principles</strong> focus on informed consent and the inclusion of ethical considerations in design,<br>\nsupporting the development of less harmful systems from the start. However, vagueness in practical application could limit its effectiveness.","children":[],"payload":{"lines":"149,151"}},{"content":"<strong>Recommended Approach:</strong> Combining both frameworks may offer a balanced approach, ensuring both responsibility<br>\nin data use and the incorporation of ethics in AI design and development, to mitigate self-destructive behaviors among users.","children":[],"payload":{"lines":"151,153"}}],"payload":{"lines":"145,146"}}],"payload":{"lines":"120,121"}},{"content":"Limits of Persuasive Technology in Smart Toys","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of AI in smart toys to influence children's behaviors, such as persuading them to desire certain brands.","children":[],"payload":{"lines":"159,160"}},{"content":"<strong>Concern:</strong> Highly persuasive technology aimed at a vulnerable audience (children).","children":[],"payload":{"lines":"160,162"}}],"payload":{"lines":"158,159"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"164,165\"><strong>OECD AI Principles</strong></p>","children":[{"content":"<strong>Focus:</strong> Responsible disclosure, transparency, privacy, societal well-being.","children":[],"payload":{"lines":"165,166"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Balance between responsible disclosure and societal well-being.","children":[],"payload":{"lines":"167,168"}},{"content":"Alignment with legal and regulatory environments.","children":[],"payload":{"lines":"168,169"}}],"payload":{"lines":"166,169"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Normative character without demonstrated use cases.","children":[],"payload":{"lines":"170,172"}}],"payload":{"lines":"169,172"}}],"payload":{"lines":"164,172"}},{"content":"<p data-lines=\"172,173\"><strong>Ethical Guidelines on Untrustworthy AI</strong></p>","children":[{"content":"<strong>Focus:</strong> Respect for human autonomy, privacy, data governance, societal well-being.","children":[],"payload":{"lines":"173,174"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Granular guidance with effective use cases.","children":[],"payload":{"lines":"175,176"}},{"content":"Proximity to legal and regulatory requirements.","children":[],"payload":{"lines":"176,177"}}],"payload":{"lines":"174,177"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Focus on EU legislation, may require adaptation outside Europe.","children":[],"payload":{"lines":"178,180"}}],"payload":{"lines":"177,180"}}],"payload":{"lines":"172,180"}}],"payload":{"lines":"162,163"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>OECD vs. Ethical Guidelines:</strong> OECD principles provide a general framework for ethical development,<br>\nwhile Ethical Guidelines offer more detailed and pragmatic guidance, especially regarding the autonomy and safety of minors.","children":[],"payload":{"lines":"182,184"}},{"content":"<strong>Impact on Product Development:</strong> Both frameworks seek to guide the creation of products that respect user autonomy<br>\nand promote their well-being, though from different levels of detail and geographic applicability.","children":[],"payload":{"lines":"184,187"}}],"payload":{"lines":"180,181"}},{"content":"Notes","children":[{"content":"<strong>Ethical Balance:</strong> It's crucial to balance technological innovation with the protection of vulnerable users,<br>\nensuring that persuasive technology does not compromise the well-being or autonomy of children.","children":[],"payload":{"lines":"189,191"}},{"content":"<strong>Framework Choice:</strong> Will depend on the specific needs of the organization and the jurisdictional context in which it operates,<br>\nthough the trend is towards granular and use-case-based ethical application.","children":[],"payload":{"lines":"191,193"}}],"payload":{"lines":"187,188"}}],"payload":{"lines":"156,157"}},{"content":"Patient Confidentiality Breach by Compliance Failure","children":[{"content":"Context","children":[{"content":"<strong>Scenario:</strong> Use of NLP chatbots for non-medical mental health assistance.","children":[],"payload":{"lines":"200,201"}},{"content":"<strong>Dilemma:</strong> Balancing user privacy with the need for intervention in cases of self-harm or suicide risk.","children":[],"payload":{"lines":"201,203"}}],"payload":{"lines":"199,200"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"205,206\"><strong>IEEE Ethically Aligned Design (EAD)</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Ethics by design, affective computing privacy, well-being.","children":[],"payload":{"lines":"206,207"}},{"content":"<strong>Approach:</strong>","children":[{"content":"Balance between user support and prevention of harmful dependencies.","children":[],"payload":{"lines":"208,209"}},{"content":"Privacy with clear boundaries, yet allowing interventions in case of vital risk.","children":[],"payload":{"lines":"209,210"}}],"payload":{"lines":"207,210"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit consideration of affective computing and well-being alongside privacy.","children":[],"payload":{"lines":"211,212"}}],"payload":{"lines":"210,212"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"High-level recommendations subject to interpretation, potential for evading responsibilities.","children":[],"payload":{"lines":"213,215"}}],"payload":{"lines":"212,215"}}],"payload":{"lines":"205,215"}},{"content":"<p data-lines=\"215,216\"><strong>Asilomar AI Principles</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Safety and transparency of failures.","children":[],"payload":{"lines":"216,217"}},{"content":"<strong>Approach:</strong>","children":[{"content":"Balanced disclosure and human life safety.","children":[],"payload":{"lines":"218,219"}},{"content":"Awareness of system limitations to manage expectations.","children":[],"payload":{"lines":"219,220"}}],"payload":{"lines":"217,220"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit mention of failure transparency, crucial in mental health.","children":[],"payload":{"lines":"221,222"}}],"payload":{"lines":"220,222"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Very high-level and generic principles, difficulty in practical implementation.","children":[],"payload":{"lines":"223,225"}}],"payload":{"lines":"222,225"}}],"payload":{"lines":"215,225"}}],"payload":{"lines":"203,204"}},{"content":"Comparative Analysis","children":[{"content":"<strong>EAD vs. Asilomar:</strong>","children":[{"content":"EAD provides a more comprehensive approach by including affective computing, but can be vague in its application.","children":[],"payload":{"lines":"228,229"}},{"content":"Asilomar emphasizes safety and transparency, essential in the context of mental health, but lacks operational specificity.","children":[],"payload":{"lines":"229,231"}}],"payload":{"lines":"227,231"}}],"payload":{"lines":"225,226"}},{"content":"Notes","children":[{"content":"<strong>Ethical Implication:</strong> Both frameworks suggest the importance of maintaining an ethical balance between patient confidentiality<br>\nand necessary intervention in emergency cases.","children":[],"payload":{"lines":"233,235"}},{"content":"<strong>Implementation Challenge:</strong> The lack of concreteness in guidelines poses challenges in effective application<br>\nand responsible ethical decision-making.","children":[],"payload":{"lines":"235,237"}},{"content":"<strong>Consideration of Principles:</strong> Despite their differences, both frameworks underline the priority of user safety<br>\nand the need for informed ethical intervention.","children":[],"payload":{"lines":"237,239"}}],"payload":{"lines":"231,232"}}],"payload":{"lines":"197,198"}},{"content":"Individual Benefits vs. Harm to Social Fabric","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> Free speech on social media vs. negative societal impact.","children":[],"payload":{"lines":"245,246"}},{"content":"<strong>Conflict:</strong> Between individual autonomy and collective well-being.","children":[],"payload":{"lines":"246,248"}}],"payload":{"lines":"244,245"}},{"content":"Application of Ethical Frameworks","children":[{"content":"<p data-lines=\"250,251\"><strong>IEEE Ethically Aligned Design (EAD)</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Individual autonomy, ensuring social well-being.","children":[],"payload":{"lines":"251,252"}},{"content":"<strong>Approach:</strong> Balance between empowering individual autonomy and restrictions to protect the community.","children":[],"payload":{"lines":"252,253"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicit call to individual autonomy.","children":[],"payload":{"lines":"254,255"}},{"content":"Flexibility to include community needs.","children":[],"payload":{"lines":"255,256"}}],"payload":{"lines":"253,256"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of specificity for content moderation.","children":[],"payload":{"lines":"257,259"}}],"payload":{"lines":"256,259"}}],"payload":{"lines":"250,259"}},{"content":"<p data-lines=\"259,260\"><strong>Santa Clara Principles on Transparency and Accountability in Content Moderation</strong></p>","children":[{"content":"<strong>Specialization:</strong> Aimed at media, addresses gaps of EAD in content moderation.","children":[],"payload":{"lines":"260,262"}}],"payload":{"lines":"259,262"}},{"content":"<p data-lines=\"262,263\"><strong>Ethical Guideline for Trustworthy AI</strong></p>","children":[{"content":"<strong>Key Principles:</strong> Accountability, human oversight, societal well-being.","children":[],"payload":{"lines":"263,264"}},{"content":"<strong>Approach:</strong> Risk-based framework to balance accountability and oversight with collective well-being.","children":[],"payload":{"lines":"264,265"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Human oversight and accountability defined explicitly.","children":[],"payload":{"lines":"266,267"}},{"content":"Strengthening of culture, values, and social norms.","children":[],"payload":{"lines":"267,268"}}],"payload":{"lines":"265,268"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of specificity for content moderation.","children":[],"payload":{"lines":"269,270"}},{"content":"Regional focus may limit global applicability.","children":[],"payload":{"lines":"270,272"}}],"payload":{"lines":"268,272"}}],"payload":{"lines":"262,272"}}],"payload":{"lines":"248,249"}},{"content":"Comparative Analysis","children":[{"content":"<strong>EAD vs. Ethical Guidelines:</strong> EAD provides a broad framework for empowering autonomy, but lacks a specific focus on moderation.<br>\nEthical Guidelines offer a risk-based framework with an emphasis on collective well-being, but its application may be regionally limited.","children":[],"payload":{"lines":"274,277"}}],"payload":{"lines":"272,273"}},{"content":"Notes","children":[{"content":"<strong>Combination of Frameworks:</strong> Integrating multiple frameworks may offer a more effective balance between individual benefits and social responsibility.","children":[],"payload":{"lines":"279,280"}},{"content":"<strong>Implementation Challenge:</strong> The lack of specificity in content moderation and regional variability requires<br>\nan adaptive and possibly combined approach to effectively address the dilemma.","children":[],"payload":{"lines":"280,282"}}],"payload":{"lines":"277,278"}}],"payload":{"lines":"242,243"}},{"content":"Emancipation of AI Systems from Human Oversight","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> AI systems operate without significant human oversight.","children":[],"payload":{"lines":"289,290"}},{"content":"<strong>Problem:</strong> Difficulty in ensuring well-being and other pro-social outcomes.","children":[],"payload":{"lines":"290,292"}}],"payload":{"lines":"288,289"}},{"content":"Beijing AI Principles (BAIP)","children":[{"content":"<strong>Approach:</strong> Control risks and openness/exchange.","children":[],"payload":{"lines":"293,294"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Explicitly identifies control risks.","children":[],"payload":{"lines":"295,296"}},{"content":"Proposes openness and exchange for public oversight and accountability.","children":[],"payload":{"lines":"296,297"}}],"payload":{"lines":"294,297"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of actionable advice.","children":[],"payload":{"lines":"298,299"}},{"content":"Points to areas for research without detailed recommendations.","children":[],"payload":{"lines":"299,301"}}],"payload":{"lines":"297,301"}}],"payload":{"lines":"292,293"}},{"content":"OECD AI Principles","children":[{"content":"<strong>Approach:</strong> Adequate human intervention, opposition to complete emancipation from human oversight.","children":[],"payload":{"lines":"302,303"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Guidance grounded in human rights legislation.","children":[],"payload":{"lines":"304,305"}},{"content":"Clear guidelines for maintaining human controls.","children":[],"payload":{"lines":"305,306"}}],"payload":{"lines":"303,306"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Very high level, abstract, and open to interpretation.","children":[],"payload":{"lines":"307,308"}},{"content":"Risk of claiming adherence without effective compliance.","children":[],"payload":{"lines":"308,310"}}],"payload":{"lines":"306,310"}}],"payload":{"lines":"301,302"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>BAIP vs. OECD:</strong>","children":[{"content":"<strong>BAIP:</strong> Focused on identifying risks and promoting openness for oversight. Lacks specificity.","children":[],"payload":{"lines":"312,313"}},{"content":"<strong>OECD:</strong> Emphasizes the need for human control and is well-aligned with legal requirements, but is abstract.","children":[],"payload":{"lines":"313,315"}}],"payload":{"lines":"311,315"}}],"payload":{"lines":"310,311"}},{"content":"Notes","children":[{"content":"The <strong>emancipation of AI</strong> from human oversight presents unique challenges in terms of control risks and ensuring human well-being.","children":[],"payload":{"lines":"316,317"}},{"content":"<strong>BAIP</strong> provides a framework for public oversight, while <strong>OECD</strong> advocates for maintaining human controls.","children":[],"payload":{"lines":"317,318"}},{"content":"Both approaches offer advantages in terms of risk awareness and promotion of openness,<br>\nbut lack detailed guidelines for practical implementation.","children":[],"payload":{"lines":"318,320"}},{"content":"<strong>Need for Balance:</strong> Between operational autonomy of AI systems and effective human oversight<br>\nto ensure ethical and pro-social outcomes.","children":[],"payload":{"lines":"320,322"}}],"payload":{"lines":"315,316"}}],"payload":{"lines":"286,287"}},{"content":"Protection Against AI-Driven Harassment","children":[{"content":"Context","children":[{"content":"<strong>Challenge:</strong> Use of AI techniques, like deep f","children":[],"payload":{"lines":"329,331"}},{"content":"<strong>Problem:</strong> Ease of implementation and potential for significant harm.","children":[],"payload":{"lines":"332,334"}}],"payload":{"lines":"328,329"}},{"content":"Toronto Declaration (TD)","children":[{"content":"<strong>Basis:</strong> International human rights.","children":[],"payload":{"lines":"335,336"}},{"content":"<strong>Approach:</strong> Consider second-order effects of open publication.","children":[],"payload":{"lines":"336,337"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Broad applicability and international coherence.","children":[],"payload":{"lines":"338,339"}},{"content":"Roots in international human rights laws.","children":[],"payload":{"lines":"339,340"}}],"payload":{"lines":"337,340"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Lack of prescriptive guidance on alternative publication models.","children":[],"payload":{"lines":"341,342"}},{"content":"Need to balance open research with rights protection.","children":[],"payload":{"lines":"342,344"}}],"payload":{"lines":"340,344"}}],"payload":{"lines":"334,335"}},{"content":"Asilomar AI Principles (AAIP)","children":[{"content":"<strong>Key Elements:</strong> Research objectives, funding, research culture, shared prosperity.","children":[],"payload":{"lines":"345,346"}},{"content":"<strong>Approach:</strong> Set expectations on worthy research problems to pursue.","children":[],"payload":{"lines":"346,347"}},{"content":"<strong>Advantages:</strong>","children":[{"content":"Addresses which research problems to pursue.","children":[],"payload":{"lines":"348,349"}},{"content":"Balances costs and benefits of research to maximize benefit.","children":[],"payload":{"lines":"349,350"}}],"payload":{"lines":"347,350"}},{"content":"<strong>Challenges:</strong>","children":[{"content":"Normative guidelines without demonstrated use cases.","children":[],"payload":{"lines":"351,352"}},{"content":"Difficulty in assessing effectiveness in practice.","children":[],"payload":{"lines":"352,354"}}],"payload":{"lines":"350,354"}}],"payload":{"lines":"344,345"}},{"content":"Comparison and Analysis","children":[{"content":"<strong>TD vs. AAIP:</strong>","children":[{"content":"<strong>TD:</strong> Focus on human rights protection and legal coherence.","children":[],"payload":{"lines":"356,357"}},{"content":"<strong>AAIP:</strong> Approach on defining and balancing ethically research objectives.","children":[],"payload":{"lines":"357,359"}}],"payload":{"lines":"355,359"}}],"payload":{"lines":"354,355"}},{"content":"Notes","children":[{"content":"Both <strong>TD</strong> and <strong>AAIP</strong> offer frameworks for protecting against AI-driven harassment.","children":[],"payload":{"lines":"360,361"}},{"content":"<strong>TD</strong> provides a foundation in human rights for broad application.","children":[],"payload":{"lines":"361,362"}},{"content":"<strong>AAIP</strong> highlights the importance of choice and balance in research.","children":[],"payload":{"lines":"362,363"}},{"content":"Both frameworks face challenges in providing specific, applicable guidance.","children":[],"payload":{"lines":"363,364"}},{"content":"<strong>Need for More Guidance:</strong> There's a need for more specific guidelines that can practically guide implementation<br>\nand ethical decision-making in the use of AI to prevent harassment.","children":[],"payload":{"lines":"364,366"}}],"payload":{"lines":"359,360"}}],"payload":{"lines":"326,327"}}],"payload":{"lines":"17,18"}}],"payload":{"lines":"1,2"}},{"colorFreezeLevel":3})</script>
</body>
</html>
